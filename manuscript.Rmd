---
title             : "Sampling Strategies in Decisions from Experience: Property Representation and Probability Weighting Approximation"
shorttitle        : "Sampling strategies"

author: 
  - name          : "Linus Hof"
    affiliation   : "1"
    corresponding : yes    
    address       : "Department of Psychology, Heidelberg University, Hauptstraße 47-51, 69117 Heidelberg, Germany"
    email         : "linushof@posteo.de"
    
affiliation:
  - id            : "1"
    institution   : "Heidelberg University"

note: | 
  **Unsubmitted draft created from the commit with the hash**: ``r repro::current_hash()``
  
authornote: |
 This is a dynamic document which can be reproduced from the accompanying GitHub repository: https://github.com/linushof/sampling-in-dfe. 
 
 The current version of this manuscript is prepared for submission as a master's thesis.
 Supervisors: Thorsten Pachur & Veronika Zilker.   
 
abstract: |
  Add abstract
  
keywords          : ""
wordcount         : ""

bibliography      : references_sampling-in-dfe.bib
csl               : apa.csl

figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : no
linkcolor         : "blue"
mask              : no
draft             : no

classoption       : "man"
documentclass     : "apa7"
output: papaja::apa6_pdf

header-includes:
   - \usepackage[capposition=top]{floatrow}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, #omit messages
                      fig.align = "l", #align figures to left margin
                      fig.pos = "t" # display figures at the top of a page
                      )
```

```{r packages, include=FALSE}
#load required packages
pacman::p_load(papaja,
               knitr,
               readr,
               tidyr, 
               dplyr,
               ggplot2,
               viridis,
               ggpubr,
               latex2exp)
```

<!-- Introduction -->

The human mind is a cognitive system that operates on inputs from an environment or memory, and in the domain of decision making, such inputs provide information about the choice alternatives between which people can choose.
Indeed, irrespective of their exact specification, decision models generally take as inputs information about a set of choice alternatives, each possessing some defining *properties*, and return a subset of chosen alternatives as outputs [@heOntologyDecisionModels2020].
Respectively, decision making can be understood as an information-processing problem whose solution requires a selection among choice alternatives.

Now, let a *prospect* be a choice alternative that possesses only two kinds of fundamental properties: the possible outcomes of the alternative (e.g., gains or losses of some amount) and the probabilities with which these outcomes occur following the choice of the alternative.
Importantly, the information that the inputs provide about these properties can come in different forms.
Specifically, in *decisions from description* (DfD), the inputs take the form of explicit and complete descriptions of all outcomes and probabilities.
Yet, in *decisions from experience* [DfE, @hertwigDecisionsExperienceEffect2004], these properties are latent and therefore not known with certainty, but they must be inferred from the relative frequencies with which the outcomes occurred in the past, e.g., when the prospect was chosen in similar past decisions.
The inputs to DfE therefore take the form of sampled outcomes.
Although these distinct input forms may in principle carry the same information about a given set of prospects, behavioral decision research has so far produced a large body of papers indicating that---taking a quite general perspective---there are robust differences between the choices that are made in DfD and DfE, leading to the notion of the *description-experience gap* [@hertwigDescriptionexperienceGapRisky2009].
In one reading of the gap,^[<!--Open footnote-->See @hertwigConstructBehaviorGap2018, for a discussion on the interpretation of the gap.<!--Close footnote-->]
choice patterns in DfD deviate from the solutions of expected value (EV) maximization, as if small-probability outcomes were given more weight than would be warranted by their objective probabilities;
in turn, in DfE, choice patterns deviate from the solutions of EV maximization as if the same small-probability outcomes were given less weight than would be objectively warranted [e.g., @barronSmallFeedbackbasedDecisions2003; @hertwigDecisionsExperienceEffect2004; @weberPredictingRiskSensitivity2004; @erevAnomaliesForecastsDescriptive2017; see @wulffMetaanalyticReviewTwo2018, for a comprehensive meta-analytic review].
Hereafter, these choice patterns are referred to as the *as-if overweighting* and *as-if underweighting of rare outcomes*, respectively.

Similar to other behavioral phenomena that can be explained by assuming that the mind is sensitive to the composition of the *samples*---i.e., sets of sampled outcomes---on which it operates [see @fiedlerBewareSamplesCognitiveecological2000], the as-if underweighting of rare outcomes can be explained by assuming that the mind is sensitive to the information provided by the small samples that people tend to rely on in DfE [see @foxDecisionsExperienceSampling2006; @hertwigDecisionsExperienceEffect2004; @hertwigDecisionsExperienceWhy2010; @rakowBiasedSamplesNot2008; @wulffMetaanalyticReviewTwo2018].
More specifically, following from the laws of large numbers [see, e.g., @kolmogorovFoundationsTheoryProbability1950], the relative frequencies with which the prospect's outcomes occur in a sample of infinite size converge almost surely to the respective objective probabilities.
In such a case or in the less strict case of large samples, then, the binomial distribution of each outcome can be approximated by a symmetric normal distribution.^[<!--Open footnote-->The binomial distribution of an outcome is the probability distribution of the number of times an outcome occurs in a sample. According to the *de Moivre-Laplace theorem* [see, e.g., @georgiiStochastikEinfuhrungWahrscheinlichkeitstheorie2015], the binomial distribution can be approximated by a normal distribution given a large number of sampled outcomes. Respectively, for large samples, the relative relative frequencies with which an outcome occurs in the sample is predicted to correspond to the objective probability of the outcome most of the time and is not predicted to be lower more often than higher or vice versa.<!--Close footnote-->]
However, for samples of small size, the binomial distribution associated with small-probability outcomes is positive skewed, therefore causing the relative frequencies with which these outcomes occur in the sample to be smaller rather than larger than their latent objective probabilities.
As a consequence, were the mind to use the relative frequencies of outcomes in a sample to infer their latent objective probabilities and to follow the principle of EV maximization, the as-if underweighting of rare outcomes in DfE could be explained by the reliance on small samples.

Yet, some studies show that the as-if underweighting of rare outcomes may appear, even if the overall number of sampled outcomes is large and the relative frequencies across all sampled outcomes correspond closely to the latent objective probabilities [@hauDescriptionexperienceGapRisky2008; @hauDecisionsExperienceStatistical2010; @ungemachAreProbabilitiesOverweighted2009; see also @wulffMetaanalyticReviewTwo2018].
Respectively, there may be a disconnect between the overall number of sampled outcomes and the size of the samples the mind relies on in the evaluation of prospects.
However, in contrast to other approaches, in the current paper it is not assumed that some of the sampled outcomes are discounted [see, e.g., @hertwigDecisionsExperienceEffect2004, who assume recency effects] or ignored [see, e.g., @cohenEffectPerceivedPatterns2021; @plonskyRelianceSmallSamples2015, who assume that only outcomes that followed some sequential pattern are considered].
Rather, assuming that any number of outcomes sampled from a prospect may either be integrated into the same sample or into multiple smaller samples, this paper presents an accumulation model that shows that---given a reliance on multiple or many small samples---an as-if underweighting of rare outcomes can occur, even if a large number of sampled outcomes is fully accounted for.

Therefore, consider first the finding that *sampling strategies* were indicative for the final choice in DfE.
Specifically, in one paradigm used to study DfE, namely, the sampling paradigm [@weberPredictingRiskSensitivity2004], before making a final choice between prospects with latent properties, people can, as much as they want, sequentially sample the prospects' outcomes according to their objective probabilities.
Considering this paradigm and the choice between two prospects, @hillsInformationSearchDecisions2010 distinguished sampling strategies along the frequency of switches between the two prospects during the sampling phase,^[<!--Open footnote-->Note that @hillsInformationSearchDecisions2010 proposed two paradigmatic sampling strategies, where prospects are either switched just once (comprehensive sampling) or after each sampled outcome (piecewise sampling).
Nevertheless, in their analyses of empirical sampling data, they used the number of switches between prospects relative to the overall number of sampled outcomes from both prospects (switching frequency) as an approximate measure for the two proposed sampling strategies, and further acknowledged that "many [sampling] strategies will fall on the continuum between [the two paradigmatic strategies]" [@hillsInformationSearchDecisions2010, p. 1788].
Respectively, in the current paper sampling strategies are defined as switching probabilities.
<!--Close footnote-->] 
and proposed two different decision strategies that people may adopt.
That is, for a summary strategy, it is assumed that the prospect is chosen which produced the greater mean across all sampled outcomes.
In turn, for a round-wise strategy, it is assumed that over multiple rounds two sampled outcomes---i.e., one from each of the prospects---are compared and that the prospect is chosen which won the comparison in most rounds.
Then, @hillsInformationSearchDecisions2010 found that the choices of people who switched frequently between prospects during the sampling phase were better predicted by a round-wise strategy (rather than a summary strategy), and that this predictive pattern reversed for people who switched infrequently.

Now, one explanation for such a reversed predictive pattern would be if the differences in the sampling strategies determine which of the two decision strategies is used.
To this end, this paper presents a computational model that provides a link between *switching probabilities*---i.e., the probability of sampling outcomes from different prospects in direct succession during the sampling phase---and the decision strategies.
Specifically, the proposed model accumulates the outcomes obtained from the comparisons between sample means, with switching probabilities determining the size of the samples underlying each mean comparison and thresholds determining how much (more) of such comparisons a prospect must win in order to be chosen.
Accordingly, the model is such that the higher (lower) the switching probabilities and the higher (lower) the thresholds, the more the accumulation process resembles the round-wise (summary) strategy.

The current paper discusses and demonstrates in a computational analysis how such a simple accumulation model can explain an as-if underweighting of rare outcomes, even if a large number of sampled outcomes is fully accounted for.
More specifically, since the switching probabilities alter the size of the samples underlying each mean comparison, the model predicts the switching probabilities to affect whether a low-probability outcome contributes to the majority of required mean comparisons about as much as would be warranted by its objective probabilities, or whether it contributes rather less.
Respectively, if the small-probability outcome is smaller (larger) than the EV, high switching probabilities cause the mean to be an inflated (deflated) estimate of the EV in most of the comparisons, which can translate to an as-if underweighting of rare outcomes, irrespective of what the thresholds determine the required number of mean comparisons to be.
Yet, since the EV is not the only property which can be used to distinguish among the prospects, the proposed model shows how the mind may rely on different sampling strategies to change which differences in the latent properties of prospects evidence is accumulate for.
Specifically, for low switching probabilities, the accumulation process unfolds over mean comparisons based on large samples and is therefore more indicative for differences in the EV; in turn, for high switching probabilities, the accumulation process unfolds over mean comparisons based on small samples and is therefore more indicative for differences in the probability to produce a higher outcome than the respective other prospect most of the time.
In either case, then, the model implements a speed-accuracy trade-off of the form that the respective differences in the latent properties are more accurately assessed, the larger the thresholds are, i.e., the more evidence must be accumulated in favor of a prospect.

To substantiate the discussion, the model is used to simulate the accumulation process for different combinations of switching probabilities and thresholds and to predict choices between a two-outcome prospect and a safe prospect, respectively.
Considering choice rates and parameter estimates of cumulative prospect theory [CPT, @tverskyAdvancesProspectTheory1992; @wakkerAxiomatizationCumulativeProspect1993], the computational analysis shows that the choices converge to the solutions of EV maximization for low switching probabilities, but take the form of an as-if underweighting of rare outcomes for high switching probabilities.
Importantly, the analysis also shows that the differences between switching probabilities become more pronounced with increasing thresholds.
In other words, the proposed model predicts an as-if underweighting of rare outcomes to occur when high switching probabilities cause the accumulation process to unfold over mean comparisons that are based on small samples.
Thus, the analysis substantiates the claim that not only the reliance on just a portion of a large number of sampled outcomes can explain an as-if underweighting of rare outcomes in DfE, but also the reliance on multiple or many small samples.
Moreover, the analysis shows that an as-if underweighting of rare outcomes cannot be equated with inaccurate inferences about latent properties---e.g., the EVs---that carry over to the subsequent choices.
Rather the opposite, an as-if underweighting of rare outcomes can also be caused by an accurate assessment of the differences among prospects in the latent probability to produce a higher outcome most of the time.
Before presenting the model and the computational analysis, the following section provides a formal definition of prospects and reviews how CPT in general and its weighting function in particular can be used to capture deviations from EV maximization.

# Prospects and the Description of Choices in CPT

Since there is an uncountable number of choices people confront in the natural world, behavioral decision research routinely abstracts from choices between particular choice alternatives, e.g., the choice between job offers, political parties to vote for, investment plans, and whatnot.
Rather, with the choice between at least two prospects, it studies a case which is counterfactual in that it omits the many particularities of each choice situation, but retains in the form of prospects the fundamental properties that almost all choice alternatives are assumed to possess.
These fundamental properties are considered the possible outcomes of a choice alternative and the probabilities with which these outcomes occur following the choice of the alternative.
Roughly speaking, then, all choice alternatives that can be fully described by their outcome-probability pairs are prospects.
As such, prospects can be understood as the distribution of a discrete random variable, for which the following section briefly provides an axiomatic basis. 

## Formal Definition of Prospects

Following @kolmogorovFoundationsTheoryProbability1950 and adopting the symbolic notation from @georgiiStochastikEinfuhrungWahrscheinlichkeitstheorie2015, let the tuple $(\Omega, \mathcal{F}, P)$ be a probability space.
Accordingly, $\Omega$ is a finite sample space with each element $\omega \in \Omega$ denoting a possible consequence of choosing the respective prospect.
$\mathcal{F}$ is the power set $\mathcal{P}(\Omega)$ with each element $A \in \mathcal{F}$ being a subset of $\Omega$, also denoted a random event.
$P$ is the probability measure
$$
P: \mathcal{F} \to [0,1]
\tag{1}
$$
assigning the elements of $\mathcal{F}$ a probability $0 < p(A) \leq 1$ with $P(\Omega) = 1$.
Now, the random variable is a function
$$
\begin{aligned}
  X : (\Omega, \mathcal{F}) &\to (\Omega', \mathcal{F'})  \\
  \omega &\mapsto x
  \; ,
\end{aligned}
\tag{2}
$$
where $(\Omega', \mathcal{F'})$ is a measurable space with each element $x \in \Omega'$ denoting a possible outcome of a prospect and each element $A' \in \mathcal{F'}$ being a subset of $\Omega'$.
An outcome's probability $p_X(x)$ is then provided by the pushforward measure
$$
P' : \mathcal{F'} \to [0,1]
\tag{3}
$$
with 
$$
P'(A' \in \mathcal{F'}) := P(\{\omega: X(\omega) = x \in A'\})
\; .
\tag{4}
$$
Note that the measure in (3) and (4), respectively, is a random variable's distribution and therefore a prospect. 
Accordingly, given a choice between $1, ..., k$ prospects, the inputs from the environment or memory should provide information about the set
$$
\{P'^1, ... , P'^k\}
\; ,
\tag{5}
$$
where each element $P'$ can itself be considered a set of outcome-probability pairs $\{(x_i, p_X(x_i)\}_{i \in \mathbb{N}}$.

## CPT and the Concept of Probability Weighting

The choices people actually make between prospects are often described in terms of deviations from the principle of EV maximization, according to which the prospect with the largest EV
$$
EV = \sum_i^n x_i \times p_X(x_i)
\tag{6}
$$ 
should be chosen.
To *describe* how people's actual choices deviate from EV maximization [see @erevAnomaliesForecastsDescriptive2017, for a recent replication of classical demonstrations],^[<!--Open footnote-->@tverskyAdvancesProspectTheory1992 addressed the *fourfold pattern of risk attitudes*---i.e., choices between prospects indicate risk aversion for gains of high probability and losses of low probability, and risk seeking for gains of low probability and losses of high probability---and related effects, e.g., the *certainty effect* and the *reflection effect*, where the latter were already addressed by CPT's predecessor, prospect theory [@kahnemanProspectTheoryAnalysis1979]. Together, these empirical choice patterns indicate a violation of EV and expected utility (EU) maximization [see @bernoulliExpositionNewTheory1954\/1738].<!--Close footnote-->]
CPT and similar rank-dependent models [see @stottCumulativeProspectTheory2006, for an overview of models] fit choice data by assuming that people maximize the value
$$
V = \sum_i^n v(x_i) \times \pi_i
\; ,
\tag{7}
$$ 
with objective outcomes $x_i$ being transformed by a value function $v$, and *cumulative decision weights* $\pi_i$ being determined by the difference between transformed cumulative probabilities of the distribution $P'$.
More specifically, following @tverskyAdvancesProspectTheory1992, the objective outcomes are transformed by a value function
$$
\begin{aligned}
  v : \Omega' &\to \mathbb{R} \\
  x &\mapsto 
  \begin{cases}
     x_i^\alpha &\forall x_i \geq 0, \\
     -\lambda |x_i|^\alpha &\text{else}
     \; ,
  \end{cases}
\end{aligned}
\tag{8}
$$
with $\alpha \in [0,1]$ determining the degree of the function's concavity (convexity) over the positive (negative) outcome interval, and $\lambda > 1$ increasing the function's slope over the negative outcome interval only.
Each subjective value $v(x)$ is then multiplied (or: weighted) with a cumulative decision weight that takes the form
$$
\pi_i =
  \begin{cases}
     w^+(P(X \geq x_i)) - w^+(P(X > x_i)) \quad \forall x_i \geq 0, \\
     w^-(P(X \leq x_i)) - w^-(P(X < x_i)) \quad \text{else}
     \; , 
  \end{cases}
\tag{9}
$$
where $w$ is a monotonic increasing, nonlinear weighting function $w: [0,1] \to [0,1]$ satisfying $w^+(0) = w^-(0) = 0$ and $w^+(1) = w^-(1) = 1$.

Essentially, the model is such that the cumulative decision weights derived for the outcomes may be greater or smaller than their objective probabilities, causing the transformed outcomes---i.e., the subjective values---to be over- or underweighted *in* CPT, respectively.
Accordingly, for the description of choices, one may adopt the as-if weighting terminology from the introduction by stating that people choose as if they maximized the value in (7) and applied the weighting pattern that was estimated in CPT.
Importantly, the as-if prefix indicates that it cannot be concluded from the estimated weighting pattern that the mind does indeed perform any of the computations associated with the weighting of subjective values in CPT; rather, the mind processes the information about the choice alternatives in a way that the resulting choices translate to the estimated weighting pattern.
The as-if weighting terminology is therefore reminiscent of the distinction between different levels of explanation [cf. @marrVisionComputationalInvestigation1982; @vanrooijTheoryTestHow2021].
That is, CPT may be considered a computational-level theory that specifies the computational problem the mind faces when being confronted with the choice between prospects, and how this problem may be solved by the abstract calculus of CPT.
However, as such, CPT cannot substitute algorithmic-level theories and process models that make claims about how exactly the mind transforms the inputs to the decision-making process into outputs which approximate the solutions of CPT [see @zilkerMeasuringModelingConstruction2020; see also @griffithsProbabilisticModelsCognition2010].
Respectively, this paper uses CPT as a mere data model to show how differences in the information-processing chain upfront choices in DfE---considered in the following section---may cause particular weighting patterns, among them the as-if underweighting of rare outcomes which has been found to be a robust behavioral phenomena in DfE.
To this end, the paper first continues to review the weighting patterns that can possibly estimated in CPT. 

Now, several consequences for the weighting pattern that can be estimated in CPT follow from (9):

* From the transformation of cumulative probabilities it follows that the value of a cumulative decision weight $\pi$ depends on the rank of the outcome $x$ for which $\pi$ is determined.

* The value of $\pi$ depends on the estimated shape of the graph of $w$ or the weighting function's parameters, respectively.
That is, the shape of the graph of $w$ displays over which interval on the cumulative probability scale $[0,1]$ the images of $w$ take values that are greater or smaller than the respective cumulative probabilities and how much greater or smaller these images are.
Hence, for a nonlinear graphical shape of $w$, the same numerical difference between objective cumulative probabilities may translate to cumulative decision weights of different value.

* For prospects containing either only positive or only negative outcomes, $\sum_i^n\pi_i = 1$ is satisfied.
Accordingly, for such prospects, the weighting of subjective values with cumulative decision weights rather than with objective probabilities may be roughly understood as a redistribution of the entire probability mass of $P(\Omega') = 1$ across outcomes [@zilkerNonlinearProbabilityWeighting2021].

\noindent
Given that the value of each cumulative decision weight depends on the two transformed cumulative probabilities in (9)---i.e., the probability of obtaining a positive (negative) outcome equal to or greater (smaller) than a respective outcome $x$, and the probability of obtaining a strictly greater (smaller) outcome---the remaining consequences for the weighting pattern are reviewed by considering the actual weighting function.
Therefore, Figure\ \@ref(fig:weighting-function) illustrates some of the possible graphical shapes of the two-parameter weighting function of @goldsteinExpressionTheoryPreference1987, which, however, is just one of several parameterizations that have been proposed [e.g., @prelecProbabilityWeightingFunction1998; @tverskyAdvancesProspectTheory1992; see @stottCumulativeProspectTheory2006, for an overview].
Now, let each $p$ on the abscissa be one of the four cumulative probabilities from (9). 
Then each graph in Figure\ \@ref(fig:weighting-function) displays the graphical shape of the weighting function
$$
\begin{aligned}
  w : [0,1] &\to [0,1] \\
  p &\mapsto \frac{\delta \times p^{\gamma}}
  {\delta \times p^{\gamma} + (1-p)^{\gamma}}
  \; ,
\end{aligned}
\tag{10}
$$
for the respective values of the parameters $\gamma \in [0,2]$ and $\delta > 0$.
Evidently, both parameters have distinct effects on the graphs' shape, with $\gamma$ affecting the curvature and $\delta$ the elevation.
As a consequence from (9) then, each combination of parameters implies a particular weighting pattern, with some of them being similar and others being rather distinct.

(ref:weighting-function) Possible Graphical Shapes of Goldstein and Einhorn's -@goldsteinExpressionTheoryPreference1987 Weighting Function

```{r weighting-function, fig.cap="(ref:weighting-function)", fig.height=7, fig.width=10}
#compute images of weighting function (wf)
wf <- tibble(p = seq(0, 1, .01)) %>%  #cumulative probabilities
  expand_grid(gamma = seq(.1, 2, .1), #gamma values
              delta = c(.1, .5, 1, 2, 5, 10)) %>% #delta values
  mutate(wp = (delta*(p^gamma))/((delta*p^gamma)+(1-p)^gamma)) #images of wf

#labeller function for facet labels with LateX math expressions 
label_delta <- function(string) {
  TeX(paste("$\\delta=$", string, sep = ""))  
}

#plot shapes of weighting function
wf %>% 
  ggplot(aes(p, wp, group = gamma)) +
  facet_wrap(~delta, labeller = as_labeller(label_delta, default = label_parsed)) + 
  scale_x_continuous(breaks = seq(0, 1, .2)) +
  scale_y_continuous(breaks = seq(0, 1, .2)) + 
  labs(x = expression(p),
       y = expression(w(p)), 
       color = expression(gamma)) + 
  theme_apa() + 
  geom_line(aes(color = gamma)) +
  scale_color_viridis(option = "viridis") + 
  geom_abline(intercept = 0, slope = 1, color = "gray", linetype = "dashed")
```

In some more detail, the gray-dashed identity lines in Figure\ \@ref(fig:weighting-function) imply a linear weighting pattern.
That is, since the images of $w$, $w(p)$, are equal to the respective cumulative probabilities $p$, all cumulative decision weights $\pi$ that are derived according to (9) would be equal to the differences between the respective objective cumulative probabilities and therefore also to the objective probabilities of the outcomes for which the weights are determined.
Such a linear weighting pattern is implied by $\gamma = 1$ and $\delta = 1$. 
Now, both deviations from $\gamma = 1$ and $\delta = 1$ produce a nonlinear graphical shape.
That is, for $\gamma > 1$, the graphs take a S-shape---running below (above) the identity line for small (large) cumulative probabilities---which is more accentuated for larger deviations from $\gamma = 1$.
Importantly, the same *small* numerical difference between two cumulative probabilities $p$ then translates to varying differences between the respective images $w(p)$ depending on the interval on the cumulative probability scale. 
Specifically, because of the S-shaped curvature, the differences between the images $w(p)$ may be smaller than those between the respective cumulative probabilities in the lower and upper part of the cumulative probability scale, but may be considerably greater in the middle part.
As a consequence, the cumulative decisions weights are smaller than the respective objective probabilities for small-probability outcomes of either a low rank or a high rank, but they are larger for small-probability outcomes of a middle rank.^[<!--Open footnote-->Note that the distinction between outcomes of either low/high rank or middle rank is unnecessary for two-outcome prospects [see @tverskyAdvancesProspectTheory1992]. However, for finite many outcomes, the distinction is critical. More so, the fact that CPT may weigh outcomes of the same small probability differently, adds another reasons why the description-experience gap should not be equated with a reversed weighting pattern in CPT [see @hertwigConstructBehaviorGap2018]. I.e., neither could the gap then be interpreted in terms of an as-if underweighting (overweighting) of rare outcomes in DfE (DfD), nor would any of the potential contributors to the gap considered so far [see, e.g., @hertwigDescriptionexperienceGapRisky2009; @wulffMetaanalyticReviewTwo2018] treat some small-probability outcomes differently than other small-probability outcomes.<!--Close footnote-->]
Note that for all $\gamma < 1$ the graph of $w$ takes an inverse S-shape and the entire weighting pattern is reversed.
Moreover, the shape of the weighting function, and thus the weighting pattern, depends strongly on $\delta$, which affects the overall elevation of the graph.
That is, for $\delta < 1$, the interval on the cumulative probability scale over which the weighting function runs below the identity line is greater than the interval over which the weighting function runs above the identity line; and this pattern reverses for $\delta > 1$.
More specifically, $\delta$ shifts across the entire cumulative probability scale the intervals within which small differences between objective cumulative probabilities translate to either smaller or greater cumulative decision weights.
In other words then, for any decrease (increase) in $\delta$, the underweighting of small probability outcomes extends to more outcomes at the lower (higher) end of the outcome range.

To summarize the preceding paragraphs, CPT is a statistical or data model that can be used to describe choices between prospects by capturing systematic deviations from EV maximization in the parameter estimates of its value and weighting function.
Importantly, each estimated weighting function implies a weighting pattern.
Although the possible weighting patterns depend on the exact parameterization of the weighting function [e.g., @goldsteinExpressionTheoryPreference1987], the latter's graph usually takes a more or less accentuated (inverse) S-shape, which implies a weighting pattern where small-probability outcomes of low and high rank are underweighted (overweighted) in CPT's overall evaluation of a prospect according to (7).
Notably, for the case of choices between at most two-outcome prospects, the weighting pattern reduces to either an underweighting or overweighting of rare outcomes.
For the description of such choices, one may then adopt the as-if weighting terminology from the introduction, by stating that people decide as if they were either underweighting or overweighting rare outcomes.

# Sampling Strategies in DfE

The need to distinguish between the computational and the algorithmic level in the domain of decision making is exemplified by the fact that information about prospects may come in the form of descriptions or sampled outcomes.
Specifically, only rarely in peoples' daily life, the inputs to the decision-making process take the form of explicit descriptions of all outcome-probability pairs.
In such cases, people would make DfD, since the information from which the mind learns about the properties of prospects are complete descriptions thereof.
Yet, rather often, people make DfE, where the mind can learn about the latent properties of prospects only by experiental sampling over time [@hertwigDescriptionexperienceGapRisky2009, p. 517].
Accordingly, for the choice between $1, ..., k$ prospects, the inputs to the decision-making process are generated by a set of prospect-specific stochastic processes
$$
\{\{X^1_t\}, ... , \{X^k_t\}\}
\; ,
\tag{11}
$$
where each $\{X_{t}\}_{t \in \mathbb N}$ is a collection of independent and identically distributed (i.i.d.) random variables.^[Note that it has been emphasized that in the natural world samples are "virtually never random" [@fiedlerBewareSamplesCognitiveecological2000, p. 660]. However, in the sampling paradigm, i.i.d. random variables are commonly assumed.]
The inputs to DfE are then the realizations of the random variables in (11), which require different algorithms to be processed than do descriptions of the outcomes and their probabilities in DfD.

## Accumulating Evidence About Differences in Latent Properties

Since it is only through their fundamental properties, or combinations thereof, that any distinction between the prospects can be made, systematic choices in DfE must be based on the assessment of differences in the latent properties of prospects.
Accordingly, the mind may use the sampled outcomes to first infer the latent objective probabilities of all possible outcomes, and then proceed by selecting a property, or combinations thereof, to assess differences among the prospects and make a respective choice.
However, the mind may also approximate such a process by using an algorithm that omits explicit inferences and directly accumulates evidence about the differences in latent properties from the sampled outcomes.
To this end, sequential sampling models of decision making [e.g., @busemeyerDecisionFieldTheory1993] assume that the outcomes of prospects are sequentially sampled and integrated into dynamic decision variables and that a choice is made once a decision variable exceeds a threshold in favor for one of the prospects.
This class of process models thereby provides an algorithmic link between the actual sampling process and the choices in DfE, and has shown to explain some of the robust deviations from EV maximization [see @busemeyerDecisionFieldTheory1993; @bhatiaSequentialSamplingParadoxes2014], including the underweighting of rare outcomes in the sampling paradigm [see @markantModelingChoiceSearch2015].
Moreover, these models implement speed-accuracy tradeoffs, with the amount of evidence that must be sampled in favor for a prospect increasing with thresholds, leading to more (less) accurate but slower (faster) choices for high (low) thresholds.

Yet, there are several distinct properties that can be used to assess differences among the prospects.
Specifically, the summary and the round-wise decision strategy---for which either the prospect is chosen that produced the greater mean across all sampled outcomes or the prospect that won more comparisons between single sampled outcomes, respectively [see @hillsInformationSearchDecisions2010]---can each be indicative for differences in a distinct latent property.
That is, for a large number of sampled outcomes, the summary strategy is indicative for differences in the latent EV as the mean of a large collection of i.i.d. random variables converges to the EV of the respective random variable.
In turn, the round-wise strategy is indicative for differences in the likelihood to produce a higher outcome than the other prospect.
Respectively, in the following section, the summary and the round-wise strategy are implemented into a common accumulation model that shows how the mind may accumulate evidence for differences in distinct latent properties [see also @bhatiaChoiceRulesAccumulator2017, where heuristic choice rules are integrated into an accumulation model].
More specifically, the proposed model accumulates the outcomes obtained from a sequence of comparisons between sample means, with the size of the samples underlying each mean comparison tending to be small (large) for high (low) switching probabilities.
Accordingly, whereas the decision variables of the model capture how much (more) comparisons between sample means a prospect has won, the unfolding accumulation process more closely resembles the round-wise strategy for high switching probabilities and the summary strategy for low switching probabilities.
Hence, the model also shows how the mind may rely on different sampling strategies to alter which differences in the latent properties of prospects evidence is accumulated for.

## Model 

We consider the sampling paradigm and a choice between two prospects denoting the distributions $P'^X$ and $P'^Y$ of the discrete random variables $X$ and $Y$, respectively.
The model assumes that the information-processing chain starts at random with a stochastic process on one of the two random variables.
Specifically, it is assumed that an agent starts with equal probability to sample from one of the prospects, say $P'^X$, and generates a sequence of random variables $X_1, X_2,...$, where the mean over the sequence is computed or updated with each new outcome that is sampled.
The respective stochastic process $\{S^X_n\}_{n \in \mathbb{N}}$ is defined by
$$
S^X_n = \frac{1}{n} \sum_{t = 1}^n X_t, \quad n \in \mathbb{N}
\; ,
\tag{12}
$$
and terminates as soon as an outcome is sampled from the other prospect.
The switching probability $\psi \in (0,1]$, which is assumed to be adopted prior the start of the information-processing chain and to be fixed throughout, controls the probability with which outcomes from different prospects are sampled in direct succession.
In other words, the switching probability is the probability with which the stochastic process on the current random variable stops and a new stochastic process on the other random variable starts with the subsequently sampled outcome.
To implement an evidence accumulation process, the model assumes that each time after a new stochastic process was started and terminated on both random variables, their respective values---i.e., the means over the sequences---are compared, with the prospect underlying the stochastic process with the greater final value receiving a round win.
Accordingly, for the prospect $P'^X$, this stage is modeled as the mapping
$$
\begin{aligned}
  Z^X : \mathbb{R} &\to \mathbb{N} \\
  S^X_n - S^Y_n &\mapsto 
  \begin{cases}
     1 &\text{if} \quad  S^X_n > S^Y_n, \\
     0 &\text{else}
     \; ,
  \end{cases}
\end{aligned}
\tag{13}
$$
where $Z^X$ is a random variable that takes only the two values $0$ and $1$, denoting a lost or won mean comparison, respectively. 
The model assumes that a round consisting of a pair of stochastic processes---i.e., one for each prospect---and the subsequent comparison of their final values is repeated until the sum of round wins for one of the two prospects reaches a threshold $\theta \in \mathbb{N}$.
Similar to the switching probability, it is assumed that the threshold is adopted prior the start of the information-processing chain and is fixed throughout.
For $P'^X$, then, we obtain a sequence of independent comparisons $Z^X_1, Z^X_2, ...$ and model the respective evidence accumulation process as a random walk $\{D^X_m\}_{m \in \mathbb{N}}$ defined by 
$$
D^X_m = \sum_{i = 1}^m Z^X_i, \quad m \in \mathbb{N}
\;,
\tag{14}
$$
resembling a dynamic decision variable.
Note that since (13) describes a Bernoulli trial, the random walk in (14) is based on a Bernoulli process.

Finally, note that the described model assumes two random walks---i.e., one for each prospect---approaching the same threshold, which is the absolute number of mean comparisons a prospect must win in order to be chosen.
However, one may also define a single random walk, resembling a common dynamic decision variable, which approaches a positive threshold $\theta^+$ and a negative threshold $\theta^-$.
Therefore, (13) may be adapted such that $Z$ takes the value $-1$ instead of $0$, such that the threshold determines how many more mean comparisons a prospect must win in order to be chosen.

### Model Predictions

Below, the key predictions concerning the effects of the model parameters---i.e., the switching probability $\psi$ and the threshold $\theta$---on the length of the information-processing chain and the final choice are outlined.
Moreover, previous research has shown that differences as to how information about the properties of prospects is processed can translate to characteristic shapes of CPT's value and weighting function [see @pachurHowTwainCan2017; @zilkerNonlinearProbabilityWeighting2021].
Respectively, this section also contains predictions about the potential relations between $\psi$ and $\theta$ and the CPT parameters.

#### Length of Information-Processing Chain

The model predicts the overall number of sampled outcomes to increase with thresholds.
Specifically, the required number of independent mean comparisons increases with thresholds.
Then, since each comparison is based on its own pair of stochastic processes, an increase in thresholds translates to a larger number of required stochastic processes and, ceteris paribus, therefore also to a larger overall number of sampled outcomes.
In turn, the model predicts the overall number of sampled outcomes to decrease with increasing switching probabilities.
Specifically, each stochastic process is predicted to terminate faster, the higher the probability that the subsequent outcome is sampled from the other prospect---i.e., the switching probability.
Accordingly, an increase in the switching probability leads to shorter stochastic processes which translates, ceteris paribus, to a smaller overall number of sampled outcomes.

#### Final Choice

Note first that the thresholds and switching probabilities alter the degree to which the accumulation process resembles the summary or the round-wise strategy.
That is, for low thresholds and switching probabilities, only a few mean comparisons based on pairs of long stochastic processes---i.e., large samples---are carried out, thereby resembling the summary strategy.
Accordingly, for such parameter combinations, the model predicts the prospect to be chosen that possesses the larger EV.
In turn, for high thresholds and switching probabilities, many mean comparisons based on pairs of short stochastic process---i.e., small samples---are carried out, thereby resembling the round-wise strategy.
Accordingly, for such parameter combinations, the model predicts the prospect to be chosen that is more likely to return a higher outcome.
Yet, if the prospect that is more likely to return a higher outcome does not possess the higher EV, the parameter combinations resembling the round-wise strategy are predicted to cause a deviation from the solutions of EV maximization.

Now, more specifically, because the switching probability is predicted to alter the length of the stochastic processes underlying each mean comparison, the switching probability should affect whether low-probability outcomes contribute to the majority of the required mean comparisons about as much as would be warranted based on their objective probabilities, or whether they contribute rather less.
That is, for short stochastic processes, the binomial distribution associated with small-probability outcomes is positive skewed, therefore causing the relative frequencies with which these outcomes occur over the course of such a process to be smaller rather than larger than their latent objective probabilities.
Respectively, if the small-probability outcome is smaller (larger) than the EV, high switching probabilities---and therefore pairs of short stochastic processes---cause the mean to be an inflated (deflated) estimate of the EV.
Such an inflation and deflation of the means for high switching probabilities can then translate to an as-if underweighting of rare outcomes.
Specifically, if the mean of the prospect with the lower (higher) EV is inflated (deflated), the outcome of the comparison between the means may be a reversal---in sign---of the outcome of a comparison between the EVs, leading to choices that take the form of an as-if underweighting of rare outcomes.
Yet, if the mean of the prospect with the lower (higher) EV is deflated (inflated), the difference between the means is an amplification of the differences between the EV, which can actually simplify EV maximization [@hertwigDecisionsExperienceWhy2010]. 
In turn, low switching probabilities---and therefore pairs of long stochastic processes---cause the mean to closely correspond to the EV, leading to choices that are in line with EV maximization.

Finally, because each comparison’s contribution to the accumulated evidence is weighted equally, the predictions made for given switching probabilities should become more robust as the thresholds and therefore the number of independent comparisons increases.
That is, the thresholds implement a speed-accuracy trade-off of the form that whatever systematic differences in the latent properties of prospects may be represented in a sequence of mean comparisons, should be more accurately assessed as the thresholds increase.
Accordingly, the as-if underweighting of rare outcomes that is predicted to occur for high switching probabilities should remain and become more pronounced the higher the thresholds are.
Thus, the model's predictions should substantiate the claim made at the outset of the paper, namely, that the reliance on multiple or many small samples---in the form of comparisons between pairs of short stochastic processes---can cause an as-if underweighting of rare outcomes while fully accounting for a large number of sampled outcomes.

#### Cumulative Prospect Theory

To elaborate how the differences in the predictions made for the model parameters may be described in CPT's parameters, the value function of Tversky and Kahneman [-@tverskyAdvancesProspectTheory1992, see (8)] and the weighting function of Goldstein and Einhorn [-@goldsteinExpressionTheoryPreference1987, see (10)] are used.
To simplify matters, the further discussion and the computational analysis are constrained to choices between a safe prospect---possessing just one outcome that occurs with certainty---and a two-outcome risky prospect.
All outcomes are assumed to be positive and the safe outcome is assumed to fall between the the low-rank outcome, $x_{low}$, and the high-rank outcome, $x_{high}$, of the risky prospect in order to omit dominant prospects that always lead to a higher outcome than the respective other prospect.

Now, since for low switching probabilities the model tends to choose the prospect possessing the larger EV, the parameters of the value and weighting function are predicted to correspond to a linear weighting of outcomes and probabilities.
Thus, the lower the switching probabilities, the more should the choices translate to parameter estimates that satisfy $\alpha = 1$, $\gamma = 1$, and $\delta = 1$.
However, for high switching probabilities, the model predicts systematic deviations from the solutions of EV maximization, which take the form of an as-if underweighting of rare outcomes:
More specifically, for $\psi = 1$, the model tends to choose the risky prospect, if the probability of its high-rank outcome satisfies $p_x(x_{high}) > .5$, irrespective of its EV.
Vice versa, the model tends to choose the safe outcome, if $p_x(x_{high}) < .5$ is satisfied.
Accordingly, for high switching probabilities, the weighting pattern should be such that the high-rank outcome is overweighted for $p_x(x_{high}) > .5$ and otherwise underweighted.
Note now that the possible weighting patterns for choices between at most two-outcome prospects readily reduces to an over- or underweighting of the high-rank outcome [@zilkerNonlinearProbabilityWeighting2021]:
$$
\begin{aligned}
  \pi_{high} &= w(p_x(x_{high})) \\
  \pi_{low} &= w(p_x(x_{low}) + p_x(x_{high})) - w(p_x(x_{high})) \\
  &= 1 - \pi_{high}
  \; .
\end{aligned}
\tag{15}
$$
That is, the images of the weighting function equal the decision weights assigned to the high-rank outcome of the risky prospect.
Hence, for high switching probabilities, the graph of the weighting function is predicted to run below the identity line for $p_x(x_{high}) < .5$---leading to an underweighting of small-probability outcomes---and above the identity line for $p_x(x_{high}) > .5$---leading to an overweighting of high-probability outcomes.
Accordingly, the graph of the weighting function should take a S-shape, which is given by $\gamma > 1$ and $\delta = 1$.
Yet, since the model tends to approximate the solutions of EV maximization the lower the switching probabilities are, the S-shape should be most pronounced for high switching probabilities.
Thus, $\gamma$ should increase with $\psi$.
Note further that the predicted shape of the weighting function for high switching probabilities reflects the round-wise strategy's sensitivity to differences in the outcome's probabilities.
That is, the slope of the weighting function increases around the midpoint of the probability scale and flattens to both ends.
reflecting that the round-wise strategy is more sensitive to the differences in the 
Accordingly, the round-wise strategy 

Finally, an increase in the switching probability should lead to a more concave value function.
Similar to the slope of the weighting function, 

```{r}
predictions <- tibble("CPT parameter" = 
                        c("$\\gamma$",
                          "$\\delta$",
                          "$\\alpha$"),
                      "Predictions for changes in $\\psi$" = 
                        c("$\\geq 1$, increases with $\\psi$",
                          "1, no effect of $\\psi$",
                          "$\\leq 1$, decreases with increasing $\\psi$"))
apa_table(predictions, caption = "Model Predictions", note = "The prediction for changes in $\\psi$ should become more robust for increasing values of $\\theta$.", escape = FALSE)
```

# Simulation Study

Below

## Method

### Choice Problems

The test set of $60$ choice problems, each consisting of a safe prospect and a two-outcome prospect, was obtained by stratified sampling from an initial set of $10,000$ choice problems.
The stratification was used to assure that some of the choice problems contain a small (high) outcome of a probability smaller than $.20$.
The exact procedure was as follows:
For each of the $10.000$ problems in the initial set, three outcomes were randomly drawn from a uniform distribution over the interval $[0, 20]$, with the smallest and highest of these three outcomes being assigned to the risky prospect in order to omit the case of dominant prospects.
The probability for the smaller outcome of the risky prospect, $p_{small}$, was drawn from a uniform distribution over the interval $[.01, .99]$, with the probability of the higher outcome being set to $p_{high} = 1-p_{small}$.
To obtain the $60$ choice problems of the test set, the initial set was divided into three subsets, where each subset contained either all problems with $p_{high} \in (0,.2)$ or $p_{high} \in [.2,.8]$ or $p_{high} \in (.8,1)$.
From each of these subset, then, $20$ choice problems were randomly sampled.

### Data Generation

The evidence accumulation model presented in this paper was implemented as a computational model to simulate the sampling process and the final choice for each of the $60$ choice problems in the test set.
All of the following parameter values were combined with each other:

* **Switching probability**: 
The switching probability $s$, defined as the probability of sampling outcomes from different prospects in direct succession, was varied in the interval $[.1, 1]$ in increments of $.1$.

* **Decision variable**: The decision variable of a prospect either counts the absolute number of won comparisons or how much more comparisons were won relative to the other prospect.

* **Threshold**: 
The value of the threshold $\theta$, determining how much (more) comparisons a prospect must win, was varied in the interval $[1,5]$ in increments of 1. 

\noindent
In sum, 100 (parameter combinations) x 60 (choices) x 100 (agents) = 600,000 sampling processes and choices were simulated. 

### Modeling

## Results

```{r data, include=FALSE}
#load choice data
cols_choices <- list(.default = col_double(),
                     boundary = col_factor(),
                     gamble = col_factor(),
                     rare = col_factor(),
                     agent = col_factor(),
                     choice = col_factor())
choices <- read_csv("data/choices/choices.csv", col_types = cols_choices)

#load CPT estimates
cols_cpt <- list(.default = col_double(),
                 boundary = col_factor(),
                 a = col_factor(),
                 parameter = col_factor())
cpt <- read_csv("data/estimates/estimates_cpt.csv", col_types = cols_cpt)
```

<!-- Plots choice rates -->

(ref:choice-rates) Effect of Switching Probability on Rates of False Risky and False Safe Choices for 2-Outcome Prospects with High Rank Outcomes of Different Probability

```{r choice-rates, fig.cap="(ref:choice-rates)", fig.height=7, fig.width=10}
#prepare data

##determine normative choice according to latent and sampled EV
fr_rates <- choices %>%
  mutate(norm = case_when(ev_ratio > 1 ~ "A", ev_ratio < 1 ~ "B"), #normative choice latent EV
         ev_ratio_exp = round(a_ev_exp/b_ev_exp, 2),
         norm_exp = case_when(ev_ratio_exp > 1 ~ "A", ev_ratio_exp < 1 ~ "B")) #normative choice sampled EV

##compute false response rates  

###latent EV
fr_rates_l <- fr_rates %>%
  filter(!is.na(norm)) %>% #exclude trials with equal EV
  group_by(s, boundary, a, rare, norm, choice) %>% #separate by model parameter and type of rare event
  summarise(n = n()) %>%
  mutate(rate = round(n/sum(n), 2), #compute response rates
         type = case_when(norm == "A" & choice == "B" ~ "Safe", #determine false response type
                          norm == "B" & choice == "A" ~ "Risky")) %>%
  ungroup() %>%
  filter(!is.na(type)) %>% #remove correct responses
  select(-c(norm, choice, n)) %>%
  mutate(norm_ev = "Latent") #assign facet label

###sampled EV
fr_rates_s <- fr_rates %>%
  filter(!is.na(norm_exp)) %>%
  group_by(s, boundary, a, rare, norm_exp, choice) %>%
  summarise(n = n()) %>%
  mutate(rate = round(n/sum(n), 2),
         type = case_when(norm_exp == "A" & choice == "B" ~ "Safe",
                          norm_exp == "B" & choice == "A" ~ "Risky")) %>%
  ungroup() %>%
  filter(!is.na(type)) %>%
  select(-c(norm_exp, choice, n)) %>%
  mutate(norm_ev = "Sample")

### merge latent and sampled data
fr_rates <- bind_rows(fr_rates_l, fr_rates_s) %>%
  mutate(rare = case_when(rare == "none" ~ "\\in \\[.2,.8\\]", #change facet labels for rare events
                          rare == "attractive" ~ "\\in (0,.2)",
                          rare == "unattractive" ~ "\\in (.8,1)"))

# labeller functions
label_theta <- function(string) {
  TeX(paste("$\\theta=$", string, sep = "")) #threshold parameter theta
}

label_rare <- function(string) {
  TeX(paste("$\\p_{High}$", string, sep = "")) #type of rare event
}

#plot
fr_rates %>%
  ggplot(aes(s, rate)) +
  facet_grid(rare~a, labeller = labeller(rare = as_labeller(label_rare, default = label_parsed), 
                                         a = as_labeller(label_theta, default = label_parsed))) +
  labs(x = "Switching Probability",
       y = "False Response Rate",
       color = "Normative\nExpected\nValue",
       shape = "False\nResponse\nType") +
  scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1, .5)) +
  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, .5)) +
  geom_point(aes(color = norm_ev, shape = type)) +
  scale_shape_manual(values = c(4, 16)) +
  scale_color_viridis_d(option = "viridis", begin = .1, end = .7) +
  theme_apa()
```

<!-- Plots CPT -->

(ref:weighting-parameters) Parameter Estimates of the Weighting Function of @goldsteinExpressionTheoryPreference1987 for Different Simulation Parameters

```{r weighting-parameters, fig.cap="(ref:weighting-parameters)", fig.height=7, fig.width=10}
#prepare data
cpt <- cpt %>% mutate(boundary = if_else(boundary == "absolute", "Absolute", "Relative"))

#plot estimates

##gamma
gamma <- cpt %>%
  filter(parameter == "gamma") %>%
  ggplot(aes(s, mean, color = s, shape = boundary)) +
  facet_wrap(~a, nrow = 1, labeller = labeller(a = as_labeller(label_theta, default = label_parsed))) +
  labs(x = element_blank(), #omit axis title
       y = expression(gamma),
       color = "Switching\nProbability",
       shape = "Boundary") +
  scale_x_continuous(limits = c(0, 1), breaks = seq(0,1,.5)) +
  geom_point() +
  geom_pointrange(aes(ymin=`2.5%`, ymax=`97.5%`)) + 
  scale_shape_manual(values = c(4, 16)) +
  scale_color_viridis(option = "viridis") +
  theme_apa() 

##delta
delta <- cpt %>%
  filter(parameter == "delta") %>% 
  ggplot(aes(s, mean, color = s, shape = boundary)) +
  facet_wrap(~a, nrow = 1) + 
  labs(x = "Switching Probability",
       y = expression(delta),
       color = "Switching\nProbability",
       shape = "Boundary") +
  scale_x_continuous(limits = c(0, 1), breaks = seq(0,1,.5)) +
  geom_point() +
  geom_pointrange(aes(ymin=`2.5%`, ymax=`97.5%`)) + 
  scale_color_viridis(option = "viridis") +
  scale_shape_manual(values = c(4, 16)) +
  theme_apa() + 
  theme(strip.text.x = element_blank()) #omit facet labels

##merge figures
ggarrange(gamma, delta, ncol = 1, nrow = 2, common.legend = TRUE, legend = "right", labels = "AUTO") 
```

(ref:value-parameters) Parameter Estimates of the Value Function of @tverskyAdvancesProspectTheory1992 and of the Logit Choice Rule for Different Simulation Parameters

```{r value-parameters, fig.cap="(ref:value-parameters)", fig.height=7, fig.width=10}
#plot estimates

##alpha
alpha <- cpt %>%
  filter(parameter == "alpha") %>% 
  ggplot(aes(s, mean, color = s, shape = boundary)) +
  facet_wrap(~a, nrow = 1, labeller = labeller(a = as_labeller(label_theta, default = label_parsed))) +
  labs(x = element_blank(),
       y = expression(alpha),
       color = "Switching\nProbability",
       shape = "Boundary") +
  scale_x_continuous(limits = c(0, 1), breaks = seq(0,1,.5)) +
  geom_point() +
  geom_pointrange(aes(ymin=`2.5%`, ymax=`97.5%`)) + 
  scale_color_viridis(option = "viridis") +
  scale_shape_manual(values = c(4, 16)) +
  theme_apa()

##rho
rho <- cpt %>%
  filter(parameter == "rho") %>% 
  ggplot(aes(s, mean, color = s, shape = boundary)) +
  facet_wrap(~a, nrow = 1) + 
  labs(x = "Switching Probability",
       y = expression(rho),
       color = "Switching\nProbability",
       shape = "Boundary") +
  scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1,.5)) +
  geom_point() +
  geom_pointrange(aes(ymin=`2.5%`, ymax=`97.5%`)) + 
  scale_color_viridis(option = "viridis") +
  scale_shape_manual(values = c(4, 16)) +
  theme_apa() + 
  theme(strip.text.x = element_blank())

##merge figure
ggarrange(alpha, rho, ncol = 1, nrow = 2, common.legend = TRUE, legend = "right", labels = "AUTO") 
```

(ref:cpt-graphs) Estimated Graphical Shapes of the Weighting and Value Function for Different Simulation Parameters

```{r cpt-graphs, fig.cap="(ref:cpt-graphs)", fig.height=7, fig.width=10}
#prepare data

##compute images of weighting and value function

###weighting function
wf <- cpt %>%
  select(s, boundary, a, parameter, mean) %>%
  pivot_wider(names_from = parameter, values_from = mean) %>%
  select(-c(alpha, rho)) %>%
  expand_grid(p = seq(0, 1, .05)) %>%
  mutate(w = round(  (delta * p^gamma)/ ((delta * p^gamma)+(1-p)^gamma), 2))

###value function
vf <- cpt %>%
  select(s, boundary, a, parameter, mean) %>%
  pivot_wider(names_from = parameter, values_from = mean) %>%
  select(-c(gamma, delta, rho)) %>%
  expand_grid(x = seq(0, 20, .5)) %>%  
  mutate(v = round(x^alpha, 2)) 

##split data to avoid passing two y-values to the same x-value in geom_line()
wf_a <- wf %>% filter(boundary == "Absolute")
wf_r <- wf %>% filter(boundary == "Relative")
vf_a <- vf %>% filter(boundary == "Absolute")
vf_r <- vf %>% filter(boundary == "Relative")

#plots 

##weighting function
weight <- wf_a %>% #graphs for absolute boundary
  ggplot(aes(p, w, group = s, color = s)) +
  facet_wrap(~a, nrow = 1, labeller = labeller(a = as_labeller(label_theta, default = label_parsed))) + 
  labs(x = "Experienced Probability",
       y = "Decision Weight",
       color = "Switching\nProbability") +
  scale_x_continuous(breaks = seq(0, 1, .5)) +
  scale_y_continuous(breaks = seq(0, 1, .5)) +
  geom_line(size = .5) +
  geom_line(data = wf_r, size = .5) +  #add curves for relative boundary
  scale_color_viridis(option = "viridis") +
  theme_apa()

##value function
value <- vf_a %>% 
  ggplot(aes(x, v, group = s, color = s)) +
  facet_wrap(~a, nrow = 1)+ 
  labs(x = "Objective Outcome",
       y = "Subjective Value",
       color="Switching\nProbability") +
  scale_x_continuous(breaks = seq(0, 20, 10)) +
  scale_y_continuous(breaks = seq(0, 20, 10)) +
  geom_line(size = .5) +
  geom_line(data = vf_r, size = .5) + 
  scale_color_viridis(option = "viridis") +
  theme_apa() + 
  theme(strip.text.x = element_blank())

##merge figures
ggarrange(weight, value, ncol = 1, nrow = 2, common.legend = TRUE, legend = "right", labels = "AUTO") 
```

For each distinct parameter combination, we ran 20 chains of 40,000 iterations each, after a warm-up period of 1000 samples.
To reduce potential autocorrelation during the sampling process, we only kept every 20th sample (thinning).
The potential scale reduction factor $\hat{R}$ [@gelmanInferenceIterativeSimulation1992] was $\leq$ `r round(max(cpt$Rhat), 3)` for all parameters, indicating good convergence.
The minimum effective sample size was `r min(cpt$n.eff)`.

As expected, the scatter plot below shows an inverse relationship between switching probability and trial length.
I.e., the lower the switching probability, the larger become the sample sequences on which each comparison between prospects is based, which in turn leads to longer trials.  
This effect is particularly pronounced for low probabilities such that the increase in trial length accelerates as switching probability decreases.


The figures below display the estimates of the $\gamma$ and $\delta$ parameter of the probability weighting function [@prelecProbabilityWeightingFunction1998] fitted to DfE simulated for different parameter values of the generating model.
The estimates are plotted against the switching probability, where each panel represents a distinct boundary type and level, i.e., number of comparisons. 
Grey dots represent agent level estimates, colored dots represent the mean across all agent level estimates. 

Most significantly, there is a strong relationship between the switching probability in the generating model and the $\gamma$ parameter.
I.e., large switching probabilities, which are indicative for small sample sequences, lead to larger estimates for $\gamma$. 
The resulting strong curvature leads to a compression of probabilities in the lower and upper range, reflecting underweighting of small probabilities and overweighting of large probabilities. 
This pattern is robust for varying degrees of the boundary level, except for $a = 1$. 
The latter deviation may be explained by the potential scale reduction factors for the respective parameter estimates, which indicate that the MCMC chains did not converge (see [Appendix 3][Appendix 3: Convergence Diagnostics for CPT Parameters]).   

<!-- Plots Appendix -->

```{r A-data, include=FALSE}
#load choice data
choices_c <- read_csv("data/choices/choices_comprehensive.csv", col_types = cols_choices)
cpt_c <- read_csv("data/estimates/estimates_cpt_comprehensive.csv", col_types = cols_cpt)
```

```{r A-choice-rates, fig.height=7, fig.width=10, include=FALSE}
#prepare data
fr_rates_c <- choices_c %>%
  mutate(norm = case_when(ev_ratio > 1 ~ "A", ev_ratio < 1 ~ "B"),
         ev_ratio_exp = round(a_ev_exp/b_ev_exp, 2),
         norm_exp = case_when(ev_ratio_exp > 1 ~ "A", ev_ratio_exp < 1 ~ "B"))

fr_rates_c_l <- fr_rates_c %>%
  filter(!is.na(norm)) %>%
  group_by(s, boundary, a, rare, norm, choice) %>% 
  summarise(n = n()) %>%
  mutate(rate = round(n/sum(n), 2),
         type = case_when(norm == "A" & choice == "B" ~ "Safe",
                          norm == "B" & choice == "A" ~ "Risky")) %>%
  ungroup() %>%
  filter(!is.na(type)) %>%
  select(-c(norm, choice, n)) %>%
  mutate(norm_ev = "Latent")

fr_rates_c_s <- fr_rates_c %>%
  filter(!is.na(norm_exp)) %>%
  group_by(s, boundary, a, rare, norm_exp, choice) %>%
  summarise(n = n()) %>%
  mutate(rate = round(n/sum(n), 2),
         type = case_when(norm_exp == "A" & choice == "B" ~ "Safe",
                          norm_exp == "B" & choice == "A" ~ "Risky")) %>%
  ungroup() %>%
  filter(!is.na(type)) %>%
  select(-c(norm_exp, choice, n)) %>%
  mutate(norm_ev = "Sample")

fr_rates_c <- bind_rows(fr_rates_c_l, fr_rates_c_s) %>%
  mutate(rare = case_when(rare == "none" ~ "\\in \\[.2,.8\\]",
                          rare == "attractive" ~ "\\in (0,.2)",
                          rare == "unattractive" ~ "\\in (.8,1)"))

fr_rates_c %>%
  ggplot(aes(s, rate)) +
  facet_grid(rare~a, labeller = labeller(rare = as_labeller(label_rare, default = label_parsed), 
                                         a = as_labeller(label_theta, default = label_parsed))) +
  labs(x = "Switching Probability",
       y = "False Response Rate",
       color = "Normative\nExpected\nValue",
       shape = "False\nResponse\nType") +
  scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1, .5)) +
  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, .5)) +
  geom_point(aes(color = norm_ev, shape = type)) +
  scale_shape_manual(values = c(4, 16)) +
  scale_color_viridis_d(option = "plasma", end = .7) +
  theme_apa()
```

```{r A-weighting-parameters, fig.height=7, fig.width=10, include=FALSE}
#prepare data
cpt_c <- cpt_c %>% mutate(boundary = if_else(boundary == "absolute", "Absolute", "Relative"))

#plot estimates

##gamma
gamma_c <- cpt_c %>%
  filter(parameter == "gamma") %>%
  ggplot(aes(s, mean, color = s, shape = boundary)) +
  facet_wrap(~a, nrow = 1, labeller = labeller(a = as_labeller(label_theta, default = label_parsed))) +
  labs(x = element_blank(),
       y = expression(gamma),
       color = "Switching\nProbability",
       shape = "Boundary") +
  scale_x_continuous(limits = c(0, 1), breaks = seq(0,1,.5)) +
  geom_point() +
  geom_pointrange(aes(ymin=`2.5%`, ymax=`97.5%`)) + 
  scale_shape_manual(values = c(4, 16)) +
  scale_color_viridis(option = "plasma") +
  theme_apa() 

##delta
delta_c <- cpt_c %>%
  filter(parameter == "delta") %>% 
  ggplot(aes(s, mean, color = s, shape = boundary)) +
  facet_wrap(~a, nrow = 1) + 
  labs(x = "Switching Probability",
       y = expression(delta),
       color = "Switching\nProbability",
       shape = "Boundary") +
  scale_x_continuous(limits = c(0, 1), breaks = seq(0,1,.5)) +
  geom_point() +
  geom_pointrange(aes(ymin=`2.5%`, ymax=`97.5%`)) + 
  scale_color_viridis(option = "plasma") +
  scale_shape_manual(values = c(4, 16)) +
  theme_apa() + 
  theme(strip.text.x = element_blank()) #omit facet labels

##merge figures
ggarrange(gamma_c, delta_c, ncol = 1, nrow = 2, common.legend = TRUE, legend = "right", labels = "AUTO") 
```

```{r A-value-parameters, fig.height=7, fig.width=10, include=FALSE}
#plot estimates

##alpha
alpha_c <- cpt_c %>%
  filter(parameter == "alpha") %>% 
  ggplot(aes(s, mean, color = s, shape = boundary)) +
  facet_wrap(~a, nrow = 1, labeller = labeller(a = as_labeller(label_theta, default = label_parsed))) +
  labs(x = element_blank(),
       y = expression(alpha),
       color = "Switching\nProbability",
       shape = "Boundary") +
  scale_x_continuous(limits = c(0, 1), breaks = seq(0,1,.5)) +
  geom_point() +
  geom_pointrange(aes(ymin=`2.5%`, ymax=`97.5%`)) + 
  scale_color_viridis(option = "plasma") +
  scale_shape_manual(values = c(4, 16)) +
  theme_apa()

##rho
rho_c <- cpt_c %>%
  filter(parameter == "rho") %>% 
  ggplot(aes(s, mean, color = s, shape = boundary)) +
  facet_wrap(~a, nrow = 1) + 
  labs(x = "Switching Probability",
       y = expression(rho),
       color = "Switching\nProbability",
       shape = "Boundary") +
  scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1,.5)) +
  geom_point() +
  geom_pointrange(aes(ymin=`2.5%`, ymax=`97.5%`)) + 
  scale_color_viridis(option = "plasma") +
  scale_shape_manual(values = c(4, 16)) +
  theme_apa() + 
  theme(strip.text.x = element_blank())

##merge figure
ggarrange(alpha_c, rho_c, ncol = 1, nrow = 2, common.legend = TRUE, legend = "right", labels = "AUTO") 
```

```{r A-cpt-graphs, fig.height=7, fig.width=10, include=FALSE}
#prepare data

##compute images of weighting and value function

###weighting function
wf_c <- cpt_c %>%
  select(s, boundary, a, parameter, mean) %>%
  pivot_wider(names_from = parameter, values_from = mean) %>%
  select(-c(alpha, rho)) %>%
  expand_grid(p = seq(0, 1, .05)) %>%
  mutate(w = round(  (delta * p^gamma)/ ((delta * p^gamma)+(1-p)^gamma), 2))

###value function
vf_c <- cpt_c %>%
  select(s, boundary, a, parameter, mean) %>%
  pivot_wider(names_from = parameter, values_from = mean) %>%
  select(-c(gamma, delta, rho)) %>%
  expand_grid(x = seq(0, 20, .5)) %>%  
  mutate(v = round(x^alpha, 2)) 

##split data to avoid passing two y-values to the same x-value in geom_line()
wf_c_a <- wf_c %>% filter(boundary == "Absolute")
wf_c_r <- wf_c %>% filter(boundary == "Relative")
vf_c_a <- vf_c %>% filter(boundary == "Absolute")
vf_c_r <- vf_c %>% filter(boundary == "Relative")

#plots 

##weighting function
weight_c <- wf_c_a %>% 
  ggplot(aes(p, w, group = s, color = s)) +
  facet_wrap(~a, nrow = 1, labeller = labeller(a = as_labeller(label_theta, default = label_parsed))) + 
  labs(x = "Experienced Probability",
       y = "Decision Weight",
       color = "Switching\nProbability") +
  scale_x_continuous(breaks = seq(0, 1, .5)) +
  scale_y_continuous(breaks = seq(0, 1, .5)) +
  geom_line(size = .5) +
  geom_line(data = wf_c_r, size = .5) + 
  scale_color_viridis(option = "plasma") +
  theme_apa()

##value function
value_c <- vf_c_a %>% 
  ggplot(aes(x, v, group = s, color = s)) +
  facet_wrap(~a, nrow = 1)+ 
  labs(x = "Objective Outcome",
       y = "Subjective Value",
       color="Switching\nProbability") +
  scale_x_continuous(breaks = seq(0, 20, 10)) +
  scale_y_continuous(breaks = seq(0, 20, 10)) +
  geom_line(size = .5) +
  geom_line(data = vf_c_r, size = .5) + 
  scale_color_viridis(option = "plasma") +
  theme_apa() + 
  theme(strip.text.x = element_blank())

##merge figures
ggarrange(weight_c, value_c, ncol = 1, nrow = 2, common.legend = TRUE, legend = "right", labels = "AUTO") 
```

# Summary and Conclusion

\newpage

# References
