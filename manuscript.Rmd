---
title             : "Sampling Strategies in Decisions from Experience: Property Representation and Probability Weighting Approximation"
shorttitle        : "Sampling strategies"

author: 
  - name          : "Linus Hof"
    affiliation   : "1"
    corresponding : yes    
    address       : "Department of Psychology, Heidelberg University, Hauptstra√üe 47-51, 69117 Heidelberg, Germany"
    email         : "linushof@posteo.de"
    
affiliation:
  - id            : "1"
    institution   : "Heidelberg University"

note: | 
  **Unsubmitted draft created from the commit with the hash**: ``r repro::current_hash()``
  
authornote: |
 This is a dynamic document which can be reproduced from the accompanying GitHub repository: https://github.com/linushof/sampling-in-dfe. 
 
 The current version of this manuscript is prepared for submission as a master's thesis.
 Supervisors: Thorsten Pachur & Veronika Zilker.   
 
abstract: |
  Add short abstract.
  
keywords          : ""
wordcount         : ""

bibliography      : ["references_sampling-in-dfe.bib"]
csl               : apa.csl

figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : no
linkcolor         : "blue"
mask              : no
draft             : no

classoption       : "man"
documentclass     : "apa7"
output            : papaja::apa6_pdf

header-includes:
   - \usepackage[capposition=top]{floatrow}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = F, fig.pos = "t", fig.align = "l")
```

```{r packages}
# load required packages
pacman::p_load(papaja,
               readr,
               tidyr, 
               dplyr,
               ggplot2,
               ggbeeswarm,
               scico)
```

<!--The mind is a cognitive system that operates on inputs from an environment or memory.
In the domain of decision making, such inputs can be organized in a set $I$ of choice alternatives $i \in I$, the latter being distinguishable from each other on the basis of the *properties* they possess.
The basic structure of decision making may then be modeled by the inclusion map

$$
\begin{aligned}
  & \iota : I' \mapsto I \\
  & \iota(i) = i \ \text{for all} \ i \in I' 
\end{aligned}
\tag{1}
$$

[cf. @jostMathematicalConcepts2015, pp. 14-15], indicating that decision making is a process that starts from an input set $I$, including all choice alternatives, and stops at a proper subset $I' \subset I$, including only the chosen alternatives [see @heOntologyDecisionModels2020].--> 

Since there is an uncountable number of decisions people confront in the natural world, behavioral decision research routinely abstracts from particular decisions, e.g., the choice between job offers, political parties to vote for, travel destinations, investment plans, and whatnot.
Rather, with the choice between at least two *prospects* (or: gambles), it studies a case which is counterfactual in that it omits the many particularities of each decision and the differences between them, but retains in the form of prospects the fundamental properties that almost all choice alternatives are assumed to possess [@lopesThoughtsPsychologicalConcept1983].^[See Chapter 1 in @knightRiskUncertaintyProfit1921, for a discussion of the reasonableness of such abstractions.] 
These fundamental properties are considered to be the possible outcomes of a choice alternative---hereafter denoted by the Greek letter $\omega$---and the probabilities with which these outcomes occur following the choice of the alternative---hereafter $p(\omega)$.
Thus, prospects are abstract surrogates for choice alternatives in the natural world, resembling probability mass functions of the form 
$$
p: \Omega \mapsto [0,1]
\; ,
\tag{1}
$$ 
each of which assigns the possible outcomes in a finite set $\Omega = \{\omega_1, ..., \omega_n\}$ a probability $0 < p(\omega_i) \leq 1$, where $i \in \{1, ..., n\}$ and $\sum_i^n p(\omega_i) = 1$.

The choices people actually make between such prospects are often described in terms of their deviation from the principle of expected value (EV) maximization, where the EV is given by 
$$
EV = \sum_i^n \omega_i \times p(\omega_i)
\; .
\tag{2}
$$ 
That is, following the principle of EV maximization, people would first calculate the prospects' EV according to (2) and thereafter chose the prospect for which the EV is maximized.
<!--However, the many assessments of peoples' choices in these decisions neither corroborate the theory that people follow the principle of EV maximization nor that of expected utility (EU) maximization [e.g., @kahnemanProspectTheoryAnalysis1979, ...].^[Following the EU principle [@bernoulliExpositionNewTheory1954], the objective outcomes in (2) are transformed by a concave utility function. This transformation expresses the idea that an increase in the objective outcome yields a diminishing increase in its subjective utility, where the latter is weighted by the objective probability to compute the expected utility of a prospect. Note that for negative outcomes the transformation function is convex.]-->
To *describe* peoples' deviations from EV <!--and EU--> maximization [see @erevAnomaliesForecastsDescriptive2017, for a recent replication of classical demonstrations], the models of cumulative prospect theory [CPT, @tverskyAdvancesProspectTheory1992; see also @stottCumulativeProspectTheory2006, for an overview of models] may replace the objective outcomes and probabilities in (2) by nonlinear transformations thereof.
More specifically, the models contain a combination of two parameterized <!--monotonic--> functions, one transforming the objective outcomes---referred to as the *value function*, $\omega \mapsto v(\omega)$---and the other transforming the cumulative distribution function of objective probabilities---referred to as the *probability weighting function*, $p(\omega) \mapsto w(p(\omega))$ or $p(\omega) \mapsto w(p(\omega))$.
<!--Note that the probability weighting function is a composition of two functions $\omega \maps to p(\omega) \maps to w(p(\omega))$.-->


The shape of the probability weighting function lead to the common interpretation that people choose as if they were over- or underweighting outcomes of certain probability (see Figure 1). 
```{r}
wf <- tibble(gamma = c(.7, 1, 1.5), 
             type = c("overweighting", "linear", "underweighting")) %>%
  expand_grid(prob = seq(0, 1, .01)) %>%
  mutate(w = exp(-1*(-log(prob))^gamma)) %>% 
  select(-gamma)


ggplot(wf) +
  geom_path(aes(prob, w, linetype = type)) +
   scale_linetype_manual(values=c("solid", "dotted", "longdash")) +
  scale_x_continuous(breaks = seq(0, 1, .1)) +
  scale_y_continuous(breaks = seq(0, 1, .1)) + 
  labs(x = expression(paste("p(", omega, ")")),
       y = expression(paste("w(p(", omega, "))")),
       linetype = "Weighting Pattern") + 
  theme_apa() 
```

One such model is the cumulative prospect theory [@tverskyAdvancesProspectTheory1992] 



 
$$
\tag{3}
$$ 

Given that the choice is perfectly systematic---as opposed to random or noisy---the chosen alternatives in $I'$ should share some property or combination of several properties which the other alternatives in the complementary subset $I \setminus I'$ do not possess.
In the following, I will refer to statements about properties that serve to distinguish between the chosen and non-chosen alternatives as *selection criteria*. 

Often, however, the properties used by the mind to make a choice are not readily described and cannot be directly evaluated [cf. @brunswikRepresentativeDesignProbabilistic1955; see @brunswikPerceptionRepresentativeDesign1956, for a detailed treatment]; rather, proper descriptions must be inferred from whatever information the inputs provide about the properties of choice alternatives, using transformation rules, statistical generalizations, or both.
Since how the inputs are represented determines the information that is made explicit and the costs at which certain operations can be carried out on that information, the feasibility and ease of these inferences depends greatly on the choice of *representation* [@marrVisionComputationalInvestigation1982; see also, e.g., @gigerenzerHowImproveBayesian1995; @griffithsProbabilisticModelsCognition2010; @kempStructuredStatisticalModels2009].
Hence, to explain how the mind makes a selection among choice alternatives, one needs to understand the output controlling properties, i.e., the applied selection criteria, the representation that is used to describe these properties, and the costs of inferring the descriptions in that representation, including their susceptibility to distortions from uncertainty or noise. The process is sketched in Figure 1.  

(ref:figure1) A rough computational level sketch of decision making as an information processing problem. To make a selection among choice alternatives on the basis of particular selection criteria, the mind requires explicit descriptions of the relevant properties before they can be evaluated. Descriptions are either readily available or must be inferred from the inputs.

```{r fig.cap= "(ref:figure1)"}
knitr::include_graphics("images/dm-sketch.png")
```

In what follows, the paper elaborates on the concepts touched upon thus far, certainly only a subset of the factors involved in the decision making process, yet central enough to illustrate a rather important principle:
Given that the mind is indeed sensitive to variations in the property values, the more accurately their descriptions are inferred, the more systematic the choices should become.
Importantly, this principle is not restricted to any one specific property. 
Rather, each selection criterion or combination thereof imposes constraints on the assessment of choice alternatives, leading to characteristic choice patterns that are eventually blurred by inaccurate property descriptions.

For the sake of example, I argue that a choice pattern robustly emerging in *decisions from experience* (DfE), the apparent underweighting of small probability events [e.g., @barronSmallFeedbackbasedDecisions2003; @hertwigDecisionsExperienceEffect2004; @weberPredictingRiskSensitivity2004; see also @wulffMetaanalyticReviewTwo2018, for a meta-analytic review], may be caused by the assessment constraints associated with a round-wise decision strategy.
This particular claim has already been made by @hillsInformationSearchDecisions2010 and follows quite directly from probability theory.
However, the current paper suggests to subordinate decision strategies to the adoption of selection criteria and addresses in some detail two "problems" in the context of DfE, in which descriptions of the properties of choice alternatives must be inferred from sampling data.

For one, there is an *induction problem*, well known from inferential statistics, according to which the sample size determines the margin of error within which any true property of a choice alternative can be inferred, given an otherwise perfect inference process. 
Yet, it follows that if an underweighting pattern is caused by the adoption of an arbitrary selection criterion, it is *a priori* predicted to become more stable with increasing sample size. 
This prediction is in line with the principle already stated above, i.e., that selection-criteria-induced choice patterns should become more systematic as property descriptions become more accurate.
Nevertheless, the prediction contrasts the explanation that underweighting is caused by the reliance on small samples [e.g., @foxDecisionsExperienceSampling2006; @hertwigDecisionsExperienceEffect2004; @hauDescriptionexperienceGapRisky2008; @ungemachAreProbabilitiesOverweighted2009; @rakowBiasedSamplesNot2008], highlighting that outside of the *statistical* models used to describe the choice data, *causal* decision making models of quite different nature may be at play, and that a rather important difference between these causal models resides in the selection criteria they incorporate.
I will elaborate on this matter as I proceed, however, to be clear from the outset, what the mind does in neither case is performing a probability weighting computation in its literal sense, but it processes the inputs in a way that the outputs approximate the solutions of what can be considered probability weighting on an abstract computational level [cf., e.g., @griffithsRationalUseCognitive2015]. 

For another, this paper approaches the problem of organizing the sampling data in such a way that it allows chains of inferences connecting the input set $I$ with the output set $I' \subset I$ that are algorithmically short and simple enough to be carried out by minds whose cognitive capacities are bounded [cf. @simonInvariantsHumanBehavior1990; @simonBehavioralModelRational1955]. 
This may be considered a *representation problem* since the inference chains are constructed around explicit descriptions of the properties of choice alternatives and representations are the "formal schemes" of symbols and rules with which these descriptions are derived [@marrRepresentationRecognitionSpatial1978, p. 270]. 
Specifically, representations differ in how they organize the information used to infer the descriptions of certain properties and these organizations determine the algorithms that can be built into the inference chain [@marrVisionComputationalInvestigation1982].
In this paper, *sampling strategies* in DfE are considered as representation systems used to organize the samples in a way that subserves the property inferences required by the application of particular selection criteria.
Though most of my expositions on the role of sampling strategies remain speculative, the core idea is not new to decision research [see, e.g., @hillsInformationSearchDecisions2010; @wulffHowShortLongrun2015].
By restating this idea and adopting some terms and concepts that have well defined meaning in math and cognitive science, I hope to integrate it into the rich study of the computationally limited mind as an adaptive cognitive system whose processes interact with the information structures in the environment or memory. 

The theoretical arguments sketched in this introduction are substantiated by a simulation study. 
For this purpose, the sampling and decision making processes are implemented in a computational model to simulate choice data from DfE.
The simulated data is modeled in cumulative prospect theory (CPT), a data model commonly used for describing decisions under risk and uncertainty [@goldsteinExpressionTheoryPreference1987; see also @tverskyAdvancesProspectTheory1992]. 
All simulations and analyses are reproducible---materials and instructions can be found on the GitHub repository.

# Inputs to the Decision Making Process and Property Descriptions 

By defining decision making as an information processing problem whose solution requires a selection among choice alternatives of the form described in (1), much weight is given to the properties of choice alternatives---whatever those may be for the moment---since it is only through them that any necessary distinction between the alternatives or collections thereof can be made. 
To stress this point, consider the power set $\mathcal{P}(I)$, which is the set of all possible subsets of $I$ (see example in Figure 2). 

(ref:figure2) A. The power set of the set $I$ including the choice alternatives A, B, and C. Black (white) circles indicate that an alternative does (not) possess a property. Each column displays a possible subset that could result from assessing whether the alternatives posses a relevant property. The properties determine the various relations among the choice alternatives. Note that properties resulting in the empty set $\{\}$ and the subset $\{A,B,C\}$ do not discriminate between choice alternatives. B. A Venn diagram visualizing the inclusion map $\iota : I' \mapsto I$. $\iota$ maps every element $i$ of the subset $I'$ to its image $i$, treated as element of the superset $I$.

```{r fig.cap= "(ref:figure2)"}
knitr::include_graphics("images/power-set.png")
```

Each of the subsets $I' \in \mathcal{P}(I)$ corresponds to a possible distinction between the choice alternatives in $I$ that could result from assessing for each alternative whether it possesses an arbitrary property (collection) or not [cf. @jostMathematicalConcepts2015, p. 16]. 
The concept of the power set thereby illustrates how different selection criteria can alter the consequential choice.
That is, in rather abstract terms, selection criteria are statements regarding the properties of choice alternatives that the mind evaluates as either true or false during the decision making process; accordingly, the subset $I'$ only contains the alternatives for which the statement is evaluated to be true.
It follows that if there is some variance in the properties across choice alternatives and the properties are not perfectly correlated, changing the selection criteria can eventually change the subset $I'$.

## What Are the Choice Alternatives and Their Properties? 

The argument so far has been quite general and abstract, since there is no complete answer to the question raised above this paragraph---there is, of course, an uncountable number of decisions and so are there choice alternatives and properties.
Therefore, in the present paper, *prospects* are used as a proxy for the variety of choice alternatives the mind is required to evaluate in natural world decisions. 
Consequently, the argument continues to proceed at an abstract level: with choices between at least two prospects, the current paper considers a case which is counterfactual, since it is freed from many varieties and complexities that the mind is normally confronted with. 
The case is, however, quite paradigmatic in research on decision theory and there are good reasons for that [cf. @knightRiskUncertaintyProfit1921, especially Chapter 1 for a brief discussion closely related to the current subject]. 

Now, let a prospect be a *probability space* denoted by the tuple $(\Omega, \mathcal{F}, P)$. 
Following the @kolmogorovFoundationsTheoryProbability1950 axioms, $\Omega$ is the sample space 

$$
\Omega = \{\omega_1, ..., \omega_n\}
\; ,
\tag{2.1}
$$ 

containing a finite set of possible outcomes $\omega$. 
$\mathcal{F}$ is the set of all possible subsets of $\Omega$, i.e., the power set $\mathcal{P}(\Omega)$.^[Note that this paper considers only the case of finite sample spaces containing of a small number of outcomes. The exact axiomatic definition of $\mathcal{F}$, which can be found in Kolmogorov [-@kolmogorovFoundationsTheoryProbability1950, pp. 2-3 and 14-15], also covers infinite sample spaces and is that of a $\sigma$-algebra. For the finite case, however, $\mathcal{P}(\Omega)$ can be considered as such. See Georgii [-@georgiiStochastikEinfuhrungWahrscheinlichkeitstheorie2015, Chapter 1.1] for a comprehensive but accessible mathematical treatment.] 

$P$ is a probability measure  

$$
P: \mathcal{F} \mapsto [0,1]
\; ,
\tag{2.2}
$$

which assigns each subset $A \in \mathcal{F}$, also referred to as *events*, a probability $0 < p(A) \leq 1$ with $P(\Omega) = 1$.^[The probability measure formally assigns probabilities to sets of outcomes $A \in F$ rather than the elementary outcomes $\omega \in \Omega$. The probabilities of $\omega$ are determined by the probability mass function $p : \Omega \mapsto [0,1]$, which is used to construct the probability measure according to the equation $P(A) = \sum_{\omega \in A} p(\omega)$ for all $A \in \mathcal{F}$ [cf. @georgiiStochastikEinfuhrungWahrscheinlichkeitstheorie2015, Chapter 1.2].]

In less technical terms, following the choice of a prospect, one of the outcomes associated with this particular prospect is obtained, a gain or loss respectively.
If there is just one outcome associated with a prospect, it is obtained with certainty.
However, if there is a collection of outcomes, just one outcome out of this collection is obtained according to some probability, where the probabilities can vary between outcomes and are given by the measure of the form described in (2.2) (see also Footnote 2). 

Since it was stated that the inputs to the decision making process can be organized in a set of choice alternatives, we can adapt (1) for the case of a choice between $1, ..., k$ prospects to obtain: 

$$
\iota : I' \mapsto I, \ \text{where} \ I = \{(\Omega_1,  \mathcal{F}_1, P_1), ..., (\Omega_k,  \mathcal{F}_k, P_k)\}
\; .
\tag{3}
$$

Given (3), it is evident that the prospects can only be distinguished by the elements of their tuples. 
These elements are, generally speaking, symbols, some of which describe properties on their own, e.g., the outcome $\omega$, whereas other properties can only be described by collections of symbols, e.g., the sample space $\Omega$ by a set of outcomes as in (2.1), or more complex combinations thereof, e.g., the weighted average which is obtained by first multiplying all outcomes in $\Omega$ by their respective probabilities in $P$ and then summing the resulting products.^[I do not refer to this quantity as expected value, since the term is reserved for random variables, which were not introduced so far.]
In turn, for choices between prospects, selection criteria are statements about the elements of their tuples that are true or false and these statements imply relations among prospects that are at least nominal, but may also draw on other levels of measurement.  

## Inferring Property Descriptions from Sampling Data

Note that a selection criterion may refer to a property for which the raw input, i.e., the symbols, their organization, and the information they encode, do not yet provide an explicit description.
Even more so, it has been repeatedly stated that for quite many decisions the mind faces, it is simply not possible to draw on direct descriptions of the properties, since they are part of the distal environment  [e.g., @brunswikOrganismicAchievementEnvironmental1943; @fiedlerExplainingSimulatingJudgment1996; @hertwigDescriptionexperienceGapRisky2009; see also @brunswikRepresentativeDesignProbabilistic1955; @brunswikPerceptionRepresentativeDesign1956; @kozyrevaInterpretationUncertaintyEcological2021].
In either case, some form of description must be inferred from whatever information the input provides about the property in question.
Consider first the counterfactual case of the prospect whose tuple is not part of the distal environment but is directly described. 
Since all information about the prospect is given, one may in principle consider the input complete, yet, the tuple implies properties of the prospect which are not explicitly described.
For example, to obtain the description of the prospect's weighted average, still a calculus according to the algebraic rules described in the preceding paragraph must be carried out. 
In general, in cases like the one just considered, where the properties are not distal and all information about them is available, property inferences take the form of a mere transformation, where the symbols from the input are ordered and combined according to some transformation rules [cf. @marrVisionComputationalInvestigation1982, p. 20].

In natural world decisions, however, the properties of choice alternatives are often distal and amenable only through their probabilistic relation to proximal cues or samples, which provide the input to the decision making process [cf. @brunswikOrganismicAchievementEnvironmental1943].
Such a proximal information basis is obtained by experience or, more technically, by *sampling*, and is neither consistent nor complete but varies in its degree of representativeness. 
In turn, the mind is not merely required to transform the inputs but to draw inductive inferences to arrive at property descriptions which then, by definition, are only probable. 
Importantly, the probability, or accuracy, of the description depends on both the sampling process that determines the representativeness of the sample and the use of the probabilistic information that is entailed in the sample [e.g., @fiedlerBewareSamplesCognitiveecological2000]. 

To adapt (3) for the case of decisions from experience [@hertwigDecisionsExperienceEffect2004], the tuples $(\Omega, \mathcal{F}, P)$ must be replaced by samples, which in this paper are treated as collections of independent and identically distributed (i.i.d.) random variables $X$.^[Note that this paper considers the counterfactual case where samples are random, although it has been stated that in the natural world samples are "virtually never random" [@fiedlerBewareSamplesCognitiveecological2000, p. 660]. To account for non-random sampling, e.g., in the form of sampling biases [e.g., @fiedlerBewareSamplesCognitiveecological2000] or dynamic information structures [e.g., @cohenEffectPerceivedPatterns2021; @plonskyRelianceSmallSamples2015], the i.i.d-assumption would need to be dropped, which is out of the scope of this paper.]
Specifically, random variables are defined as a measurable function 

$$
X: (\Omega, \mathcal{F})  \mapsto (\Omega', \mathcal{F'}) 
\; ,
\tag{4}
$$

where $\Omega'$ is a set of real numbered values $X$ can take and $\mathcal{F'}$ is a set of subsets of $\Omega'$. 
I.e., $\Omega$ maps into $\Omega'$ such that correspondingly each subset $A' \in \mathcal{F'}$ has a pre-image $X^{-1}A' \in \mathcal{F}$, which is the set $\{\omega \in \Omega: X(\omega) \in A'\}$ [@kolmogorovFoundationsTheoryProbability1950, p. 21].


$$
\begin{aligned}
  & \iota : I' \mapsto I, \ \text{where} \ I = \{X_{1i}, ..., X_{ki}\} \\
  & i \in \{1, ..., N\} 
  \; .
\end{aligned}
\tag{5}
$$


To provide a formal definition of sampling in risky choice, we make use of the mathematical concept of a random variable and start by referring to a prospect as *"risky"* in the case where $p(\omega) \neq 1$ for all $\omega \in \Omega$.
Here, risky describes the fact that if agents would choose a prospect and any of its outcomes in $\Omega$ must occur, none of these outcomes will occur with certainty. 
It is acceptable to speak of the occurrence of $\omega$ as a realization of a random variable $X$ defined on a prospect iff the following conditions (1) and (2) are met: 


(2) The mapping is such that $X(\omega) = x \equiv \omega$. 

In (2), $x \equiv \omega$ means that the realization of a random variable $X(\omega) = x$ is numerically equivalent to its pre-image $\omega$.  
Given conditions (1) and (2), we denote any observation of $\omega$ as a *"single sample"*, or realization, of a random variable defined on a prospect and the act of generating a sequence of single samples in discrete time as *"sequential sampling"*. 
Note that, since random variables defined on the same prospect are independent and identically distributed (iid), the weak law of the large number applies to the relative frequency of occurrence of an outcome $\omega$ in a sequence of single samples originating from the same prospect.
Thus, long sample sequences in principle allow to obtain the same information about a prospect by sampling as by symbolic description.

Consider now a choice between prospects $1, ..., k$.
To construct a stochastic sampling model for DfE, we assume that agents base their decision on the information related to these prospects and define a decision variable as a function of the latter:

$$
D:= f((\Omega_1, \mathcal{F}_1, P_1), ..., (\Omega_k, \mathcal{F}_k, P_k))
\;.
$$

Now, since in DfE no symbolic descriptions of the prospects are provided, the model must be restricted to the case where decisions are based on sequences of single samples originating from the respective prospects:

$$
D := f(X_{i1}, ..., X_{ik}) 
\; ,
$$

where $i \in \{1, ..., N\}$ denotes a sequence of length $N$ of random variables that are iid.  

Concerning the form of $f$ and the measures it utilizes, it is quite proper to say that they reflect our assumptions about the exact kind of information agents process and the way they do and that these choices should be informed by psychological theory and empirical protocols. 
Taking the case of different sampling and decision strategies previously assumed to play a role in DfE, the following section demonstrates how such assumptions can be explicated in a stochastic model that builds on the sampling approach outlined so far.  

# Evaluation of Choice Alternatives and Outputs of the Decision Making Process

...

# Sampling Strategies as Representation Systems

...

# Simulation Study

...

The switching probability $s$ is the probability with which agents draw a single sample from the prospect they did not get their most recent single sample from.
$s$ is varied between .1 to 1 in increments of .1.
The two boundary parameters resemble the concept of a decision threshold, i.e., if a prospect reaches a boundary, it is chosen by the synthetic agent.
The boundary type is either the minimum number of comparisons any prospect must win (absolute boundary) or the minimum difference between the number of won comparisons (relative boundary).
The boundary value $a$ is varied between 1 to 5 in increments of 1.

## Test set

For each parameter combination of the generating model, 100 synthetic agents are presented with 60 choices problems.
In sum, 100 (parameter combinations) x 100 (agents) x 60 (choices) = 600,000 choices are simulated.
We test a set of 2-prospect choice problems, where one of the prospects contains a safe outcome, i.e., $p(\omega) = 1$ and the other two outcomes where all $p(\omega) \neq 1$.
Both outcomes and probabilities are drawn from uniform distributions, ranging from 0 to 20 for outcomes and from .01 to .99 for probabilities of the smaller outcome of the risky prospect.
To omit dominant prospects within a choice problem, outcomes of the safe prospect always fall between both outcomes of the risky prospect.
Table A1 in [Appendix 2][Appendix 2: Choice Problems] contains the test set of 60 choice problems, which were sampled from an initial set of 10,000.
Sampling of gambles was stratified, randomly drawing an equal number of 20 gambles with no, an attractive, and an unattractive rare outcome.
Risky outcomes are considered *"rare"* if their probability is $p < .2$ and *"attractive"* (*"unattractive"*) if they are higher (lower) than the safe outcome.

## Results

...

```{r}

# read cpt data

cols <- list(.default = col_double(),
             boundary = col_factor(),
             a = col_factor(),
             parameter = col_factor())
cpt_long <- read_csv("data/estimates/estimates_cpt.csv", col_types = cols)

# store convergence diagnostics

gel_92 <- cpt_long %>% select(s, boundary, a, parameter, Rhat, n.eff) 
```

For each distinct parameter combination, we ran 20 chains of 40,000 iterations each, after a warm-up period of 1000 samples.
To reduce potential autocorrelation during the sampling process, we only kept every 20th sample (thinning).
The potential scale reduction factor $\hat{R}$ [@gelmanInferenceIterativeSimulation1992] was $\leq$ `r round(max(gel_92$Rhat), 3)` for all parameters, indicating good convergence.
The minimum effective sample size was `r min(gel_92$n.eff)`.


### Plausibility Check: Relationship between Switching Probability and Trial Length

```{r include=FALSE}

# read choice data 

cols <- list(.default = col_double(),
             boundary = col_factor(),
             gamble = col_factor(),
             rare = col_factor(),
             agent = col_factor(),
             choice = col_factor())
choices <- read_csv("data/choices/choices.csv", col_types = cols)

# get median trial length for each parameter combination

trial_length <- choices %>% 
  group_by(s, boundary, a) %>% 
  summarise(med = median(n_sample))
```

The median length of trials, i.e., the number of single samples drawn in a trial, generated by different parameter combinations ranged from `r min(trial_length$med)` to `r max(trial_length$med)`.
As expected, the scatter plot below shows an inverse relationship between switching probability and trial length.
I.e., the lower the switching probability, the larger become the sample sequences on which each comparison between prospects is based, which in turn leads to longer trials.  
This effect is particularly pronounced for low probabilities such that the increase in trial length accelerates as switching probability decreases.


```{r eval=FALSE}

# get median trial length for each switching probability 

trial_length_s <- choices %>% 
  group_by(s) %>%
  summarise(med = median(n_sample))

# plot

trial_length %>%
  ggplot(aes(x = s, y = med)) +
  geom_jitter(color = "#CECECE", size = 3) +
  geom_point(data = trial_length_s, aes(color = s), size = 3) +
  geom_path(data = trial_length_s, aes(color = s)) +
  scale_color_scico(palette = "buda") + 
  scale_x_continuous(breaks = seq(0, 1, .1)) + 
  scale_y_continuous(breaks = seq(0, 120, 10)) +
  labs(title = "Trial Length", 
       x ="Switching Probability",
       y = "Median Trial Length", 
       color="Switching Probability") + 
  theme_apa()
```

### Probability Weighting Function

```{r eval=FALSE}

# tidy CPT data: parameters as separate columns 

cpt_wide <- cpt_long %>% 
  select(s, boundary, a, parameter, mean) %>% 
  pivot_wider(names_from = parameter, values_from = mean)
```

The figures below display the estimates of the $\gamma$ and $\delta$ parameter of the probability weighting function [@prelecProbabilityWeightingFunction1998] fitted to DfE simulated for different parameter values of the generating model.
The estimates are plotted against the switching probability, where each panel represents a distinct boundary type and level, i.e., number of comparisons. 
Grey dots represent agent level estimates, colored dots represent the mean across all agent level estimates. 

Most significantly, there is a strong relationship between the switching probability in the generating model and the $\gamma$ parameter.
I.e., large switching probabilities, which are indicative for small sample sequences, lead to larger estimates for $\gamma$. 
The resulting strong curvature leads to a compression of probabilities in the lower and upper range, reflecting underweighting of small probabilities and overweighting of large probabilities. 
This pattern is robust for varying degrees of the boundary level, except for $a = 1$. 
The latter deviation may be explained by the potential scale reduction factors for the respective parameter estimates, which indicate that the MCMC chains did not converge (see [Appendix 3][Appendix 3: Convergence Diagnostics for CPT Parameters]).   

```{r eval=FALSE}

# Density Plot 

cpt_long %>% 
  filter(parameter == "gamma" | parameter == "delta") %>% 
  ggplot(aes(x = s, y = mean)) +
  geom_density_2d_filled(contour_var = "ndensity") + 
  scale_fill_scico_d(palette = "grayC") +
  scale_color_scico_d(palette = "grayC") + 
  scale_x_continuous(breaks = seq(0, 1, .2)) + 
  scale_y_continuous(limits = c(0,2), breaks = seq(0, 2, .2)) +
  labs(x ="Switching Probability",
       y = "Parameter Value",  
       fill="Density") + 
  facet_grid(parameter~a) + 
  theme_apa()
```

```{r eval=FALSE}

# Scatter Plots 

# Gamma 

cpt_wide %>% 
  ggplot(aes(x = s, y = gamma, color = s)) +
  geom_point(size = 2) +
  geom_line(size = 1) +
  scale_color_scico(palette = "buda") + 
  scale_x_continuous(breaks = seq(0, 1, .2)) + 
  scale_y_continuous(breaks = seq(0, 2, .2)) +
  facet_grid(boundary~a) +
  labs(title = expression(paste("Curvature ", gamma)),
       x ="Switching Probability",
       y = expression(gamma), 
       color="Switching Probability") + 
  theme_minimal()

# Delta

cpt_wide %>% 
  ggplot(aes(x = s, y = delta, color = s)) +
  geom_point(size = 2) +
  geom_line(size = 1) +
  scale_color_scico(palette = "buda") + 
  scale_x_continuous(breaks = seq(0, 1, .2)) + 
  scale_y_continuous(breaks = seq(0, 2, .2)) +
  facet_grid(boundary~a, switch = "y") +
  labs(title = expression(paste("Curvature ", delta)),
       x ="Switching Probability",
       y = expression(delta), 
       color="Switching Probability") + 
  theme_minimal()
```

Below, the resulting probability weighting functions are displayed. 

```{r eval=FALSE}

# Weighting Functions 

## compute decision weights 

cpt_w <- cpt_wide %>% 
  select(-c(alpha, rho)) %>% 
  expand_grid(ep = seq(0, 1, .1)) %>% #
  mutate(w = round(  (delta * ep^gamma)/ ((delta * ep^gamma)+(1-ep)^gamma), 2)) 

## plot curves

cpt_w %>% 
  group_by(boundary, a, s) %>% 
  ggplot(aes(x = ep, y = w, color = s)) +
  geom_path() + 
  scale_color_scico(palette = "grayC") + 
  scale_x_continuous(breaks = seq(0, 1, .2)) +
  scale_y_continuous(breaks = seq(0, 1, .2)) + 
  labs(x ="Experienced Probability",
       y = "Probability Weighting", 
       color="Switching Probability") + 
  theme_minimal()

cpt_w %>% 
  group_by(boundary, a, s) %>% 
  ggplot(aes(x = ep, y = w, color = s)) +
  geom_path() + 
  scale_color_scico(palette = "buda") + 
  scale_x_continuous(breaks = seq(0, 1, .2)) +
  scale_y_continuous(breaks = seq(0, 1, .2)) + 
  facet_wrap(~a) +
  labs(x ="Experienced Probability",
       y = "Probability Weighting", 
       color="Switching Probability") + 
  theme_minimal()
```

The false response rates for different parameter values of the generating model reflect the probability weighting patterns from above. 
That is, the strong curvature resulting from large switching probabilities produces an underweighting of small probabilities. This in turn has the effect that the rarity of an attractive (unattractive) outcome leads to higher rates of choosing the safe (risky) prospect although the risky (safe) prospect had a higher experienced expected value.

```{r eval=FALSE}

# compute false response rates

fr_rates <- choices %>% 
  mutate(ev_ratio_exp = round(a_ev_exp/b_ev_exp, 2), # experienced EV (eEV)
         norm = case_when(ev_ratio_exp > 1 ~ "A", ev_ratio_exp < 1 ~ "B")) %>% # normative choice according to eEV
  filter(!is.na(norm)) %>% # exclude trials with normative indifferent prospects
  group_by(s, boundary, a, rare, norm, choice) %>% # group correct and incorrect responses
  summarise(n = n()) %>% # absolute numbers 
  mutate(rate = round(n/sum(n), 2), # response rates 
         type = case_when(norm == "A" & choice == "B" ~ "false safe", norm == "B" & choice == "A" ~ "false risky")) %>% filter(!is.na(type))  # remove correct responses

# violin scatter plot

fr_rates %>% 
  ggplot(aes(x = rare, y = rate, color = s)) +
  geom_quasirandom(aes(shape = type), size = 3) +  
  scale_y_continuous(breaks = seq(0, 1, .2)) +
  scale_color_scico(palette = "buda") + 
  scale_shape_manual(values=c(8, 16))+
  labs(x = "Rare Event", 
       y = "False Response Rate", 
       color = "Switching Probability",
       shape = "False Response") + 
  theme_minimal() 
```

```{r eval=FALSE}
fr_rates %>% 
  ggplot(aes(a, s, fill = rate)) + 
  geom_tile(colour="white", size=0.1) +
  scale_fill_scico(palette = "buda") + 
  facet_grid(type ~ fct_relevel(rare, "attractive", "none", "unattractive"), switch = "y") +
  scale_x_continuous(expand=c(0,0), breaks = seq(1, 5, 1)) +
  scale_y_continuous(expand=c(0,0), breaks = seq(.1, 1, .1)) +
  labs(title = "False Response Rates", 
       x = "a", 
       y= "s", 
       fill = "% False Responses") + 
  theme_minimal() 


fr_rates %>% 
  ggplot(aes(s, rate, color = s)) + 
  facet_grid(type ~ fct_relevel(rare, "attractive", "none", "unattractive"), switch = "y") +
  geom_jitter(size = 3) + 
  scale_x_continuous(breaks = seq(0, 1, .1)) +
  scale_y_continuous(breaks = seq(0, 1, .1)) +
  scale_color_scico(palette = "buda") + 
  labs(title = "False Response Rates", 
       x = "s", 
       y= "% False Responses", 
       color = "a") + 
  theme_minimal()
```

### Value Function 

```{r eval=FALSE}

# Density Plot 

cpt_wide %>%
  ggplot(aes(x = s, y = alpha)) +
  geom_density_2d_filled(contour_var = "ndensity") + 
  scale_fill_scico_d(palette = "grayC") +
  scale_x_continuous(breaks = seq(0, 1, .2)) + 
  scale_y_continuous(limits = c(0,2), breaks = seq(0, 2, .2)) +
  labs(x ="Switching Probability",
       y = "Parameter Value",  
       fill="Density") + 
  facet_wrap(~a, nrow = 1) + 
  theme_minimal()
```

```{r eval=FALSE}
# value function 

## compute values 

cpt_v <- cpt_wide %>% 
  select(-c(gamma, delta, rho)) %>% 
  expand_grid(x = seq(0, 20, 2)) %>%  
  mutate(v = round(x^alpha, 2)) 

## plot curves

cpt_v %>% 
  group_by(boundary, a, s) %>% 
  ggplot(aes(x = x, y = v)) +
  geom_path(aes(color = s)) +
  scale_color_scico(palette = "grayC") + 
  scale_x_continuous(breaks = seq(0, 20, 5)) +
  scale_y_continuous(breaks = seq(0, 20, 5)) + 
  labs(title = "Value Function",
       x ="Objective Value",
       y = "Subjective Value", 
       color="Switching Probability") + 
  theme_minimal()

cpt_v %>% 
  group_by(boundary, a, s) %>% 
  ggplot(aes(x = x, y = v)) +
  geom_path(aes(color = s)) +
  scale_color_scico(palette = "buda") + 
  scale_x_continuous(breaks = seq(0, 20, 5)) +
  scale_y_continuous(breaks = seq(0, 20, 5)) + 
  facet_wrap(~a) +
  labs(title = "Value Function",
       x ="Objective Value",
       y = "Subjective Value", 
       color="Switching Probability") + 
  theme_minimal()
```

```{r eval=FALSE}

# alpha
cpt_wide %>% 
  ggplot(aes(x = s, y = alpha, color = s)) +
  geom_point(size = 2) +
  geom_line(size = 1) +
  scale_color_scico(palette = "buda") + 
  scale_x_continuous(breaks = seq(0, 1, .2)) + 
  scale_y_continuous(breaks = seq(0, 2, .2)) +
  facet_grid(boundary~a, switch = "y") +
  labs(title = expression(alpha),
       x ="Switching Probability",
       y = expression(alpha), 
       color="Switching Probability") + 
  theme_minimal()
```

# Discussion and Conclusion


# References
