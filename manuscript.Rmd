---
title             : "Sampling Strategies in Decisions from Experience: Property Representation and Probability Weighting Approximation"
shorttitle        : "Sampling strategies"

author: 
  - name          : "Linus Hof"
    affiliation   : "1"
    corresponding : yes    
    address       : "Department of Psychology, Heidelberg University, Hauptstra√üe 47-51, 69117 Heidelberg, Germany"
    email         : "linushof@posteo.de"
    
affiliation:
  - id            : "1"
    institution   : "Heidelberg University"

note: | 
  **Unsubmitted draft created from the commit with the hash**: ``r repro::current_hash()``
  
authornote: |
 This is a dynamic document which can be reproduced from the accompanying GitHub repository: https://github.com/linushof/sampling-in-dfe. 
 
 The current version of this manuscript is prepared for submission as a master's thesis.
 Supervisors: Thorsten Pachur & Veronika Zilker.   
 
abstract: |
  Add short abstract.
  
keywords          : ""
wordcount         : ""

bibliography      : ["references_sampling-in-dfe.bib"]
csl               : apa.csl

figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : no
linkcolor         : "blue"
mask              : no
draft             : no

classoption       : "man"
documentclass     : "apa7"
output            : papaja::apa6_pdf

header-includes:
   - \usepackage[capposition=top]{floatrow}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = F, fig.pos = "t", fig.align = "l")
```

```{r packages}
# load required packages
pacman::p_load(papaja,
               readr,
               tidyr, 
               dplyr,
               ggplot2,
               ggbeeswarm,
               scico)
```

<!-- Introduction -->

The human mind is a cognitive system that operates on inputs from an environment or memory.
In the domain of decision making, such inputs provide information about the choice alternatives among which people can choose.
Let us treat these choice alternatives hereafter as elements $c$ of the set $C$.
To each $c \in C$ is then assigned some information from the inputs and this information may be used by the mind to learn about the *properties* of the respective choice alternative.
In turn, decision making can be considered an information processing problem which starts from the set $C$, containing all choice alternatives, and stops at a proper subset $C' \subset C$ with the inclusion map
$$
\begin{aligned}
  \iota : C' &\to C \\
  c &\mapsto c  \quad \forall c \in C'
\end{aligned}
\tag{1}
$$
[@jostMathematicalConcepts2015, p. 15], containing only the chosen alternatives.
Indeed, irrespective of their exact mathematical specification or computational implementation, decision models generally take as inputs information about a set of choice alternatives to return a subset thereof as outputs [@heOntologyDecisionModels2020].

<!-- Add short and general outlook on the paper -->

# Prospects, Decisions from Description, and Decisions from Experience

Since there is an uncountable number of decisions people confront in the natural world, behavioral decision research routinely abstracts from decisions between particular choice alternatives, e.g., the choice between job offers, political parties to vote for, investment plans, and whatnot.
Rather, with the choice between at least two *prospects* (see below), it studies a case which is counterfactual in that it omits the many particularities of each decision, but retains in the form of prospects the fundamental properties that almost all choice alternatives are assumed to possess [@lopesThoughtsPsychologicalConcept1983].^[See @knightRiskUncertaintyProfit1921, Chapter 1, for a timeless discussion of the reasonableness of such abstractions.] 
These fundamental properties are considered the possible outcomes of a choice alternative---hereafter $x_i$---and the probabilities with which these outcomes occur following the choice of the alternative---hereafter $p_X(x_i)$.
Roughly speaking, then, all choice alternatives that can be fully described by their outcome-probability pairs $(x_i, p_X(x_i))$ are prospects (or: gambles), which are exclusively considered below. 
<!--For illustration, take the choice alternatives in the following example with monetary outcomes: 

\noindent
**Example 1.** 
```{r echo=TRUE}
# Alternative 1
a1_outcomes <- 1 
a1_prob <- 1 

# Alternative 2
a2_outcomes <- c(10, 0)
a2_prob <- c(.1, .9)
```
-->

Now, more formally, let the axiomatic definition of a prospect be that of a discrete random variable's distribution.
Let therefore the tuple $(\Omega, \mathcal{F}, P)$ be a probability space. 
Following the @kolmogorovFoundationsTheoryProbability1950 axioms, $\Omega$ is the sample space containing a finite set of elements
$$
\omega_i \in \{\omega_1, ..., \omega_n\} = \Omega
\; .
\tag{2}
$$ 
$\mathcal{F}$ is the set of all possible subsets of $\Omega$, i.e., the power set $\mathcal{P}(\Omega)$ with each element $A \in P(\Omega) = \mathcal{F}$ being a subset of $\Omega$.^[Note that this paper considers only the case of finite sample spaces. The exact axiomatic definition of $\mathcal{F}$, which can be found in Kolmogorov [-@kolmogorovFoundationsTheoryProbability1950, pp. 2-3 and 14-15], also covers infinite sample spaces and is that of a $\sigma$-algebra. For the finite case, however, $\mathcal{P}(\Omega)$ can be considered as such [@georgiiStochastikEinfuhrungWahrscheinlichkeitstheorie2015, Chapter 1.1].] 
$P$ is a probability measure
$$
P: \mathcal{F} \to [0,1]
\; ,
\tag{3}
$$
which assigns each subset $A \in \mathcal{F}$ a probability $0 < p(A) \leq 1$ with $P(\Omega) = 1$.<!--^[The probabilities $p(\omega)$ are determined by the probability mass function $p : \Omega \to [0,1]$, which is used to construct the probability measures $P(A) = \sum_{\omega \in A} p(\omega)$ for all $A \in \mathcal{F}$.]-->
The random variable $X$ is the measurable function
$$
\begin{aligned}
  X : (\Omega, \mathcal{F}) &\to (\Omega', \mathcal{F'})  \\
  \omega &\mapsto x
  \; ,
\end{aligned}
\tag{4}
$$
where $(\Omega', \mathcal{F'})$ is a measurable space with each element $x \in \Omega'$ being a possible outcome of a prospect and each element $A' \in \mathcal{F'}$ being a subset of $\Omega'$.
An outcome's probability $p_X(x)$ is then provided by the probability measure
$$
P_X : \mathcal{F'} \to [0,1]
\tag{5}
$$
with 
$$
P_X(A' \in \mathcal{F'}) := P(X^{-1} \ A') = P(\{\omega: X(\omega) = x \in A'\})
\tag{6}
$$
[see @kolmogorovFoundationsTheoryProbability1950, p. 21; see also @georgiiStochastikEinfuhrungWahrscheinlichkeitstheorie2015, Chapter 1, for a comprehensive introduction to random variables].
That is, the set consisting of a single outcome $x$ can be treated as a subset $\{x\} \in \mathcal{F'}$ and we therefore obtain $p_X(x) = P(X(\omega) = x)$.
Note that the probability measure in (5) and (6), respectively, is a discrete random variable's distribution and therefore a prospect.
To summarize and simplify, given a choice between $1, ..., k$ prospects, the inputs from the environment or memory should provide information about the set
$$
C = \{P_{X_1}, ... , P_{X_k}\}
\tag{7}
$$
with each element $c \in C$ being a distribution $P_X$ of a random variable defined on a different probability space.
Accordingly, each $c$ can itself be considered a set of outcome-probability pairs $(x_i, p_X(x_i)) \in \{(x_1, p_X(x_1)), ..., (x_n, p_X(x_n))\}$.

However, rarely in peoples' daily life, inputs take the form of explicit descriptions of all outcomes-probability pairs.
In such cases, people would make *decisions from description* (DfD), since the information from which the mind learns about the prospects are complete descriptions thereof.
Yet, rather often, people make *decisions from experience* [DfE, @hertwigDecisionsExperienceEffect2004], where the mind can learn about the prospects only from a record of past experiences with them.
That is, people may have experienced the possible outcomes of a prospect when they themselves or others have made the same decision repeatedly in the past, and the record of experienced outcomes for this particular prospect is a rough description of a *sample*.
The mind may then infer from the relative frequency with which an outcome occurred in such a sample of past decisions its probability of occurrence following a future decision.

Now, more formally, let the sample of a prospect be a set of realizations of the respective random variable $X$ according to its distribution $P_X$.^[Note that this paper considers the counterfactual case where samples are random, although it has been emphasized that in the natural world samples are "virtually never random" [@fiedlerBewareSamplesCognitiveecological2000, p. 660]. To account for non-random sampling, e.g., in the form of sampling biases [e.g., @fiedlerBewareSamplesCognitiveecological2000] or dynamic information structures [e.g., @cohenEffectPerceivedPatterns2021; @plonskyRelianceSmallSamples2015], the i.i.d-assumption would need to be dropped, which is out of the scope of this paper.]
So, for the choice between $1, ..., k$ prospects, the inputs to DfE are generated by a set $S$ of stochastic processes
$$
S = \{X_{1t}, ... , X_{kt}\}
\tag{8}
$$
with $t \in \{1, ..., N\}$ denoting a sequence of independent and identically distributed (i.i.d.) random variables and $N$ denoting the size of the respective sequence.
The sets of realizations that result from these stochastic processes may then be used to make an uncertain inference about the respective sets of outcome-probability pairs in (7).

Of course, the accuracy of such inferences depends, ceteris paribus, on the size of the samples, since from the laws of large numbers it follows that the relative frequency with which an outcome occurs in a sample converges to the outcome's objective probability only as the size of a sample increases [see @georgiiStochastikEinfuhrungWahrscheinlichkeitstheorie2015, Chapter 5].
However, if the choices that people actually make between prospects are described, robust differences can be found between the choices in DfD and DfE, and the size of samples in DfE provides just one and only a partial explanation for this *description-experience gap* [see @hertwigDescriptionexperienceGapRisky2009; @wulffMetaanalyticReviewTwo2018]. 
The following section briefly addresses how choices between prospects in general and the description-experience gap in particular can be described using cumulative prospect theory's [CPT, @tverskyAdvancesProspectTheory1992; @wakkerAxiomatizationCumulativeProspect1993] *weighting function*.^[This paper also considers CPT's value function, but emphasis is put on the weighting function.]
<!-- The two sections thereafter ... --> 

# The Description of Choices in CPT and the Description-Experience Gap

The choices people actually make between prospects---be that in DfD or DfE---are often described in terms of deviations from expected value (EV) maximization, where the EV of a prospect is given by 
$$
EV = \sum_i^n x_i \times p_X(x_i)
\; .
\tag{9}
$$ 
That is, following the principle of EV maximization, one would calculate the prospects' EV---each by first multiplying its outcomes $x_i$ by their respective probabilities $p_X(x_i)$ and then summing the resulting products---to subsequently choose the prospect with the largest EV.
To *describe* how people's actual choices deviate from EV maximization [see @erevAnomaliesForecastsDescriptive2017, for a recent replication of classical demonstrations], the models of cumulative prospect theory [CPT, @tverskyAdvancesProspectTheory1992; @wakkerAxiomatizationCumulativeProspect1993] and similar rank-dependent models [see @stottCumulativeProspectTheory2006, for an overview of models] fit choice data by maximizing the value
$$
V = \sum_i^n v(x_i) \times \pi_i
\; ,
\tag{10}
$$ 
with objective outcomes $x_i$ being transformed by a *value function* $v$, and *cumulative decision weights* $\pi_i$ being determined by the difference between transformed cumulative probabilities of the distribution $P_X$.^[Note that CPT or other originally deterministic decision models may be amended by a stochastic choice function to account for the probabilistic nature of choices [see, e.g., @rieskampProbabilisticNaturePreferential2008].]
Importantly, the transformation of cumulative probabilities is carried out by a weighting function $w$ (see (11) and (12) below).
More specifically, CPT proposes cumulative decision weights as replacements for objective probabilities to account for empirical regularities in the deviations from EV maximization in DfD^[@tverskyAdvancesProspectTheory1992 addressed the *fourfold pattern of risk attitudes*---i.e., choices between prospects indicate risk aversion for gains of high probability and losses of low probability, and risk seeking for gains of low probability and losses of high probability---and related effects such as the *certainty effect* and the *reflection effect* that were already addressed by CPT's predecessor, prospect theory [@kahnemanProspectTheoryAnalysis1979]. Together, these empirical choice patterns indicate a violation of the EV principle and the expected utility (EU) principle [see @bernoulliExpositionNewTheory1954\/1738].] that cannot be captured by the transformation of objective outcomes into subjective values $v(x)$ alone (see Footnote 6).
In essence, to provide a proper description of people's choices between prospects in terms of their deviation from EV maximization, the proposed model is such that the inferred cumulative decision weights may be larger or smaller than the respective objective probabilities in (9); and they may therefore give more or less weight to subjective values for the overall valuation of a prospect in CPT than would be objectively warranted.
In other words, for an inferred cumulative decision weight that is greater (smaller) than the objective probability it replaces, the respective outcome is overweighted (underweighted) in CPT.
Accordingly one may---but must not---adopt an as-if weighting terminology for the description of choices by stating that people decide *as if* they maximized the value in (10) and applied the inferred over- and underweighting pattern.
Importantly, the as-if prefix indicates that it cannot be concluded from the inferred cumulative decision weights that the mind does indeed perform the weighting computation in its literal sense, but it processes the inputs in a way that the outputs approximate the solutions of what can be considered probability weighting on an abstract computational level [see, e.g., @griffithsRationalUseCognitive2015]. 

Now, more formally, cumulative decision weights in CPT take the form
$$
\pi_i =
  \begin{cases}
     w^+(P(X \geq x_i)) - w^+(P(X > x_i)) \quad \forall x_i \geq 0, \\
     w^-(P(X \leq x_i)) - w^-(P(X < x_i)) \quad \text{else}, 
  \end{cases}
\tag{11}
$$
where $w$ is a monotonic, nonlinear function satisfying $w^+(0) = w^-(0) = 0$ and $w^+(1) = w^-(1) = 1$ [@tverskyAdvancesProspectTheory1992].
From the transformation of cumulative probabilities in (11), it follows that the replacement of objective probabilities by cumulative decision weights depends on the rank of the outcome to which the decision weight is assigned and the shape of the weighting function, which itself depends on the exact parameterization of the function [e.g., @goldsteinExpressionTheoryPreference1987; @tverskyAdvancesProspectTheory1992; @prelecProbabilityWeightingFunction1998; see also @stottCumulativeProspectTheory2006]. 
That is, the shape of the weighting function determines over which interval on the probability scale [0, 1] cumulative probabilities are overweighted or underweighted.
In turn, the same difference in the objective cumulative probability ... 


Now, although the possible deviation patterns, which span the entire probability scale, depend on the exact parameterization of the cumulative weighting function, they allow the adoption of an as-if weighting terminology for the description of choice behavior, which was originally introduced outside of the CPT models [see @pachurWeightUncertainEvents2019].

Figure 1 illustrates such a description in CPT with different parameter settings for the two-parameter weighting function of @goldsteinExpressionTheoryPreference1987 with
$$
\begin{aligned}
  w : [0,1] &\to [0,1] \\
  p_X(x) &\mapsto \frac{\delta \times p_X(x)^{\gamma}}
  {\delta \times p_X(x)^{\gamma} + (1-p_X(x))^{\gamma}}
  \; ,
\end{aligned}
\tag{12}
$$
where $\gamma \in [0,2]$ and $\delta \geq 0$ determine the function's curvature and elevation, respectively.
In essence, if the estimate of a cumulative decision weight is larger (smaller) than the objective probability from which it is derived, the weighting function runs above (below) the dashed identity line.
The choice data are then described *as if* people maximized the value in (8) and applied the over- and underweighting pattern indicated by the estimated shape of the overall probability weighting function.


(ref:weighting) Probability Weighting Function of @goldsteinExpressionTheoryPreference1987 for Different Values of the Curvature Parameter $\gamma$ and the Elevation Parameter $\delta$.

```{r fig.cap="(ref:weighting)"}
wf <- tibble(gamma = seq(.1, 2, .1)) %>%
  expand_grid(delta = c(.1, .5, 1, 2, 5, 10),
              prob = seq(0, 1, .01)) %>%
  mutate(w = (delta*(prob^gamma))/((delta*prob^gamma)+(1-prob)^gamma))

ggplot(wf) +
  geom_line(aes(prob, w, group = gamma, color = gamma)) +
  geom_segment(x = 0, xend = 1, y =  0, yend = 1, linetype = "dashed", size = .2, color = "gray") +
  scale_color_scico(palette = "lisbon") + 
  scale_x_continuous(breaks = seq(0, 1, .2)) +
  scale_y_continuous(breaks = seq(0, 1, .2)) + 
  labs(x = "p",
       y = "w(p)", 
       color = expression(gamma)) + 
  facet_wrap(. ~ delta, labeller = label_bquote(cols = delta: .(delta))) + 
  theme_minimal()
```

Research on choices in DfD and DfE 
Specifically, when people make DfD, decision weights are typically estimated to be larger than the objective probabilities in the lower probability range.
However, for DfE, this pattern reverses and decisions weights are typically estimated to be smaller than the objective probabilities in the lower probability range [e.g., @barronSmallFeedbackbasedDecisions2003; @hertwigDecisionsExperienceEffect2004; @weberPredictingRiskSensitivity2004; also see @wulffMetaanalyticReviewTwo2018].  

# Explanations for Underweighting in DfE


# Decision and Sampling Strategies

<!-- old -->

Given that the choice is perfectly systematic---as opposed to random or noisy---the chosen alternatives in $I'$ should share some property or combination of several properties which the other alternatives in the complementary subset $I \setminus I'$ do not possess.
In the following, I will refer to statements about properties that serve to distinguish between the chosen and non-chosen alternatives as *selection criteria*. 

Often, however, the properties used by the mind to make a choice are not readily described and cannot be directly evaluated [cf. @brunswikRepresentativeDesignProbabilistic1955; see @brunswikPerceptionRepresentativeDesign1956, for a detailed treatment]; rather, proper descriptions must be inferred from whatever information the inputs provide about the properties of choice alternatives, using transformation rules, statistical generalizations, or both.
Since how the inputs are represented determines the information that is made explicit and the costs at which certain operations can be carried out on that information, the feasibility and ease of these inferences depends greatly on the choice of *representation* [@marrVisionComputationalInvestigation1982; see also, e.g., @gigerenzerHowImproveBayesian1995; @griffithsProbabilisticModelsCognition2010; @kempStructuredStatisticalModels2009].
Hence, to explain how the mind makes a selection among choice alternatives, one needs to understand the output controlling properties, i.e., the applied selection criteria, the representation that is used to describe these properties, and the costs of inferring the descriptions in that representation, including their susceptibility to distortions from uncertainty or noise. The process is sketched in Figure 1.  

(ref:figure1) A rough computational level sketch of decision making as an information processing problem. To make a selection among choice alternatives on the basis of particular selection criteria, the mind requires explicit descriptions of the relevant properties before they can be evaluated. Descriptions are either readily available or must be inferred from the inputs.

```{r fig.cap= "(ref:figure1)"}
knitr::include_graphics("images/dm-sketch.png")
```

In what follows, the paper elaborates on the concepts touched upon thus far, certainly only a subset of the factors involved in the decision making process, yet central enough to illustrate a rather important principle:
Given that the mind is indeed sensitive to variations in the property values, the more accurately their descriptions are inferred, the more systematic the choices should become.
Importantly, this principle is not restricted to any one specific property. 
Rather, each selection criterion or combination thereof imposes constraints on the assessment of choice alternatives, leading to characteristic choice patterns that are eventually blurred by inaccurate property descriptions.

For the sake of example, I argue that a choice pattern robustly emerging in *decisions from experience* (DfE), the apparent underweighting of small probability events [e.g., @barronSmallFeedbackbasedDecisions2003; @hertwigDecisionsExperienceEffect2004; @weberPredictingRiskSensitivity2004; see also @wulffMetaanalyticReviewTwo2018, for a meta-analytic review], may be caused by the assessment constraints associated with a round-wise decision strategy.
This particular claim has already been made by @hillsInformationSearchDecisions2010 and follows quite directly from probability theory.
However, the current paper suggests to subordinate decision strategies to the adoption of selection criteria and addresses in some detail two "problems" in the context of DfE, in which descriptions of the properties of choice alternatives must be inferred from sampling data.

For one, there is an *induction problem*, well known from inferential statistics, according to which the sample size determines the margin of error within which any true property of a choice alternative can be inferred, given an otherwise perfect inference process. 
Yet, it follows that if an underweighting pattern is caused by the adoption of an arbitrary selection criterion, it is *a priori* predicted to become more stable with increasing sample size. 
This prediction is in line with the principle already stated above, i.e., that selection-criteria-induced choice patterns should become more systematic as property descriptions become more accurate.
Nevertheless, the prediction contrasts the explanation that underweighting is caused by the reliance on small samples [e.g., @foxDecisionsExperienceSampling2006; @hertwigDecisionsExperienceEffect2004; @hauDescriptionexperienceGapRisky2008; @ungemachAreProbabilitiesOverweighted2009; @rakowBiasedSamplesNot2008], highlighting that outside of the *statistical* models used to describe the choice data, *causal* decision making models of quite different nature may be at play, and that a rather important difference between these causal models resides in the selection criteria they incorporate.
I will elaborate on this matter as I proceed, however, to be clear from the outset, what the mind does in neither case is performing a probability weighting computation in its literal sense, but it processes the inputs in a way that the outputs approximate the solutions of what can be considered probability weighting on an abstract computational level [cf., e.g., @griffithsRationalUseCognitive2015]. 

For another, this paper approaches the problem of organizing the sampling data in such a way that it allows chains of inferences connecting the input set $I$ with the output set $I' \subset I$ that are algorithmically short and simple enough to be carried out by minds whose cognitive capacities are bounded [cf. @simonInvariantsHumanBehavior1990; @simonBehavioralModelRational1955]. 
This may be considered a *representation problem* since the inference chains are constructed around explicit descriptions of the properties of choice alternatives and representations are the "formal schemes" of symbols and rules with which these descriptions are derived [@marrRepresentationRecognitionSpatial1978, p. 270]. 
Specifically, representations differ in how they organize the information used to infer the descriptions of certain properties and these organizations determine the algorithms that can be built into the inference chain [@marrVisionComputationalInvestigation1982].
In this paper, *sampling strategies* in DfE are considered as representation systems used to organize the samples in a way that subserves the property inferences required by the application of particular selection criteria.
Though most of my expositions on the role of sampling strategies remain speculative, the core idea is not new to decision research [see, e.g., @hillsInformationSearchDecisions2010; @wulffHowShortLongrun2015].
By restating this idea and adopting some terms and concepts that have well defined meaning in math and cognitive science, I hope to integrate it into the rich study of the computationally limited mind as an adaptive cognitive system whose processes interact with the information structures in the environment or memory. 

The theoretical arguments sketched in this introduction are substantiated by a simulation study. 
For this purpose, the sampling and decision making processes are implemented in a computational model to simulate choice data from DfE.
The simulated data is modeled in cumulative prospect theory (CPT), a data model commonly used for describing decisions under risk and uncertainty [@goldsteinExpressionTheoryPreference1987; see also @tverskyAdvancesProspectTheory1992]. 
All simulations and analyses are reproducible---materials and instructions can be found on the GitHub repository.

# Inputs to the Decision Making Process and Property Descriptions 

By defining decision making as an information processing problem whose solution requires a selection among choice alternatives of the form described in (1), much weight is given to the properties of choice alternatives---whatever those may be for the moment---since it is only through them that any necessary distinction between the alternatives or collections thereof can be made. 
To stress this point, consider the power set $\mathcal{P}(I)$, which is the set of all possible subsets of $I$ (see example in Figure 2). 

(ref:figure2) A. The power set of the set $I$ including the choice alternatives A, B, and C. Black (white) circles indicate that an alternative does (not) possess a property. Each column displays a possible subset that could result from assessing whether the alternatives posses a relevant property. The properties determine the various relations among the choice alternatives. Note that properties resulting in the empty set $\{\}$ and the subset $\{A,B,C\}$ do not discriminate between choice alternatives. B. A Venn diagram visualizing the inclusion map $\iota : I' \mapsto I$. $\iota$ maps every element $i$ of the subset $I'$ to its image $i$, treated as element of the superset $I$.

```{r fig.cap= "(ref:figure2)"}
knitr::include_graphics("images/power-set.png")
```

Each of the subsets $I' \in \mathcal{P}(I)$ corresponds to a possible distinction between the choice alternatives in $I$ that could result from assessing for each alternative whether it possesses an arbitrary property (collection) or not [cf. @jostMathematicalConcepts2015, p. 16]. 
The concept of the power set thereby illustrates how different selection criteria can alter the consequential choice.
That is, in rather abstract terms, selection criteria are statements regarding the properties of choice alternatives that the mind evaluates as either true or false during the decision making process; accordingly, the subset $I'$ only contains the alternatives for which the statement is evaluated to be true.
It follows that if there is some variance in the properties across choice alternatives and the properties are not perfectly correlated, changing the selection criteria can eventually change the subset $I'$.

## What Are the Choice Alternatives and Their Properties? 

Given (3), it is evident that the prospects can only be distinguished by the elements of their tuples. 
These elements are, generally speaking, symbols, some of which describe properties on their own, e.g., the outcome $\omega$, whereas other properties can only be described by collections of symbols, e.g., the sample space $\Omega$ by a set of outcomes as in (2.1), or more complex combinations thereof, e.g., the weighted average which is obtained by first multiplying all outcomes in $\Omega$ by their respective probabilities in $P$ and then summing the resulting products.^[I do not refer to this quantity as expected value, since the term is reserved for random variables, which were not introduced so far.]
In turn, for choices between prospects, selection criteria are statements about the elements of their tuples that are true or false and these statements imply relations among prospects that are at least nominal, but may also draw on other levels of measurement.  

## Inferring Property Descriptions from Sampling Data

Note that a selection criterion may refer to a property for which the raw input, i.e., the symbols, their organization, and the information they encode, do not yet provide an explicit description.
Even more so, it has been repeatedly stated that for quite many decisions the mind faces, it is simply not possible to draw on direct descriptions of the properties, since they are part of the distal environment  [e.g., @brunswikOrganismicAchievementEnvironmental1943; @fiedlerExplainingSimulatingJudgment1996; @hertwigDescriptionexperienceGapRisky2009; see also @brunswikRepresentativeDesignProbabilistic1955; @brunswikPerceptionRepresentativeDesign1956; @kozyrevaInterpretationUncertaintyEcological2021].
In either case, some form of description must be inferred from whatever information the input provides about the property in question.
Consider first the counterfactual case of the prospect whose tuple is not part of the distal environment but is directly described. 
Since all information about the prospect is given, one may in principle consider the input complete, yet, the tuple implies properties of the prospect which are not explicitly described.
For example, to obtain the description of the prospect's weighted average, still a calculus according to the algebraic rules described in the preceding paragraph must be carried out. 
In general, in cases like the one just considered, where the properties are not distal and all information about them is available, property inferences take the form of a mere transformation, where the symbols from the input are ordered and combined according to some transformation rules [cf. @marrVisionComputationalInvestigation1982, p. 20].

In natural world decisions, however, the properties of choice alternatives are often distal and amenable only through their probabilistic relation to proximal cues or samples, which provide the input to the decision making process [cf. @brunswikOrganismicAchievementEnvironmental1943].
Such a proximal information basis is obtained by experience or, more technically, by *sampling*, and is neither consistent nor complete but varies in its degree of representativeness. 
In turn, the mind is not merely required to transform the inputs but to draw inductive inferences to arrive at property descriptions which then, by definition, are only probable. 
Importantly, the probability, or accuracy, of the description depends on both the sampling process that determines the representativeness of the sample and the use of the probabilistic information that is entailed in the sample [e.g., @fiedlerBewareSamplesCognitiveecological2000]. 

To adapt (3) for the case of decisions from experience [@hertwigDecisionsExperienceEffect2004], the tuples $(\Omega, \mathcal{F}, P)$ must be replaced by samples, which in this paper are treated as collections of independent and identically distributed (i.i.d.) random variables $X$.^[Note that this paper considers the counterfactual case where samples are random, although it has been stated that in the natural world samples are "virtually never random" [@fiedlerBewareSamplesCognitiveecological2000, p. 660]. To account for non-random sampling, e.g., in the form of sampling biases [e.g., @fiedlerBewareSamplesCognitiveecological2000] or dynamic information structures [e.g., @cohenEffectPerceivedPatterns2021; @plonskyRelianceSmallSamples2015], the i.i.d-assumption would need to be dropped, which is out of the scope of this paper.]
Specifically, random variables are defined as a measurable function 

$$
X: (\Omega, \mathcal{F})  \mapsto (\Omega', \mathcal{F'}) 
\; ,
\tag{4}
$$

where $\Omega'$ is a set of real numbered values $X$ can take and $\mathcal{F'}$ is a set of subsets of $\Omega'$. 
I.e., $\Omega$ maps into $\Omega'$ such that correspondingly each subset $A' \in \mathcal{F'}$ has a pre-image $X^{-1}A' \in \mathcal{F}$, which is the set $\{\omega \in \Omega: X(\omega) \in A'\}$ [@kolmogorovFoundationsTheoryProbability1950, p. 21].


$$
\begin{aligned}
  & \iota : I' \mapsto I, \ \text{where} \ I = \{X_{1i}, ..., X_{ki}\} \\
  & i \in \{1, ..., N\} 
  \; .
\end{aligned}
\tag{5}
$$


To provide a formal definition of sampling in risky choice, we make use of the mathematical concept of a random variable and start by referring to a prospect as *"risky"* in the case where $p(\omega) \neq 1$ for all $\omega \in \Omega$.
Here, risky describes the fact that if agents would choose a prospect and any of its outcomes in $\Omega$ must occur, none of these outcomes will occur with certainty. 
It is acceptable to speak of the occurrence of $\omega$ as a realization of a random variable $X$ defined on a prospect iff the following conditions (1) and (2) are met: 


(2) The mapping is such that $X(\omega) = x \equiv \omega$. 

In (2), $x \equiv \omega$ means that the realization of a random variable $X(\omega) = x$ is numerically equivalent to its pre-image $\omega$.  
Given conditions (1) and (2), we denote any observation of $\omega$ as a *"single sample"*, or realization, of a random variable defined on a prospect and the act of generating a sequence of single samples in discrete time as *"sequential sampling"*. 
Note that, since random variables defined on the same prospect are independent and identically distributed (iid), the weak law of the large number applies to the relative frequency of occurrence of an outcome $\omega$ in a sequence of single samples originating from the same prospect.
Thus, long sample sequences in principle allow to obtain the same information about a prospect by sampling as by symbolic description.

Consider now a choice between prospects $1, ..., k$.
To construct a stochastic sampling model for DfE, we assume that agents base their decision on the information related to these prospects and define a decision variable as a function of the latter:

$$
D:= f((\Omega_1, \mathcal{F}_1, P_1), ..., (\Omega_k, \mathcal{F}_k, P_k))
\;.
$$

Now, since in DfE no symbolic descriptions of the prospects are provided, the model must be restricted to the case where decisions are based on sequences of single samples originating from the respective prospects:

$$
D := f(X_{i1}, ..., X_{ik}) 
\; ,
$$

where $i \in \{1, ..., N\}$ denotes a sequence of length $N$ of random variables that are iid.  

Concerning the form of $f$ and the measures it utilizes, it is quite proper to say that they reflect our assumptions about the exact kind of information agents process and the way they do and that these choices should be informed by psychological theory and empirical protocols. 
Taking the case of different sampling and decision strategies previously assumed to play a role in DfE, the following section demonstrates how such assumptions can be explicated in a stochastic model that builds on the sampling approach outlined so far.  

# Evaluation of Choice Alternatives and Outputs of the Decision Making Process

...

# Sampling Strategies as Representation Systems

...

# Simulation Study

...

The switching probability $s$ is the probability with which agents draw a single sample from the prospect they did not get their most recent single sample from.
$s$ is varied between .1 to 1 in increments of .1.
The two boundary parameters resemble the concept of a decision threshold, i.e., if a prospect reaches a boundary, it is chosen by the synthetic agent.
The boundary type is either the minimum number of comparisons any prospect must win (absolute boundary) or the minimum difference between the number of won comparisons (relative boundary).
The boundary value $a$ is varied between 1 to 5 in increments of 1.

## Test set

For each parameter combination of the generating model, 100 synthetic agents are presented with 60 choices problems.
In sum, 100 (parameter combinations) x 100 (agents) x 60 (choices) = 600,000 choices are simulated.
We test a set of 2-prospect choice problems, where one of the prospects contains a safe outcome, i.e., $p(\omega) = 1$ and the other two outcomes where all $p(\omega) \neq 1$.
Both outcomes and probabilities are drawn from uniform distributions, ranging from 0 to 20 for outcomes and from .01 to .99 for probabilities of the smaller outcome of the risky prospect.
To omit dominant prospects within a choice problem, outcomes of the safe prospect always fall between both outcomes of the risky prospect.
Table A1 in [Appendix 2][Appendix 2: Choice Problems] contains the test set of 60 choice problems, which were sampled from an initial set of 10,000.
Sampling of gambles was stratified, randomly drawing an equal number of 20 gambles with no, an attractive, and an unattractive rare outcome.
Risky outcomes are considered *"rare"* if their probability is $p < .2$ and *"attractive"* (*"unattractive"*) if they are higher (lower) than the safe outcome.

## Results

...

```{r}

# read cpt data

cols <- list(.default = col_double(),
             boundary = col_factor(),
             a = col_factor(),
             parameter = col_factor())
cpt_long <- read_csv("data/estimates/estimates_cpt.csv", col_types = cols)

# store convergence diagnostics

gel_92 <- cpt_long %>% select(s, boundary, a, parameter, Rhat, n.eff) 
```

For each distinct parameter combination, we ran 20 chains of 40,000 iterations each, after a warm-up period of 1000 samples.
To reduce potential autocorrelation during the sampling process, we only kept every 20th sample (thinning).
The potential scale reduction factor $\hat{R}$ [@gelmanInferenceIterativeSimulation1992] was $\leq$ `r round(max(gel_92$Rhat), 3)` for all parameters, indicating good convergence.
The minimum effective sample size was `r min(gel_92$n.eff)`.


### Plausibility Check: Relationship between Switching Probability and Trial Length

```{r include=FALSE}

# read choice data 

cols <- list(.default = col_double(),
             boundary = col_factor(),
             gamble = col_factor(),
             rare = col_factor(),
             agent = col_factor(),
             choice = col_factor())
choices <- read_csv("data/choices/choices.csv", col_types = cols)

# get median trial length for each parameter combination

trial_length <- choices %>% 
  group_by(s, boundary, a) %>% 
  summarise(med = median(n_sample))
```

The median length of trials, i.e., the number of single samples drawn in a trial, generated by different parameter combinations ranged from `r min(trial_length$med)` to `r max(trial_length$med)`.
As expected, the scatter plot below shows an inverse relationship between switching probability and trial length.
I.e., the lower the switching probability, the larger become the sample sequences on which each comparison between prospects is based, which in turn leads to longer trials.  
This effect is particularly pronounced for low probabilities such that the increase in trial length accelerates as switching probability decreases.


```{r eval=FALSE}

# get median trial length for each switching probability 

trial_length_s <- choices %>% 
  group_by(s) %>%
  summarise(med = median(n_sample))

# plot

trial_length %>%
  ggplot(aes(x = s, y = med)) +
  geom_jitter(color = "#CECECE", size = 3) +
  geom_point(data = trial_length_s, aes(color = s), size = 3) +
  geom_path(data = trial_length_s, aes(color = s)) +
  scale_color_scico(palette = "buda") + 
  scale_x_continuous(breaks = seq(0, 1, .1)) + 
  scale_y_continuous(breaks = seq(0, 120, 10)) +
  labs(title = "Trial Length", 
       x ="Switching Probability",
       y = "Median Trial Length", 
       color="Switching Probability") + 
  theme_apa()
```

### Probability Weighting Function

```{r eval=FALSE}

# tidy CPT data: parameters as separate columns 

cpt_wide <- cpt_long %>% 
  select(s, boundary, a, parameter, mean) %>% 
  pivot_wider(names_from = parameter, values_from = mean)
```

The figures below display the estimates of the $\gamma$ and $\delta$ parameter of the probability weighting function [@prelecProbabilityWeightingFunction1998] fitted to DfE simulated for different parameter values of the generating model.
The estimates are plotted against the switching probability, where each panel represents a distinct boundary type and level, i.e., number of comparisons. 
Grey dots represent agent level estimates, colored dots represent the mean across all agent level estimates. 

Most significantly, there is a strong relationship between the switching probability in the generating model and the $\gamma$ parameter.
I.e., large switching probabilities, which are indicative for small sample sequences, lead to larger estimates for $\gamma$. 
The resulting strong curvature leads to a compression of probabilities in the lower and upper range, reflecting underweighting of small probabilities and overweighting of large probabilities. 
This pattern is robust for varying degrees of the boundary level, except for $a = 1$. 
The latter deviation may be explained by the potential scale reduction factors for the respective parameter estimates, which indicate that the MCMC chains did not converge (see [Appendix 3][Appendix 3: Convergence Diagnostics for CPT Parameters]).   

```{r eval=FALSE}

# Density Plot 

cpt_long %>% 
  filter(parameter == "gamma" | parameter == "delta") %>% 
  ggplot(aes(x = s, y = mean)) +
  geom_density_2d_filled(contour_var = "ndensity") + 
  scale_fill_scico_d(palette = "acton") +
  scale_color_scico_d(palette = "acton") + 
  scale_x_continuous(breaks = seq(0, 1, .2)) + 
  scale_y_continuous(limits = c(0,2), breaks = seq(0, 2, .2)) +
  labs(x ="Switching Probability",
       y = "Parameter Value",  
       fill="Density") + 
  facet_grid(parameter~a) + 
  theme_apa()
```

```{r eval=FALSE}

# Scatter Plots 

# Gamma 

cpt_wide %>% 
  ggplot(aes(x = s, y = gamma, color = s)) +
  geom_point(size = 2) +
  geom_line(size = 1) +
  scale_color_scico(palette = "buda") + 
  scale_x_continuous(breaks = seq(0, 1, .2)) + 
  scale_y_continuous(breaks = seq(0, 2, .2)) +
  facet_grid(boundary~a) +
  labs(title = expression(paste("Curvature ", gamma)),
       x ="Switching Probability",
       y = expression(gamma), 
       color="Switching Probability") + 
  theme_minimal()

# Delta

cpt_wide %>% 
  ggplot(aes(x = s, y = delta, color = s)) +
  geom_point(size = 2) +
  geom_line(size = 1) +
  scale_color_scico(palette = "buda") + 
  scale_x_continuous(breaks = seq(0, 1, .2)) + 
  scale_y_continuous(breaks = seq(0, 2, .2)) +
  facet_grid(boundary~a, switch = "y") +
  labs(title = expression(paste("Curvature ", delta)),
       x ="Switching Probability",
       y = expression(delta), 
       color="Switching Probability") + 
  theme_minimal()
```

Below, the resulting probability weighting functions are displayed. 

```{r eval=FALSE}

# Weighting Functions 

## compute decision weights 

cpt_w <- cpt_wide %>% 
  select(-c(alpha, rho)) %>% 
  expand_grid(ep = seq(0, 1, .1)) %>% #
  mutate(w = round(  (delta * ep^gamma)/ ((delta * ep^gamma)+(1-ep)^gamma), 2)) 

## plot curves

cpt_w %>% 
  group_by(boundary, a, s) %>% 
  ggplot(aes(x = ep, y = w, color = s)) +
  geom_path() + 
  scale_color_scico(palette = "grayC") + 
  scale_x_continuous(breaks = seq(0, 1, .2)) +
  scale_y_continuous(breaks = seq(0, 1, .2)) + 
  labs(x ="Experienced Probability",
       y = "Probability Weighting", 
       color="Switching Probability") + 
  theme_minimal()

cpt_w %>% 
  group_by(boundary, a, s) %>% 
  ggplot(aes(x = ep, y = w, color = s)) +
  geom_path() + 
  scale_color_scico(palette = "buda") + 
  scale_x_continuous(breaks = seq(0, 1, .2)) +
  scale_y_continuous(breaks = seq(0, 1, .2)) + 
  facet_wrap(~a) +
  labs(x ="Experienced Probability",
       y = "Probability Weighting", 
       color="Switching Probability") + 
  theme_minimal()
```

The false response rates for different parameter values of the generating model reflect the probability weighting patterns from above. 
That is, the strong curvature resulting from large switching probabilities produces an underweighting of small probabilities. This in turn has the effect that the rarity of an attractive (unattractive) outcome leads to higher rates of choosing the safe (risky) prospect although the risky (safe) prospect had a higher experienced expected value.

```{r eval=FALSE}

# compute false response rates

fr_rates <- choices %>% 
  mutate(ev_ratio_exp = round(a_ev_exp/b_ev_exp, 2), # experienced EV (eEV)
         norm = case_when(ev_ratio_exp > 1 ~ "A", ev_ratio_exp < 1 ~ "B")) %>% # normative choice according to eEV
  filter(!is.na(norm)) %>% # exclude trials with normative indifferent prospects
  group_by(s, boundary, a, rare, norm, choice) %>% # group correct and incorrect responses
  summarise(n = n()) %>% # absolute numbers 
  mutate(rate = round(n/sum(n), 2), # response rates 
         type = case_when(norm == "A" & choice == "B" ~ "false safe", norm == "B" & choice == "A" ~ "false risky")) %>% filter(!is.na(type))  # remove correct responses

# violin scatter plot

fr_rates %>% 
  ggplot(aes(x = rare, y = rate, color = s)) +
  geom_quasirandom(aes(shape = type), size = 3) +  
  scale_y_continuous(breaks = seq(0, 1, .2)) +
  scale_color_scico(palette = "buda") + 
  scale_shape_manual(values=c(8, 16))+
  labs(x = "Rare Event", 
       y = "False Response Rate", 
       color = "Switching Probability",
       shape = "False Response") + 
  theme_minimal() 
```

```{r eval=FALSE}
fr_rates %>% 
  ggplot(aes(a, s, fill = rate)) + 
  geom_tile(colour="white", size=0.1) +
  scale_fill_scico(palette = "buda") + 
  facet_grid(type ~ fct_relevel(rare, "attractive", "none", "unattractive"), switch = "y") +
  scale_x_continuous(expand=c(0,0), breaks = seq(1, 5, 1)) +
  scale_y_continuous(expand=c(0,0), breaks = seq(.1, 1, .1)) +
  labs(title = "False Response Rates", 
       x = "a", 
       y= "s", 
       fill = "% False Responses") + 
  theme_minimal() 


fr_rates %>% 
  ggplot(aes(s, rate, color = s)) + 
  facet_grid(type ~ fct_relevel(rare, "attractive", "none", "unattractive"), switch = "y") +
  geom_jitter(size = 3) + 
  scale_x_continuous(breaks = seq(0, 1, .1)) +
  scale_y_continuous(breaks = seq(0, 1, .1)) +
  scale_color_scico(palette = "buda") + 
  labs(title = "False Response Rates", 
       x = "s", 
       y= "% False Responses", 
       color = "a") + 
  theme_minimal()
```

### Value Function 

```{r eval=FALSE}

# Density Plot 

cpt_wide %>%
  ggplot(aes(x = s, y = alpha)) +
  geom_density_2d_filled(contour_var = "ndensity") + 
  scale_fill_scico_d(palette = "grayC") +
  scale_x_continuous(breaks = seq(0, 1, .2)) + 
  scale_y_continuous(limits = c(0,2), breaks = seq(0, 2, .2)) +
  labs(x ="Switching Probability",
       y = "Parameter Value",  
       fill="Density") + 
  facet_wrap(~a, nrow = 1) + 
  theme_minimal()
```

```{r eval=FALSE}
# value function 

## compute values 

cpt_v <- cpt_wide %>% 
  select(-c(gamma, delta, rho)) %>% 
  expand_grid(x = seq(0, 20, 2)) %>%  
  mutate(v = round(x^alpha, 2)) 

## plot curves

cpt_v %>% 
  group_by(boundary, a, s) %>% 
  ggplot(aes(x = x, y = v)) +
  geom_path(aes(color = s)) +
  scale_color_scico(palette = "grayC") + 
  scale_x_continuous(breaks = seq(0, 20, 5)) +
  scale_y_continuous(breaks = seq(0, 20, 5)) + 
  labs(title = "Value Function",
       x ="Objective Value",
       y = "Subjective Value", 
       color="Switching Probability") + 
  theme_minimal()

cpt_v %>% 
  group_by(boundary, a, s) %>% 
  ggplot(aes(x = x, y = v)) +
  geom_path(aes(color = s)) +
  scale_color_scico(palette = "buda") + 
  scale_x_continuous(breaks = seq(0, 20, 5)) +
  scale_y_continuous(breaks = seq(0, 20, 5)) + 
  facet_wrap(~a) +
  labs(title = "Value Function",
       x ="Objective Value",
       y = "Subjective Value", 
       color="Switching Probability") + 
  theme_minimal()
```

```{r eval=FALSE}

# alpha
cpt_wide %>% 
  ggplot(aes(x = s, y = alpha, color = s)) +
  geom_point(size = 2) +
  geom_line(size = 1) +
  scale_color_scico(palette = "buda") + 
  scale_x_continuous(breaks = seq(0, 1, .2)) + 
  scale_y_continuous(breaks = seq(0, 2, .2)) +
  facet_grid(boundary~a, switch = "y") +
  labs(title = expression(alpha),
       x ="Switching Probability",
       y = expression(alpha), 
       color="Switching Probability") + 
  theme_minimal()
```

# Discussion and Conclusion


# References
