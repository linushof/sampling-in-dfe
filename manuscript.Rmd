---
title             : |
  Sampling Strategies in Decisions from Experience: Property Representation and Probability Weighting Approximation
  
shorttitle        : "Sampling strategies"

author: 
  - name          : "Linus Hof"
    affiliation   : "1"
    corresponding : yes
    address       : "Institute of Psychology, Heidelberg University, Hauptstr. 47 – 51, 69117 Heidelberg"    
    email         : "linus.hof@stud.uni-heidelberg.de"
    
affiliation:
  - id            : "1"
    institution   : "Heidelberg University"
    
authornote: |
 This manuscript is a dynamic document which can be reproduced using the materials and instructions provided on the GitHub repository: https://github.com/linushof/sampling-in-dfe. The current version of the manuscript, created from the commit with the hash `r repro::current_hash()`, is prepared for submission as a master's thesis in fulfillment of the requirements for the degree Master of Science (M.Sc.) at Heidelberg University, Faculty of Behavioural and Cultural Studies, Institute of Psychology. Supervisors:
  
  \indent
  1. Prof. Dr. Thorsten Pachur, Technical University of Munich
  
  \indent
  2. Dr. Veronika Zilker, Max Planck Institute for Human Development
 
abstract: "In decisions from experience, systematic choices between prospects are based on the assessment of differences in latent properties. Yet, several properties can be used to distinguish among the prospects. To this end, this paper presents a sampling and accumulation model that allows sampling  strategies—i.e., the probability of sampling outcomes from different prospects in direct succession (switching probability)—to alter which differences in the latent properties evidence is accumulated for. Specifically, the proposed model sequentially samples outcomes from two prospects and accumulates the results obtained from a sequence of ordinal comparisons between sample means, with switching probabilities determining the size of the samples underlying each comparison and thresholds determining how much comparisons a prospect must win in order to be chosen. A computational implementation of the model is used to simulate the respective information-processing chains upfront choices between a safe and a two-outcome prospect, while varying switching probabilities and thresholds. The analysis of the simulation data shows that, depending on whether the accumulation process unfolds over mean comparisons based on small or large samples, evidence is accumulated for differences either in the probability to produce a higher outcome most of the time or in the expected value. The respective choice patterns reflect an as-if underweighting of rare outcomes or expected value maximization, both of which become more robust with increasing thresholds. The analysis moreover shows how the distinct choice patterns resulting from differences in the information-processing chains translate to the parameters of cumulative prospect theory’s value and weighting function."
  
keywords          : "risky choice, information sampling, evidence accumulation, cognitive modeling, cumulative prospect theory"
wordcount         : ""

bibliography      : references_sampling-in-dfe.bib
csl               : apa.csl

figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : no
linkcolor         : "blue"
link-citations    : true
mask              : no
draft             : no

classoption       : "man"
documentclass     : "apa7"
output: papaja::apa6_pdf

header-includes:
   - \usepackage[capposition=top]{floatrow}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, #omit messages
                      fig.align = "l", #align figures to left margin
                      fig.pos = "t", #display figures at the top of a page
                      fig.height=7, 
                      fig.width=10)
```

```{r packages, include=FALSE}
#load required packages
pacman::p_load(papaja,
               knitr,
               readr,
               tidyr, 
               dplyr,
               ggplot2,
               viridis,
               ggpubr,
               latex2exp)
```

<!-- Introduction -->

The human mind is a cognitive system that operates on inputs from an environment or memory, and in the domain of decision making, such inputs provide information about the alternatives between which people can choose.
In fact, irrespective of their exact mathematical specification or computational implementation, decision models generally take as inputs information about a set of choice alternatives, each possessing some defining *properties*, and return a subset of chosen alternatives as outputs [@heOntologyDecisionModels2020].
Respectively, decision making can be understood as an information-processing problem whose solution requires a selection among choice alternatives.

Now, let a *prospect* be a choice alternative that possesses only two kinds of fundamental properties: the possible outcomes of the alternative (e.g., gains or losses of some amount) and the probabilities with which these outcomes occur following the choice of the alternative.
Importantly, the information that the inputs provide about these properties can come in different forms.
Specifically, in *decisions from description* (DFD), the inputs take the form of explicit and complete descriptions of all outcomes and probabilities.
Yet, in *decisions from experience* [DFE, @hertwigDecisionsExperienceEffect2004], these properties are latent and therefore not known with certainty, but they must be inferred from the relative frequencies with which the outcomes occurred in the past, e.g., when the prospect was chosen in similar past decisions.
The inputs to DFE therefore take the form of sampled outcomes.
Although these distinct input forms may in principle carry the same information about a given set of prospects, behavioral decision research has so far produced a large body of papers indicating that---taking a quite general perspective---there are robust differences between the choices that are made in DFD and DFE, leading to the notion of the *description-experience gap* [@hertwigDescriptionexperienceGapRisky2009].
In one reading of the gap,^[<!--Open footnote-->See @hertwigConstructBehaviorGap2018, for a discussion on the interpretation of the gap.<!--Close footnote-->]
choice patterns in DFD deviate from the solutions of expected value (EV) maximization, as if small-probability outcomes are given more weight than would be warranted by their objective probabilities;
in turn, in DFE, choice patterns deviate from the solutions of EV maximization, as if the same small-probability outcomes are given less weight than would be objectively warranted [e.g., @barronSmallFeedbackbasedDecisions2003; @hertwigDecisionsExperienceEffect2004; @weberPredictingRiskSensitivity2004; @erevAnomaliesForecastsDescriptive2017; @regenwetterConstructBehaviorGap2017; see @wulffMetaanalyticReviewTwo2018, for a comprehensive meta-analytic review].
Hereafter, these choice patterns are referred to as the *as-if overweighting* and *as-if underweighting of rare outcomes*, respectively.

Similar to explanations for other behavioral phenomena that rest on the assumption that the mind is sensitive to the composition of the *samples*---i.e., sets of sampled outcomes---on which it operates [cf. @fiedlerBewareSamplesCognitiveecological2000], an explanation for the as-if underweighting of rare outcomes may be build on the assumption that the mind is sensitive to the information provided by small samples [@hertwigDecisionsExperienceEffect2004; @plonskyRelianceSmallSamples2015; see also @erevChoicePredictionCompetition2010; @erevAnomaliesForecastsDescriptive2017, for the performance of models assuming reliance on small samples in prediction competitions]:
Specifically, following from the laws of large numbers [cf., e.g., @kolmogorovFoundationsTheoryProbability1950], the relative frequencies with which the prospect's outcomes occur in a sample of infinite size converge almost surely to the respective objective probabilities.
In such a case---or in the less strict case of large samples---, then, the binomial distribution of each outcome can be approximated by a symmetric normal distribution.^[<!--Open footnote-->The binomial distribution of an outcome is the probability distribution of the number of times an outcome occurs in a sample. According to the *de Moivre-Laplace theorem* [see, e.g., @georgiiStochastikEinfuhrungWahrscheinlichkeitstheorie2015], the binomial distribution can be approximated by a normal distribution given a large sample. Respectively, the relative relative frequencies with which an outcome occurs in a large sample is predicted to correspond to the objective probability of the outcome most of the time and is not predicted to be lower more often than higher or vice versa.<!--Close footnote-->]
However, for samples of small size, the binomial distribution associated with small-probability outcomes is positive skewed, therefore causing the relative frequencies with which these outcomes occur in the sample to be smaller rather than larger than their latent objective probabilities.

In fact, in DFE, people tend to sample only a small number of outcomes from each prospect [@hertwigDecisionsExperienceEffect2004; @foxDecisionsExperienceSampling2006; @hertwigDecisionsExperienceWhy2010; @rakowBiasedSamplesNot2008; see also @wulffMetaanalyticReviewTwo2018], which is a sufficient condition for the reliance on small samples in the evaluation of prospects.
Yet, the as-if underweighting of rare outcomes may appear, even if the overall number of sampled outcomes is large and the relative frequencies closely resemble the latent objective probabilities [@hauDescriptionexperienceGapRisky2008; @hauDecisionsExperienceStatistical2010; @ungemachAreProbabilitiesOverweighted2009; @wulffMetaanalyticReviewTwo2018].
While this latter finding does not preclude the reliance on small samples---i.e., the mind may rely on only a portion of the sampled outcomes, discount them, or, as proposed in the current paper, distribute them over multiple smaller samples---, it suggests that an explanation for the as-if underweighting of rare outcomes cannot be reduced to inaccurate inferences about the latent properties of prospects that are caused by frugal sampling and the implied sampling error.
Rather the opposite, this paper presents a simple sampling and accumulation model that suggests that the as-if underweighting of rare outcomes can be the consequence of an accurate assessment of differences among prospects in a latent property [but see @hertwigDescriptionexperienceGapRisky2009; @plonskyRelianceSmallSamples2015;  @wulffMetaanalyticReviewTwo2018, for alternative explanations].

Therefore, consider first the finding that *sampling strategies* were indicative for the final choice in DFE.
Specifically, in one paradigm used to study DFE, namely, the sampling paradigm [@weberPredictingRiskSensitivity2004], before making a final choice between prospects with latent properties, people can, as much as they want, sequentially sample the prospects' outcomes according to their objective probabilities.
Considering this paradigm and the choice between two prospects, @hillsInformationSearchDecisions2010 distinguished sampling strategies along the frequency of switches between the two prospects during the sampling phase,^[<!--Open footnote-->Note that @hillsInformationSearchDecisions2010 proposed two paradigmatic sampling strategies, where prospects are either switched just once (comprehensive sampling) or after each sampled outcome (piecewise sampling).
Nevertheless, in their analyses of empirical sampling data, they used the number of switches between prospects relative to the overall number of sampled outcomes from both prospects (switching frequency) as an approximate measure for the two proposed sampling strategies, and further acknowledged that "many [sampling] strategies will fall on the continuum between [the two paradigmatic strategies]" [@hillsInformationSearchDecisions2010, p. 1788].
Respectively, in the current paper sampling strategies are defined as switching probabilities.
<!--Close footnote-->] 
and proposed two different decision strategies that people may adopt.
That is, for a summary strategy, it is assumed that the prospect is chosen which produced the greater mean across all sampled outcomes.
In turn, for a round-wise strategy, it is assumed that over multiple rounds two sampled outcomes---i.e., one from each of the prospects---are compared and that the prospect is chosen which won the comparison in most rounds.
Then, @hillsInformationSearchDecisions2010 found that the choices of people who switched frequently between prospects during the sampling phase were better predicted by a round-wise strategy (rather than a summary strategy), and that this predictive pattern reversed for people who switched infrequently.

Now, one explanation for such a reversed predictive pattern would be if the differences in the sampling strategies determine which of the two decision strategies is used.
To this end, this paper presents a computational model that provides a link between *switching probabilities*---i.e., the probability of sampling outcomes from different prospects in direct succession during the sampling phase---and the decision strategies.
Specifically, the proposed model accumulates the outcomes obtained from the comparisons between sample means, with switching probabilities determining the size of the samples underlying each mean comparison and thresholds determining how much (more) of such comparisons a prospect must win in order to be chosen.
Accordingly, the model is such that the higher (lower) the switching probabilities and the higher (lower) the thresholds, the more the accumulation process resembles the round-wise (summary) strategy.

The current paper discusses and demonstrates in a computational analysis how such a simple accumulation model can explain an as-if underweighting of rare outcomes, even if a large number of sampled outcomes is fully accounted for.
More specifically, since the switching probabilities alter the size of the samples underlying each mean comparison, the model predicts the switching probabilities to affect whether a low-probability outcome contributes to the majority of required mean comparisons about as much as would be warranted by its objective probabilities, or whether it contributes rather less.
Respectively, if the small-probability outcome is smaller (larger) than the EV, high switching probabilities cause the mean to be an inflated (deflated) estimate of the EV in most of the comparisons, which can translate to an as-if underweighting of rare outcomes, irrespective of what the thresholds determine the required number of mean comparisons to be.
Yet, since the EV is not the only property which can be used to distinguish among the prospects, the proposed model shows how the mind may rely on different sampling strategies to change which differences in the latent properties of prospects evidence is accumulate for.
Specifically, for low switching probabilities, the accumulation process unfolds over mean comparisons based on large samples and is therefore more indicative for differences in the EV; in turn, for high switching probabilities, the accumulation process unfolds over mean comparisons based on small samples and is therefore more indicative for differences in the probability to produce a higher outcome than the respective other prospect most of the time.
In either case, then, the model implements a speed-accuracy trade-off of the form that the respective differences in the latent properties are more accurately assessed, the larger the thresholds are, i.e., the more evidence must be accumulated in favor of a prospect.

To substantiate the discussion, the model is used to simulate the accumulation process for different combinations of switching probabilities and thresholds and to predict choices between a two-outcome prospect and a safe prospect, respectively.
Considering choice rates and parameter estimates of cumulative prospect theory [CPT, @tverskyAdvancesProspectTheory1992; @wakkerAxiomatizationCumulativeProspect1993], the computational analysis shows that the choices converge to the solutions of EV maximization for low switching probabilities, but take the form of an as-if underweighting of rare outcomes for high switching probabilities.
Importantly, the analysis also shows that the differences between switching probabilities become more pronounced with increasing thresholds.
In other words, the proposed model predicts an as-if underweighting of rare outcomes to occur when high switching probabilities cause the accumulation process to unfold over mean comparisons that are based on small samples.
Thus, the analysis substantiates the claim that not only the reliance on just a portion of a large number of sampled outcomes can explain an as-if underweighting of rare outcomes in DFE, but also the reliance on multiple or many small samples.
Moreover, the analysis shows that an as-if underweighting of rare outcomes cannot be equated with inaccurate inferences about latent properties---e.g., the EVs---that carry over to the subsequent choices.
Rather the opposite, an as-if underweighting of rare outcomes can also be caused by an accurate assessment of the differences among prospects in the latent probability to produce a higher outcome most of the time.
Before presenting the model and the computational analysis, the following section provides a formal definition of prospects and reviews how CPT in general and its weighting function in particular can be used to capture deviations from EV maximization.

# Prospects and the Description of Choices in CPT

Since there is an uncountable number of choices people confront in the natural world, behavioral decision research routinely abstracts from choices between particular choice alternatives, e.g., the choice between job offers, political parties to vote for, investment plans, and whatnot.
Rather, with the choice between at least two prospects, it studies a case which is counterfactual in that it omits the many particularities of each choice situation, but retains in the form of prospects the fundamental properties that almost all choice alternatives are assumed to possess.
These fundamental properties are considered the possible outcomes of a choice alternative and the probabilities with which these outcomes occur following the choice of the alternative.
Roughly speaking, then, all choice alternatives that can be fully described by their outcome-probability pairs are prospects.
As such, prospects can be understood as the distribution of a discrete random variable, for which the following section briefly provides an axiomatic basis. 

## Formal Definition of Prospects

Following @kolmogorovFoundationsTheoryProbability1950 and adopting the symbolic notation from @georgiiStochastikEinfuhrungWahrscheinlichkeitstheorie2015, let the tuple $(\Omega, \mathcal{F}, P)$ be a probability space.
Accordingly, $\Omega$ is a finite sample space with each element $\omega \in \Omega$ denoting a possible consequence of choosing the respective prospect.
$\mathcal{F}$ is the power set $\mathcal{P}(\Omega)$ with each element $A \in \mathcal{F}$ being a subset of $\Omega$, also denoted a random event.
$P$ is the probability measure
$$
P: \mathcal{F} \to [0,1]
\tag{1}
$$
assigning the elements of $\mathcal{F}$ a probability $0 < p(A) \leq 1$ with $P(\Omega) = 1$.
Now, the random variable is a function
$$
\begin{aligned}
  X : (\Omega, \mathcal{F}) &\to (\Omega', \mathcal{F'})  \\
  \omega &\mapsto x
  \; ,
\end{aligned}
\tag{2}
$$
where $(\Omega', \mathcal{F'})$ is a measurable space with each element $x \in \Omega'$ denoting a possible outcome of a prospect and each element $A' \in \mathcal{F'}$ being a subset of $\Omega'$.
An outcome's probability $p_X(x)$ is then provided by the pushforward measure
$$
P' : \mathcal{F'} \to [0,1]
\tag{3}
$$
with 
$$
P'(A' \in \mathcal{F'}) := P(\{\omega: X(\omega) = x \in A'\})
\; .
\tag{4}
$$
Note that the measure in (3) and (4), respectively, is a random variable's distribution and therefore a prospect. 
Accordingly, given a choice between $1, ..., k$ prospects, the inputs from the environment or memory should provide information about the set
$$
\{P'^1, ... , P'^k\}
\; ,
\tag{5}
$$
where each element $P'$ can itself be considered a set of outcome-probability pairs $\{(x_i, p_X(x_i)\}_{i \in \mathbb{N}}$.

## CPT and the Concept of Probability Weighting

The choices people actually make between prospects are often described in terms of deviations from the principle of EV maximization, according to which the prospect with the largest EV
$$
EV = \sum_i^n x_i \times p_X(x_i)
\tag{6}
$$ 
should be chosen.
To *describe* how people's actual choices deviate from EV maximization [see @erevAnomaliesForecastsDescriptive2017, for a recent replication of classical demonstrations],^[<!--Open footnote-->@tverskyAdvancesProspectTheory1992 addressed the *fourfold pattern of risk attitudes*---i.e., choices between prospects indicate risk aversion for gains of high probability and losses of low probability, and risk seeking for gains of low probability and losses of high probability---and related effects, e.g., the *certainty effect* and the *reflection effect*, where the latter were already addressed by CPT's predecessor, prospect theory [@kahnemanProspectTheoryAnalysis1979]. Together, these empirical choice patterns indicate a violation of EV and expected utility (EU) maximization [see @bernoulliExpositionNewTheory1954\/1738].<!--Close footnote-->]
CPT and similar rank-dependent models [see @stottCumulativeProspectTheory2006, for an overview of models] fit choice data by assuming that people maximize the value
$$
V = \sum_i^n v(x_i) \times \pi_i
\; ,
\tag{7}
$$ 
with objective outcomes $x_i$ being transformed by a value function $v$, and *cumulative decision weights* $\pi_i$ being determined by the difference between transformed cumulative probabilities of the distribution $P'$.
More specifically, following @tverskyAdvancesProspectTheory1992, the objective outcomes are transformed by a value function
$$
\begin{aligned}
  v : \Omega' &\to \mathbb{R} \\
  x &\mapsto 
  \begin{cases}
     x_i^\alpha &\forall x_i \geq 0, \\
     -\lambda |x_i|^\alpha &\text{else}
     \; ,
  \end{cases}
\end{aligned}
\tag{8}
$$
with $\alpha \in [0,1]$ determining the degree of the function's concavity (convexity) over the positive (negative) outcome interval, and $\lambda > 1$ increasing the function's slope over the negative outcome interval only.
Each subjective value $v(x)$ is then multiplied (or: weighted) with a cumulative decision weight that takes the form
$$
\pi_i =
  \begin{cases}
     w^+(P(X \geq x_i)) - w^+(P(X > x_i)) \quad \forall x_i \geq 0, \\
     w^-(P(X \leq x_i)) - w^-(P(X < x_i)) \quad \text{else}
     \; , 
  \end{cases}
\tag{9}
$$
where $w$ is a monotonic increasing, nonlinear weighting function $w: [0,1] \to [0,1]$ satisfying $w^+(0) = w^-(0) = 0$ and $w^+(1) = w^-(1) = 1$.

Essentially, the model is such that the cumulative decision weights derived for the outcomes may be greater or smaller than their objective probabilities, causing the transformed outcomes---i.e., the subjective values---to be over- or underweighted *in* CPT, respectively.
Accordingly, for the description of choices, one may adopt the as-if weighting terminology from the introduction by stating that people choose as if they maximized the value in (7) and applied the weighting pattern that was estimated in CPT.
Importantly, the as-if prefix indicates that it cannot be concluded from the estimated weighting pattern that the mind does indeed perform any of the computations associated with the weighting of subjective values in CPT; rather, the mind processes the information about the choice alternatives in a way that the resulting choices translate to the estimated weighting pattern.
The as-if weighting terminology is therefore reminiscent of the distinction between different levels of explanation [cf. @marrVisionComputationalInvestigation1982].
That is, CPT may be considered a computational-level theory that specifies the computational problem the mind faces when being confronted with the choice between prospects, and how this problem may be solved by the abstract calculus of CPT.
However, as such, CPT cannot substitute algorithmic-level theories and process models that make claims about how exactly the mind transforms the inputs to the decision-making process into outputs which approximate the solutions of CPT [see @zilkerMeasuringModelingConstruction2020; see also @griffithsProbabilisticModelsCognition2010].
Respectively, this paper uses CPT as a mere data model to show how differences in the information-processing chain upfront choices in DFE---considered in the following section---may cause particular weighting patterns, among them the as-if underweighting of rare outcomes which has been found to be a robust behavioral phenomena in DFE.
To this end, the paper first continues to review the weighting patterns that can possibly estimated in CPT. 

Now, several consequences for the weighting pattern that can be estimated in CPT follow from (9):

* From the transformation of cumulative probabilities it follows that the value of a cumulative decision weight $\pi$ depends on the rank of the outcome $x$ for which $\pi$ is determined.

* The value of $\pi$ depends on the estimated shape of the graph of $w$ or the weighting function's parameters, respectively.
That is, the shape of the graph of $w$ displays over which interval on the cumulative probability scale $[0,1]$ the images of $w$ take values that are greater or smaller than the respective cumulative probabilities and how much greater or smaller these images are.
Hence, for a nonlinear graphical shape of $w$, the same numerical difference between objective cumulative probabilities may translate to cumulative decision weights of different value.

* For prospects containing either only positive or only negative outcomes, $\sum_i^n\pi_i = 1$ is satisfied.
Accordingly, for such prospects, the weighting of subjective values with cumulative decision weights rather than with objective probabilities may be roughly understood as a redistribution of the entire probability mass of $P(\Omega') = 1$ across outcomes [@zilkerNonlinearProbabilityWeighting2021].

\noindent
Given that the value of each cumulative decision weight depends on the two transformed cumulative probabilities in (9)---i.e., the probability of obtaining a positive (negative) outcome equal to or greater (smaller) than a respective outcome $x$, and the probability of obtaining a strictly greater (smaller) outcome---the remaining consequences for the weighting pattern are reviewed by considering the actual weighting function.
Therefore, Figure\ \@ref(fig:weighting-function) illustrates some of the possible graphical shapes of the two-parameter weighting function of @goldsteinExpressionTheoryPreference1987, which, however, is just one of several parameterizations that have been proposed [e.g., @prelecProbabilityWeightingFunction1998; @tverskyAdvancesProspectTheory1992; see @stottCumulativeProspectTheory2006, for an overview].
Now, let each $p$ on the abscissa be one of the four cumulative probabilities from (9). 
Then each graph in Figure\ \@ref(fig:weighting-function) displays the graphical shape of the weighting function
$$
\begin{aligned}
  w : [0,1] &\to [0,1] \\
  p &\mapsto \frac{\delta \times p^{\gamma}}
  {\delta \times p^{\gamma} + (1-p)^{\gamma}}
  \; ,
\end{aligned}
\tag{10}
$$
for the respective values of the parameters $\gamma \in [0,2]$ and $\delta > 0$.
Evidently, both parameters have distinct effects on the graphs' shape, with $\gamma$ affecting the curvature and $\delta$ the elevation.
As a consequence from (9) then, each combination of parameters implies a particular weighting pattern, with some of them being similar and others being rather distinct.

(ref:weighting-function) Possible Graphical Shapes of Goldstein and Einhorn's -@goldsteinExpressionTheoryPreference1987 Weighting Function

```{r weighting-function, fig.cap="(ref:weighting-function)"}
#compute images of weighting function (wf)
wf <- tibble(p = seq(0, 1, .01)) %>%  #cumulative probabilities
  expand_grid(gamma = seq(.1, 2, .1), #gamma values
              delta = c(.1, .5, 1, 2, 5, 10)) %>% #delta values
  mutate(wp = (delta*(p^gamma))/((delta*p^gamma)+(1-p)^gamma)) #images of wf

#labeller function for facet labels with LateX math expressions 
label_delta <- function(string) {
  TeX(paste("$\\delta=$", string, sep = ""))  
}

#plot shapes of weighting function
wf %>% 
  ggplot(aes(p, wp, group = gamma)) +
  facet_wrap(~delta, labeller = as_labeller(label_delta, default = label_parsed)) + 
  scale_x_continuous(breaks = seq(0, 1, .5)) +
  scale_y_continuous(breaks = seq(0, 1, .5)) + 
  labs(x = expression(p),
       y = expression(w(p)), 
       color = expression(gamma)) + 
  theme_apa() + 
  geom_line(aes(color = gamma), size = .5) +
  scale_color_viridis(option = "viridis") + 
  geom_abline(intercept = 0, slope = 1, color = "gray", linetype = "dashed")
```

In some more detail, the gray-dashed identity lines in Figure\ \@ref(fig:weighting-function) imply a linear weighting pattern.
That is, since the images of $w$, $w(p)$, are equal to the respective cumulative probabilities $p$, all cumulative decision weights $\pi$ that are derived according to (9) would be equal to the differences between the respective objective cumulative probabilities and therefore also to the objective probabilities of the outcomes for which the weights are determined.
Such a linear weighting pattern is implied by $\gamma = 1$ and $\delta = 1$. 
Now, both deviations from $\gamma = 1$ and $\delta = 1$ produce a nonlinear graphical shape.
That is, for $\gamma > 1$, the graphs take a S-shape---running below (above) the identity line for small (large) cumulative probabilities---which is more accentuated for larger deviations from $\gamma = 1$.
Importantly, the same *small* numerical difference between two cumulative probabilities $p$ then translates to varying differences between the respective images $w(p)$ depending on the interval on the cumulative probability scale. 
Specifically, because of the S-shaped curvature, the differences between the images $w(p)$ may be smaller than those between the respective cumulative probabilities in the lower and upper part of the cumulative probability scale, but may be considerably greater in the middle part.
As a consequence, the cumulative decisions weights are smaller than the respective objective probabilities for small-probability outcomes of either a low rank or a high rank, but they are larger for small-probability outcomes of a middle rank.^[<!--Open footnote-->Note that the distinction between outcomes of either low/high rank or middle rank is unnecessary for two-outcome prospects [see @tverskyAdvancesProspectTheory1992]. However, for finite many outcomes, the distinction is critical. More so, the fact that CPT may weigh outcomes of the same small probability differently, adds another reasons why the description-experience gap should not be equated with a reversed weighting pattern in CPT [see @hertwigConstructBehaviorGap2018]. I.e., neither could the gap then be interpreted in terms of an as-if underweighting (overweighting) of rare outcomes in DFE (DFD), nor would any of the potential contributors to the gap considered so far [see, e.g., @hertwigDescriptionexperienceGapRisky2009; @wulffMetaanalyticReviewTwo2018] treat some small-probability outcomes differently than other small-probability outcomes.<!--Close footnote-->]
Note that for all $\gamma < 1$ the graph of $w$ takes an inverse S-shape and the entire weighting pattern is reversed.
Moreover, the shape of the weighting function, and thus the weighting pattern, depends strongly on $\delta$, which affects the overall elevation of the graph.
That is, for $\delta < 1$, the interval on the cumulative probability scale over which the weighting function runs below the identity line is greater than the interval over which the weighting function runs above the identity line; and this pattern reverses for $\delta > 1$.
More specifically, $\delta$ shifts across the entire cumulative probability scale the intervals within which small differences between objective cumulative probabilities translate to either smaller or greater cumulative decision weights.
In other words then, for any decrease (increase) in $\delta$, the underweighting of small probability outcomes extends to more outcomes at the lower (higher) end of the outcome range.

To summarize the preceding paragraphs, CPT is a statistical or data model that can be used to describe choices between prospects by capturing systematic deviations from EV maximization in the parameter estimates of its value and weighting function.
Importantly, each estimated weighting function implies a weighting pattern.
Although the possible weighting patterns depend on the exact parameterization of the weighting function [e.g., @goldsteinExpressionTheoryPreference1987], the latter's graph usually takes a more or less accentuated (inverse) S-shape, which implies a weighting pattern where small-probability outcomes of low and high rank are underweighted (overweighted) in CPT's overall evaluation of a prospect according to (7).
Notably, for the case of choices between at most two-outcome prospects, the weighting pattern reduces to either an underweighting or overweighting of rare outcomes.
For the description of such choices, one may then adopt the as-if weighting terminology from the introduction, by stating that people decide as if they were either underweighting or overweighting rare outcomes.

# Sampling Strategies in DFE

The need to distinguish between the computational and the algorithmic level in the domain of decision making is exemplified by the fact that information about prospects may come in the form of descriptions or sampled outcomes.
Specifically, only rarely in peoples' daily life, the inputs to the decision-making process take the form of explicit descriptions of all outcome-probability pairs.
In such cases, people would make DFD, since the information from which the mind learns about the properties of prospects are complete descriptions thereof.
Yet, rather often, people make DFE, where the mind can learn about the latent properties of prospects only by experiental sampling over time [@hertwigDescriptionexperienceGapRisky2009, p. 517].
Accordingly, for the choice between $1, ..., k$ prospects, the inputs to the decision-making process are generated by a set of prospect-specific stochastic processes
$$
\{\{X^1_t\}, ... , \{X^k_t\}\}
\; ,
\tag{11}
$$
where each $\{X_{t}\}_{t \in \mathbb N}$ is a collection of independent and identically distributed (i.i.d.) random variables.^[Note that it has been emphasized that in the natural world samples are "virtually never random" [@fiedlerBewareSamplesCognitiveecological2000, p. 660]. However, in the sampling paradigm, i.i.d. random variables are commonly assumed.]
The inputs to DFE are then the realizations of the random variables in (11), which require different algorithms to be processed than do descriptions of the outcomes and their probabilities in DFD.

## Accumulating Evidence About Differences in Latent Properties

Since it is only through their fundamental properties, or combinations thereof, that any distinction between the prospects can be made, systematic choices in DFE must be based on the assessment of differences in the latent properties of prospects.
Accordingly, the mind may use the sampled outcomes to first infer the latent objective probabilities of all possible outcomes, and then proceed by selecting a property, or combinations thereof, to assess differences among the prospects and make a respective choice.
However, the mind may also approximate such a process by using an algorithm that omits explicit inferences and directly accumulates evidence about the differences in latent properties from the sampled outcomes.
To this end, sequential sampling models of decision making [e.g., @busemeyerDecisionFieldTheory1993] assume that the outcomes of prospects are sequentially sampled and integrated into dynamic decision variables and that a choice is made once a decision variable exceeds a threshold in favor for one of the prospects.
This class of process models thereby provides an algorithmic link between the actual sampling process and the choices in DFE, and has shown to explain some of the robust deviations from EV maximization [see @busemeyerDecisionFieldTheory1993; @bhatiaSequentialSamplingParadoxes2014], including the underweighting of rare outcomes in the sampling paradigm [see @markantModelingChoiceSearch2015].
Moreover, these models implement speed-accuracy tradeoffs, with the amount of evidence that must be sampled in favor for a prospect increasing with thresholds, leading to more (less) accurate but slower (faster) choices for high (low) thresholds.

Yet, there are several distinct properties that can be used to assess differences among the prospects.
Specifically, the summary and the round-wise decision strategy---for which either the prospect is chosen that produced the greater mean across all sampled outcomes or the prospect that won more comparisons between single sampled outcomes, respectively [see @hillsInformationSearchDecisions2010]---can each be indicative for differences in a distinct latent property.
That is, for a large number of sampled outcomes, the summary strategy is indicative for differences in the latent EV as the mean of a large collection of i.i.d. random variables converges to the EV of the respective random variable.
In turn, the round-wise strategy is indicative for differences in the likelihood to produce a higher outcome than the other prospect.
Respectively, in the following section, the summary and the round-wise strategy are implemented into a common accumulation model that shows how the mind may accumulate evidence for differences in distinct latent properties [see also @bhatiaChoiceRulesAccumulator2017, where heuristic choice rules are integrated into an accumulation model].
More specifically, the proposed model accumulates the outcomes obtained from a sequence of comparisons between sample means, with the size of the samples underlying each mean comparison tending to be small (large) for high (low) switching probabilities.
Accordingly, whereas the decision variables of the model capture how much (more) comparisons between sample means a prospect has won, the unfolding accumulation process more closely resembles the round-wise strategy for high switching probabilities and the summary strategy for low switching probabilities.
Hence, the model also shows how the mind may rely on different sampling strategies to alter which differences in the latent properties of prospects evidence is accumulated for.

## Model 

We consider the sampling paradigm and a choice between two prospects denoting the distributions $P'^X$ and $P'^Y$ of the discrete random variables $X$ and $Y$, respectively.
The model assumes that the information-processing chain starts at random with a stochastic process on one of the two random variables.
Specifically, it is assumed that an agent starts with equal probability to sample from one of the prospects, say $P'^X$, and generates a sequence of random variables $X_1, X_2,...$, where the mean over the sequence is computed or updated with each new outcome that is sampled.
The respective stochastic process $\{S^X_n\}_{n \in \mathbb{N}}$ is defined by
$$
S^X_n = \frac{1}{n} \sum_{t = 1}^n X_t, \quad n \in \mathbb{N}
\; ,
\tag{12}
$$
and terminates as soon as an outcome is sampled from the other prospect.
The switching probability $\psi \in (0,1]$, which is assumed to be adopted prior the start of the information-processing chain and to be fixed throughout, controls the probability with which outcomes from different prospects are sampled in direct succession.
In other words, the switching probability is the probability with which the stochastic process on the current random variable stops and a new stochastic process on the other random variable starts with the subsequently sampled outcome.
To implement an evidence accumulation process, the model assumes that each time after a new stochastic process was started and terminated on both random variables, their respective values---i.e., the means over the sequences---are compared, with the prospect underlying the stochastic process with the greater final value receiving a round win.
Accordingly, for the prospect $P'^X$, this stage is modeled as the mapping
$$
\begin{aligned}
  Z^X : \mathbb{R} &\to \mathbb{N} \\
  S^X_n - S^Y_n &\mapsto 
  \begin{cases}
     1 &\text{if} \quad  S^X_n > S^Y_n, \\
     0 &\text{else}
     \; ,
  \end{cases}
\end{aligned}
\tag{13}
$$
where $Z^X$ is a random variable that takes only the two values $0$ and $1$, denoting a lost or won mean comparison, respectively. 
The model assumes that a round consisting of a pair of stochastic processes---i.e., one for each prospect---and the subsequent comparison of their final values is repeated until the sum of round wins for one of the two prospects reaches a threshold $\theta \in \mathbb{N}$.
Similar to the switching probability, it is assumed that the threshold is adopted prior the start of the information-processing chain and is fixed throughout.
For $P'^X$, then, we obtain a sequence of independent comparisons $Z^X_1, Z^X_2, ...$ and model the respective evidence accumulation process as a random walk $\{D^X_m\}_{m \in \mathbb{N}}$ defined by 
$$
D^X_m = \sum_{i = 1}^m Z^X_i, \quad m \in \mathbb{N}
\;,
\tag{14}
$$
resembling a dynamic decision variable.
Note that since (13) describes a Bernoulli trial, the random walk in (14) is based on a Bernoulli process.

Finally, note that the described model assumes two random walks---i.e., one for each prospect---approaching the same threshold, which is the absolute number of mean comparisons a prospect must win in order to be chosen.
However, one may also define a single random walk, resembling a common dynamic decision variable, which approaches a positive threshold $\theta^+$ and a negative threshold $\theta^-$.
Therefore, (13) may be adapted such that $Z$ takes the value $-1$ instead of $0$, such that the threshold determines how many more mean comparisons a prospect must win in order to be chosen.

### Model Predictions

Below, the key predictions concerning the effects of the model parameters---i.e., the switching probability $\psi$ and the threshold $\theta$---on the length of the information-processing chain and the final choice are outlined.
Moreover, previous research has shown that differences as to how information about the properties of prospects is processed can translate to characteristic shapes of CPT's value and weighting function [see @pachurHowTwainCan2017; @zilkerNonlinearProbabilityWeighting2021].
Respectively, this section also contains predictions about the potential relations between $\psi$ and $\theta$ and the CPT parameters.
A summary of the model predictions can be found in Table\ \@ref(tab:predictions).

#### Length of Information-Processing Chain

The model predicts the overall number of sampled outcomes to increase with thresholds.
Specifically, the required number of independent mean comparisons increases with thresholds.
Then, since each comparison is based on its own pair of stochastic processes, an increase in thresholds translates to a larger number of required stochastic processes and, ceteris paribus, therefore also to a larger overall number of sampled outcomes.
In turn, the model predicts the overall number of sampled outcomes to decrease with increasing switching probabilities.
Specifically, each stochastic process is predicted to terminate faster, the higher the probability that the subsequent outcome is sampled from the other prospect---i.e., the switching probability.
Accordingly, an increase in the switching probability leads to shorter stochastic processes which translates, ceteris paribus, to a smaller overall number of sampled outcomes.

#### Final Choice

Note first that the thresholds and switching probabilities alter the degree to which the accumulation process resembles the summary or the round-wise strategy.
That is, for low thresholds and switching probabilities, only a few mean comparisons based on pairs of long stochastic processes---i.e., large samples---are carried out, thereby resembling the summary strategy.
Accordingly, for such parameter combinations, the model predicts the prospect to be chosen that possesses the larger EV.
In turn, for high thresholds and switching probabilities, many mean comparisons based on pairs of short stochastic process---i.e., small samples---are carried out, thereby resembling the round-wise strategy.
Accordingly, for such parameter combinations, the model predicts the prospect to be chosen that is more likely to return a higher outcome.
Yet, if the prospect that is more likely to return a higher outcome does not possess the higher EV, the parameter combinations resembling the round-wise strategy are predicted to cause a deviation from the solutions of EV maximization.

Now, more specifically, because the switching probability is predicted to alter the length of the stochastic processes underlying each mean comparison, the switching probability should affect whether low-probability outcomes contribute to the majority of the required mean comparisons about as much as would be warranted based on their objective probabilities, or whether they contribute rather less.
That is, for short stochastic processes, the binomial distribution associated with small-probability outcomes is positive skewed, therefore causing the relative frequencies with which these outcomes occur over the course of such a process to be smaller rather than larger than their latent objective probabilities.
Respectively, if the small-probability outcome is smaller (larger) than the EV, high switching probabilities---and therefore pairs of short stochastic processes---cause the mean to be an inflated (deflated) estimate of the EV.
Such an inflation and deflation of the means for high switching probabilities can then translate to an as-if underweighting of rare outcomes.
Specifically, if the mean of the prospect with the lower (higher) EV is inflated (deflated), the outcome of the comparison between the means may be a reversal---in sign---of the outcome of a comparison between the EVs, leading to choices that take the form of an as-if underweighting of rare outcomes.
Yet, if the mean of the prospect with the lower (higher) EV is deflated (inflated), the difference between the means is an amplification of the differences between the EV, which can actually simplify EV maximization [@hertwigDecisionsExperienceWhy2010]. 
In turn, low switching probabilities---and therefore pairs of long stochastic processes---cause the mean to closely correspond to the EV, leading to choices that are in line with EV maximization.

Finally, because each comparison’s contribution to the accumulated evidence is weighted equally, the predictions made for given switching probabilities should become more robust as the thresholds and therefore the number of independent comparisons increases.
That is, the thresholds implement a speed-accuracy trade-off of the form that whatever systematic differences in the latent properties of prospects may be represented in a sequence of mean comparisons, should be more accurately assessed as the thresholds increase.
Accordingly, the as-if underweighting of rare outcomes that is predicted to occur for high switching probabilities should remain and become more pronounced the higher the thresholds are.
Thus, the model's predictions should substantiate the claim made at the outset of the paper, namely, that the reliance on multiple or many small samples---in the form of comparisons between pairs of short stochastic processes---can cause an as-if underweighting of rare outcomes while fully accounting for a large number of sampled outcomes.

#### Cumulative Prospect Theory

To elaborate how the differences in the predictions made for the model parameters may be described in CPT's parameters, the value function of Tversky and Kahneman [-@tverskyAdvancesProspectTheory1992, see (8)] and the weighting function of Goldstein and Einhorn [-@goldsteinExpressionTheoryPreference1987, see (10)] are used.
To simplify matters, the further discussion and the computational analysis are constrained to choices between a safe prospect---possessing just one outcome that occurs with certainty---and a two-outcome risky prospect.
All outcomes are assumed to be positive and the safe outcome is assumed to fall between the the low-rank outcome, $x_{low}$, and the high-rank outcome, $x_{high}$, of the risky prospect in order to omit dominant prospects that always lead to a higher outcome than the respective other prospect.

Now, since for low switching probabilities the model tends to choose the prospect possessing the larger EV, the parameters of the value and weighting function are predicted to correspond to a linear weighting of outcomes and probabilities.
Thus, the lower the switching probabilities, the more should the choices translate to parameter estimates that satisfy $\alpha = 1$, $\gamma = 1$, and $\delta = 1$.
However, for high switching probabilities, the model predicts systematic deviations from the solutions of EV maximization, which take the form of an as-if underweighting of rare outcomes:
More specifically, for $\psi = 1$, the model tends to choose the risky prospect, if the probability of its high-rank outcome satisfies $p_x(x_{high}) > .5$, irrespective of its EV.
Vice versa, the model tends to choose the safe outcome, if $p_x(x_{high}) < .5$ is satisfied.
Accordingly, for high switching probabilities, the weighting pattern should be such that the high-rank outcome is overweighted for $p_x(x_{high}) > .5$ and otherwise underweighted.
Note now that the possible weighting patterns for choices between at most two-outcome prospects readily reduces to an over- or underweighting of the high-rank outcome [@zilkerNonlinearProbabilityWeighting2021]:
$$
\begin{aligned}
  \pi_{high} &= w(p_x(x_{high})) \\
  \pi_{low} &= w(p_x(x_{low}) + p_x(x_{high})) - w(p_x(x_{high})) \\
  &= 1 - \pi_{high}
  \; .
\end{aligned}
\tag{15}
$$
That is, the images of the weighting function equal the decision weights assigned to the high-rank outcome of the risky prospect.
Hence, for high switching probabilities, the graph of the weighting function is predicted to run below the identity line for $p_x(x_{high}) < .5$---leading to an underweighting of small-probability outcomes---and above the identity line for $p_x(x_{high}) > .5$---leading to an overweighting of high-probability outcomes.
Accordingly, the graph of the weighting function should take a S-shape, which is given by $\gamma > 1$ and $\delta = 1$.
Yet, since the model tends to approximate the solutions of EV maximization the lower the switching probabilities are, the S-shape should be most pronounced for high switching probabilities.
Thus, $\gamma$ should increase with $\psi$.
Note further that the predicted shape of the weighting function for high switching probabilities reflects the round-wise strategy's high sensitivity to differences in the probability to produce the higher outcome most of the time.
That is, the slope of the weighting function increases around the midpoint of the probability scale.
The predicted flat ends of the graph, however, indicate that the round-wise strategy more or less ignores how much larger the probability to produce a higher outcome is. 

Moreover, an increase in the switching probability should lead to a more concave value function, since all mean comparisons are ordinal and weighted equally in their contribution to the accumulated evidence.
Specifically, the model is such that the magnitudes of outcomes are ignored once a comparison is carried out.
Hence, for high switching probabilities, the choices depend on which prospect produces the higher outcome most of the time, irrespective of how much larger the outcomes are.
Therefore, $\alpha$ is predicted to decrease as $\psi$.
Finally, all predictions concerning the parameters of CPT's value and weighting function should become more robust with increases in $\theta$ as increasing thresholds lead to more systematic choices.

(ref:predictions) Summary of Model Predictions

```{r predictions}
predictions <- tibble("Measure" = 
                        c("Choices pattern",
                          "",
                          "$\\gamma$ (curvature of $w$)",
                          "$\\delta$ (elevation of $w$)",
                          "$\\alpha$ (concavity of $v$)"),
                      "Predictions for changes in $\\psi$" = 
                        c("More EV maximization for decreasing $\\psi$",
                          "More as-if underweighting of rare outcomes for increasing $\\psi$",
                          "$\\geq 1$, increases with $\\psi$",
                          "1, no effect of $\\psi$",
                          "$\\leq 1$, decreases with increasing $\\psi$"))
apa_table(predictions, caption = "(ref:predictions)", note = "The predictions for changes in $\\psi$ should become more robust for increasing values of $\\theta$ as choices become more systematic for high thresholds.", escape = FALSE)
```

# Simulation Study

To substantiate and refine the predictions of the model, a computational implementation was used to simulate the sampling and accumulation process for a set of choices between a safe prospect and a two-outcome (risky) prospect.
The computational model was written in `R` [@rcoreteamLanguageEnvironmentStatistical2021] and is embodied in the GitHub repository accompanying this paper.
The simulation was conducted for varying combinations of switching probabilities and thresholds.
For each of these combinations, the simulated data was modeled with CPT's value and weighting function, using a Bayesian parameter estimation.
The simulated choices and estimated CPT parameters can be understood as theory-implied data and data models which remain to be tested against empirical data [see @guestHowComputationalModeling2021; @haslbeckModelingPsychopathologyData2021].

## Method

Below, the data generation and data modeling procedure is briefly reviewed. 

### Choice Problems

A test set of $60$ choice problems was obtained by stratified sampling from an initial set of $10,000$ problems.
The stratification procedure was used to ensure that the test set contained choice problems with small-probability outcomes of different rank---i.e., small-probability outcomes that are either higher or lower than the EV of the two-outcome prospect---as well as choice problems without small-probability outcomes.
The exact procedure was as follows:
For each of the $10.000$ problems in the initial set, three outcomes were randomly drawn from a uniform distribution over the interval $[0, 20]$, with the smallest and highest of these three outcomes being assigned to the risky prospect to omit dominant prospects.
The probability for the lower outcome of the risky prospect, $p_x(x_{low})$, was drawn from a uniform distribution over the interval $(0, 1)$, with the probability of the higher outcome being set to $p_x(x_{high}) = 1-p_x(x_{low})$.
To obtain the $60$ choice problems of the test set, the initial set was divided into three subsets, where each subset contained either all problems with $p_x(x_{high}) \in (0,.2)$ or $p_x(x_{high}) \in [.2,.8]$ or $p_x(x_{high}) \in (.8,1)$.
From each of these subset, then, $20$ choice problems were randomly sampled.

### Data Generation

To simulate the sampling and accumulation processes, the following parameter values were used and combined with each other.
That is, each parameter combination was used to solve the test set.

* *Switching probability* $\psi$ : 
The switching probability was varied in the interval $[.1, 1]$ in increments of $.1$.

* *Threshold* $\theta$: 
The threshold was varied in the interval $[1,5]$ in increments of 1. 

* *Decision variable*: The decision variable of a prospect either counts the number of won comparisons---implying an absolute threshold---or how much more comparisons were won relative to the other prospect---implying a relative threshold.

\noindent
Since the switching probability introduces some stochasticity into the information-processing chain, each of the 100 resulting parameter combinations was used 100 times---resembling 100 agents---to solve the test set. 
In sum, then 100 (parameter combinations) $\times$ 100 (agents) $\times$ 60 (choice problems)  = 600,000 sampling and accumulation processes were simulated. 
The respective dataset can be retrieved from the accompanying GitHub repository.

### Bayesian CPT Analysis of Choice Data

The choice data generated for each parameter combination was separately modeled in CPT, using Tversky and Kahneman's (1992) value function and Goldstein and Einhorn's (1987) weighting function.
To demonstrate that the distortions from linear probability weighting are not just due to the difference between the latent objective probabilities and the relative number of times the outcomes are sampled over the course of any accumulation process, the sampled relative frequencies are supplied as probability information to the weighting function.
To accommodate for possible random choice behavior that may be exerted by some parameter combinations of the data-generating accumulation model, the CPT model was amended with the logit choice rule
$$
p(P'^{safe}) = \frac{1} {1 + e^{-\rho(V_{safe}^{\frac{1}{\alpha}}-V_{risky}^{\frac{1}{\alpha}})}}
\; ,
\tag{16}
$$
where $p(P'^{safe})$ is the probability that the safe prospect is chosen over the risky prospect, $V_{safe}$ and $V_{risky}$ are the valuations of the safe and risky prospect that result from the parameter estimates of the value and weighting function, and $\rho \geq 0$ is a sensitivity parameter.
The sensitivity parameter governs how strongly the choice between prospects depends on the differences in the valuations of the prospects---i.e., the core CPT model.
Specifically, $\rho = 0$ implies no sensibility and therefore random choices.
In turn, for increasing values of $\rho$, the probability of choosing the prospect with the higher valuation increases.
Note further that the valuation of the prospects were rescaled by $\frac{1}{\alpha}$, as proposed by @stewartPsychologicalParametersHave2018, to guard against possible parameter interdependencies between $\alpha$ and $\rho$ [see @krefeld-schwalbStructuralParameterInterdependencies2021; @scheibehenneUsingBayesianHierarchical2015].
In sum, then, the model has four free parameters $\alpha, \gamma, \delta, \rho$.

Since for a given choice problem and parameter combination of the accumulation model there should be no systematic differences among the 100 iterations (agents), their data is combined and free parameters are estimated across them.
Such a grouped approach is expected to reveal the main effects of a given parameter combination of the accumulation model on the choice patterns and ignores unsystematic differences or noise that may be caused by the switching probability [see @nilssonHierarchicalBayesianParameter2011].
To facilitate comparisons across parameter combinations of the accumulation model, uninformative prior distributions were used throughout for all four parameters of the data model.
Specifically, the prior distribution $\alpha \sim U(0,1)$, $\gamma \sim U(0,2)$, $\delta \sim U(0,10)$, and $\rho \sim U(0,5)$ were used.  
 
```{r data, include=FALSE}
#load choice data
cols_choices <- list(.default = col_double(),
                     boundary = col_factor(),
                     gamble = col_factor(),
                     rare = col_factor(),
                     agent = col_factor(),
                     choice = col_factor())
choices <- read_csv("data/choices/choices.csv", col_types = cols_choices)
choices <- choices %>% 
  filter(boundary == "absolute")

#load CPT estimates
cols_cpt <- list(.default = col_double(),
                 boundary = col_factor(),
                 a = col_factor(),
                 parameter = col_factor())
cpt <- read_csv("data/estimates/estimates_cpt.csv", col_types = cols_cpt)
cpt <- cpt %>% 
  filter(boundary == "absolute")
```

To estimate the posterior distributions of the parameters, Markov Chain Monte Carlo sampling was used, where 20 chains of 40,000 samples each were run after a warm-up period of 1000 samples.
To reduce potential autocorrelation during the sampling process, only every 20th sample was kept (thinning), leaving a total of 40,000 samples across chains.
The minimum effective sample size was `r min(cpt$n.eff)`.
The potential scale reduction factor $\hat{R}$ [see @gelmanInferenceIterativeSimulation1992] was $\leq$ `r round(max(cpt$Rhat), 4)` for all parameters, indicating good convergence.

## Results

We start by inspecting how the number of outcomes sampled over the course of a sampling and accumulation process changes with varying combinations of switching probabilities and thresholds.
Figure\ \@ref(fig:chain-length) shows the respective median for each parameter combination.
Since the two stochastic processes underlying a mean comparison tend to terminate faster the higher the switching probabilities are, the model predicts the overall number of sampled outcomes to decrease with increasing switching probabilities.
As can be seen from the changing slopes of the lines in Figure\ \@ref(fig:chain-length), the decrease in the number of sampled outcomes diminishes as the relative increase in the switching probability diminishes.
Moreover, the overall number of sampled outcomes increases with thresholds at a relatively constant rate, reflecting the latters impact on the number of required mean comparisons.
Finally, consider the dashed horizontal line which displays the median number of 14 outcomes that @wulffMetaanalyticReviewTwo2018 found to be sampled in 10,712 trials involving a choice between a safe and a two-outcome prospect in the sampling paradigm.
Notably, the parameter combinations that closely resemble the round-wise strategy---i.e., high switching probabilities and thresholds---or the summary strategy---i.e., low switching probabilities and thresholds---lead to overall numbers of sampled outcomes that come fairly close to this meta-analytic median.
In turn, hybrids of both strategies produce overall numbers of sampled outcomes that are considerably lower or higher.

(ref:chain-length) Lengths of Information-Processing Chains

```{r chain-length, fig.cap="(ref:chain-length)"}
choices %>%
  group_by(s, a) %>% 
  summarize(n_med = median(n_sample)) %>% 
  ggplot(aes(x = s, y = n_med, group = as.factor(a), color = as.factor(a))) + 
   labs(x = expression(psi),
       y = "Median of Overall Sampled Outcomes",
       color = expression(theta)) +
  scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1, .5)) +
  scale_y_continuous(limits = c(0, 120), breaks = seq(0, 150, 50)) +
  geom_point() +
  geom_line() + 
  geom_hline(yintercept = 14, linetype = "dashed", color = "gray") +
  annotate(geom="text", x=.95, y=16, label="Wulff et al. (2018)", color="gray") + 
  scale_color_viridis_d(option = "viridis") +
  theme_apa()
```


### Final Choice

Figure\ \@ref(fig:choice-rates) displays the rates of choices that did not maximize the latent EV (hereafter: false response rates) for each combination of switching probabilities and thresholds.
Moreover, the rates are separated by the presence and rank of a small-probability outcome.
Consider first the top panel which shows the false response rates across all problems where the low-rank outcome of the risky prospect has a small probability:
Over the course of short stochastic processes, then, the low-rank outcomes tend to be sampled less often than would be objectively warranted, leading to an inflation of the respective means of the risky prospect.
Accordingly, the top panels show that the rates of false choices of the risky prospect increase with the switching probability, but the rates of false safe choices remain generally low.
More specifically, the higher the switching probabilities, the more severe should the inflation of the means---and the overestimation of the EVs---of the risky prospects be. 
As a consequence, if the risky prospects possesses the smaller EV, an increase in the switching probability increases the risk to deviate from EV maximization by falsely choosing the risky prospects on the basis of mean comparisons.
Importantly, these deviations take the form of an as-if underweighting of rare outcomes.
In turn, if the risky prospects possess the larger EV, the inflation of their means decreases the risk to falsely choose the safe prospect.
Note from the middle panel that the pattern of false response rates reverses across all problems where the high-rank outcome of the risky prospect has a small probability.
In this case, then, the means of the risky prospects tend to be more deflated, the higher the switching probability is, which, however, again results in an as-if underweighting of rare outcomes.
Furthermore, the differences between the switching probabilities concerning the false response rates tend to be more pronounced for high thresholds, showing that over the course of multiple mean comparisons the inflation and deflation of the means of the risky prospect is more robust.

(ref:choice-rates) Rates of False Risky and False Safe Choices

```{r choice-rates, fig.cap="(ref:choice-rates)"}
#prepare data

##determine normative choice according to latent and sampled EV
fr_rates <- choices %>%
  mutate(norm = case_when(ev_ratio > 1 ~ "A", ev_ratio < 1 ~ "B")) %>% # determine normative choice
  filter(!is.na(norm)) %>% #exclude trials with equal EV
  group_by(s, boundary, a, rare, norm, choice) %>% #separate by model parameter and type of rare event
  summarise(n = n()) %>%
  mutate(rate = round(n/sum(n), 2), #compute response rates
         type = case_when(norm == "A" & choice == "B" ~ "Safe", #determine false response type
                          norm == "B" & choice == "A" ~ "Risky")) %>%
  ungroup() %>%
  filter(!is.na(type)) %>% #remove correct responses
  select(-c(norm, choice, n)) %>% 
  mutate(rare = case_when(rare == "none" ~ "\\in \\[.2,.8\\]", #change facet labels for rare events
                          rare == "attractive" ~ "\\in (0,.2)",
                          rare == "unattractive" ~ "\\in (.8,1)"))

# labeller functions
label_theta <- function(string) {
  TeX(paste("$\\theta=$", string, sep = "")) #threshold parameter theta
}

label_rare <- function(string) {
  TeX(paste("$\\p_{High}$", string, sep = "")) #type of rare event
}

#plot
fr_rates %>%
  ggplot(aes(s, rate, group = type)) +
  facet_grid(rare~a, labeller = labeller(rare = as_labeller(label_rare, default = label_parsed), 
                                         a = as_labeller(label_theta, default = label_parsed))) +
  labs(x = expression(psi),
       y = "False Response Rate",
       color = expression(psi),
       shape = "False\nResponse") +
  scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1, .5)) +
  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, .5)) +
  geom_line(aes(color = s, group = type)) + 
  geom_point(aes(color = s, shape = type), size = 2) +
  scale_shape_manual(values = c(4, 16)) +
  scale_color_viridis(option = "viridis") +
  theme_apa()
```

### Cumulative Prospect Theory

Figure\ \@ref(fig:weighting-parameters) shows the means and the 95%-intervals of the posterior distributions of the curvature parameter $\gamma$ and elevation parameter $\delta$ as well as the resulting graphical shape of the weighting function.
The findings are fairly consinstent with the predictions.
Note first that the estimates for the parameter combination $\theta = 1$ and $\psi = 1$ have large posterior intervals.
In these cases, no other relative frequencies than 0 and 1 are supplied to the weighting function, which may explain why the values in between cannot reliably be accounted for.
However, for $\theta = 1$ and $\psi < 1$, the parameter estimates indicate a linear weighting pattern, demonstrating the well-established explanation that if the prospect with the higher mean across all sampled outcomes is chosen, sampling error can account for any deviations from EV maximization.

For $\theta > 1$, the estimates substantiate the prediction that $\gamma$ takes values $\geq 1$ which increase with the switching probability, resulting in a increasingly pronounced S-shaped weighting function.
In other words, the higher the switching probability, the more severe is the underweighting (overweighting) of high-rank outcomes of small (large) probability in CPT.
Moreover, $\delta$ takes values $\geq 1$ and increases slightly with the switching probability, causing the high-rank outcome to be overweighted the most, if its probability is just above the mid-point.

(ref:weighting-parameters) Parameter Estimates and Graphical Shape of the Weighting Function

```{r weighting-parameters, fig.cap="(ref:weighting-parameters)"}

#plot estimates

##gamma
gamma <- cpt %>%
  filter(parameter == "gamma") %>%
  ggplot(aes(s, mean, color = s)) +
  facet_wrap(~a, nrow = 1, labeller = labeller(a = as_labeller(label_theta, default = label_parsed))) +
  scale_y_continuous(limits = c(0,2), breaks = seq(0,2.0,1.0))+
  labs(x = element_blank(), #omit axis title
       y = expression(gamma),
       color = expression(psi)) +
  geom_errorbar(aes(ymin=`2.5%`, ymax=`97.5%`)) + 
  geom_point() +
  scale_color_viridis(option = "viridis") +
  theme_apa() +
  theme(axis.line.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.text.x = element_blank())

##delta
delta <- cpt %>%
  filter(parameter == "delta") %>% 
  ggplot(aes(s, mean, color = s)) +
  facet_wrap(~a, nrow = 1) + 
  scale_y_continuous(limits = c(0,10), breaks = seq(0,10,5)) +
  scale_x_continuous(limits = c(0, 1.1), breaks = seq(0,1,.5)) +
  labs(x = expression(psi),
       y = expression(delta),
       color = expression(psi)) +
  geom_errorbar(aes(ymin=`2.5%`, ymax=`97.5%`)) + 
  geom_point() +
  scale_color_viridis(option = "viridis") +
  theme_apa() + 
  theme(strip.text.x = element_blank()) #omit facet labels

wf <- cpt %>%
  select(s, boundary, a, parameter, mean) %>%
  pivot_wider(names_from = parameter, values_from = mean) %>%
  select(-c(alpha, rho)) %>%
  expand_grid(p = seq(0, 1, .05)) %>%
  mutate(w = round(  (delta * p^gamma)/ ((delta * p^gamma)+(1-p)^gamma), 2))

##weighting function
weight <- wf %>% #graphs for absolute boundary
  ggplot(aes(p, w, group = s, color = s)) +
  facet_wrap(~a, nrow = 1, labeller = labeller(a = as_labeller(label_theta, default = label_parsed))) + 
  labs(x = "Experienced Probability",
       y = expression(pi),
       color = expression(psi)) +
  scale_x_continuous(breaks = seq(0, 1, .5)) +
  scale_y_continuous(breaks = seq(0, 1, .5)) +
  geom_line(size = .5) +
  scale_color_viridis(option = "viridis") +
  theme_apa() + 
  theme(strip.text.x = element_blank()) #omit facet labels


##merge figures
ggarrange(gamma, delta, weight, ncol = 1, nrow = 3, common.legend = TRUE, legend = "right")
```


Figure\ \@ref(fig:value-parameters) shows the means and the 95%-intervals of the posterior distributions of the outcome sensitivity parameter $\alpha$ and the choice sensitivity parameter $\rho$, as well as the shape of the value function.
As predicted, an increase in the switching probability leads to a decrease in $\alpha$, reflecting that the outcome information is largely ignored if choices are based on ordinal comparisons of single outcomes rather than of means of large samples.
Note further that the estimates are stable across thresholds.
Finally, note that the choice sensitivity parameter varied systematically with the switching probability, such that the choices were more sensitive to the valuations in CPT for low values of $\psi$.
However, even for high values of $\psi$, the choices did not appear to be random.

(ref:value-parameters) Parameter Estimates and Graphical Shape of the Value Function

```{r value-parameters, fig.cap="(ref:value-parameters)"}
#plot estimates

##alpha
alpha <- cpt %>%
  filter(parameter == "alpha") %>% 
  ggplot(aes(s, mean, color = s)) +
  facet_wrap(~a, nrow = 1, labeller = labeller(a = as_labeller(label_theta, default = label_parsed))) +
  scale_x_continuous(limits = c(0, 1.1), breaks = seq(0,1,.5)) +
  scale_y_continuous(limits = c(0,1), breaks = seq(0,1, .5)) + 
  labs(x = element_blank(),
       y = expression(alpha),
       color = expression(psi)) +
  geom_point() +
  geom_errorbar(aes(ymin=`2.5%`, ymax=`97.5%`)) + 
  scale_color_viridis(option = "viridis") +
  theme_apa() + 
  theme(axis.line.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.text.x = element_blank())

###value function
vf <- cpt %>%
  select(s, boundary, a, parameter, mean) %>%
  pivot_wider(names_from = parameter, values_from = mean) %>%
  select(-c(gamma, delta, rho)) %>%
  expand_grid(x = seq(0, 20, .5)) %>%  
  mutate(v = round(x^alpha, 2)) 

value <- vf %>% 
  ggplot(aes(x, v, group = s, color = s)) +
  facet_wrap(~a, nrow = 1)+ 
  labs(x = "Objective Outcome",
       y = "Subjective Value",
       color=expression(psi)) +
  scale_x_continuous(limits = c(0,20), breaks = seq(0, 20, 10)) +
  scale_y_continuous(limits = c(0,20), breaks = seq(0, 20, 10)) +
  geom_line(size = .5) +
  scale_color_viridis(option = "viridis") +
  theme_apa() + 
  theme(strip.text.x = element_blank())

##rho
rho <- cpt %>%
  filter(parameter == "rho") %>% 
  ggplot(aes(s, mean, color = s, shape = boundary)) +
  facet_wrap(~a, nrow = 1) + 
  labs(x = expression(psi),
       y = expression(rho),
       color = expression(psi)) +
  scale_x_continuous(limits = c(0, 1.1), breaks = seq(0, 1,.5)) +
  scale_y_continuous(limits = c(0, 5), breaks = seq(0, 5,2.5)) +
  geom_point() +
  geom_errorbar(aes(ymin=`2.5%`, ymax=`97.5%`)) + 
  scale_color_viridis(option = "viridis") +
  scale_shape_manual(values = c(4, 16)) +
  theme_apa() + 
  theme(strip.text.x = element_blank())

##merge figure
ggarrange(alpha, rho, value, ncol = 1, nrow = 3, common.legend = TRUE, legend = "right") 
```

In sum, then, the computational analysis substantiates the claim that sampling strategies can be used to alter which difference in the latent properties of prospects evidence is accumulated for and that the choices vary respectively.
Moreover, it has been demonstrated how these differences in the choice patterns translate to characteristic shapes in CPT's weighting and value function. 

# Discussion

\newpage

# References
